{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChromaDB 패널 검색 (메타데이터 필터 적용)\n",
    "\n",
    "## 주요 개선사항\n",
    "- **메타데이터 필터 적용**: 지역, 연령대, 성별 필터링\n",
    "- **Fallback 메커니즘**: 메타데이터 필터로 0건이면 topic만으로 재검색\n",
    "\n",
    "## 검색 파이프라인\n",
    "1. **메타데이터 추출**: LLM으로 검색 쿼리에서 구조화된 메타데이터 추출\n",
    "2. **카테고리 분류**: LLM으로 메타데이터를 카테고리별로 분류\n",
    "3. **텍스트 생성**: 카테고리별로 자연어 텍스트 생성\n",
    "4. **임베딩 생성**: Upstage Solar로 임베딩\n",
    "5. **Topic + 메타데이터 필터링 검색**: 카테고리(topic)와 메타데이터로 필터링\n",
    "6. **단계적 필터링**: 여러 카테고리를 순차적으로 적용하여 후보 축소\n",
    "\n",
    "## 필요한 패키지\n",
    "```bash\n",
    "pip install anthropic langchain-upstage langchain-chroma chromadb\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 라이브러리 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라이브러리 import 완료\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "from typing import List, Dict, Any, Optional\n",
    "from anthropic import Anthropic\n",
    "from langchain_upstage import UpstageEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from collections import defaultdict\n",
    "\n",
    "# ⭐ 파일 핸들 제한 확인 및 조정 (Windows는 자동 조정됨)\n",
    "import sys\n",
    "if sys.platform != 'win32':\n",
    "    import resource\n",
    "    try:\n",
    "        soft, hard = resource.getrlimit(resource.RLIMIT_NOFILE)\n",
    "        print(f\"현재 파일 핸들 제한: {soft} (최대: {hard})\")\n",
    "        # 가능한 최대값으로 설정\n",
    "        resource.setrlimit(resource.RLIMIT_NOFILE, (min(4096, hard), hard))\n",
    "        print(f\"조정된 파일 핸들 제한: {min(4096, hard)}\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(\"라이브러리 import 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 설정 및 Config 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 환경 설정 완료\n",
      "   카테고리 수: 17개\n"
     ]
    }
   ],
   "source": [
    "# ChromaDB 저장 경로\n",
    "CHROMA_BASE_DIR = r\"C:\\Capstone\\Chroma_db\"\n",
    "\n",
    "# API Keys\n",
    "UPSTAGE_API_KEY = os.getenv('UPSTAGE_API_KEY', 'up_2KGGBmZpBmlePxUyk3ouWBf9iqOmJ')\n",
    "ANTHROPIC_API_KEY = os.getenv('ANTHROPIC_API_KEY', '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')\n",
    "\n",
    "# category_config.json 로드\n",
    "CATEGORY_CONFIG_PATH = r\"C:\\Capstone\\search2\\category_config.json\"\n",
    "\n",
    "with open(CATEGORY_CONFIG_PATH, 'r', encoding='utf-8') as f:\n",
    "    CATEGORY_CONFIG = json.load(f)\n",
    "\n",
    "print(\"✅ 환경 설정 완료\")\n",
    "print(f\"   카테고리 수: {len(CATEGORY_CONFIG)}개\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 메타데이터 추출기 (LLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MetadataExtractor 클래스 정의 완료 (직업 15개 보기 정규화 추가)\n"
     ]
    }
   ],
   "source": [
    "class MetadataExtractor:\n",
    "    \"\"\"LLM으로 검색 쿼리에서 메타데이터 추출\"\"\"\n",
    "\n",
    "    def __init__(self, api_key: str):\n",
    "        self.client = Anthropic(api_key=api_key)\n",
    "        self.model = \"claude-sonnet-4-5-20250929\"\n",
    "\n",
    "    def extract(self, query: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        자연어 쿼리에서 구조화된 메타데이터 추출 (다중 값/범위 지원)\n",
    "\n",
    "        Args:\n",
    "            query: 검색 쿼리 (예: \"서울 강남구 27세 기혼 남자\")\n",
    "\n",
    "        Returns:\n",
    "            메타데이터 딕셔너리 (예: {\"지역\": \"서울\", \"지역구\": \"강남구\", \"나이\": 27, \"연령대\": \"20대\", \"성별\": \"남\", \"결혼여부\": \"기혼\"})\n",
    "        \"\"\"\n",
    "        prompt = f\"\"\"당신은 자연어 질의에서 메타데이터를 추출하는 전문가입니다.\n",
    "\n",
    "자연어 질의를 분석하여 모든 정보를 메타데이터로 추출하세요.\n",
    "\n",
    "=== 추출 규칙 ===\n",
    "\n",
    "1. **지역 관련 정보는 모두 \"지역\" 키로 추출** (매우 중요!)\n",
    "   - 국내 지역: \"서울\", \"경기\", \"부산\" 등 → \"지역\" 키 사용\n",
    "   - 지역구: \"강남구\", \"서초구\", \"양산시\" 등 → \"지역구\" 키로 별도 추출\n",
    "   - 해외 관련: \"해외\", \"외국\", \"국외\", \"외국인\", \"해외 거주\" 등 → \"지역\": \"해외\"\n",
    "   - \"거주지\", \"거주\", \"사는 곳\" 등의 키 사용 금지\n",
    "   - 반드시 \"지역\" 키만 사용할 것\n",
    "\n",
    "2. **다중 값은 리스트로 표현**\n",
    "   - \"서울, 경기\" → \"지역\": [\"서울\", \"경기\"]\n",
    "   - \"서울 또는 경기\" → \"지역\": [\"서울\", \"경기\"]\n",
    "   - \"20대, 30대\" → \"연령대\": [\"20대\", \"30대\"]\n",
    "\n",
    "3. **나이와 연령대 모두 추출**\n",
    "   - \"27세\" → \"나이\": 27, \"연령대\": \"20대\"\n",
    "   - \"35세\" → \"나이\": 35, \"연령대\": \"30대\"\n",
    "   - 연령대만 있으면: \"20대\" → \"연령대\": \"20대\"\n",
    "\n",
    "4. **범위는 연령대 리스트로 변환**\n",
    "   - \"10~20세\" → \"연령대\": [\"10대\", \"20대\"]\n",
    "   - \"20대~30대\" → \"연령대\": [\"20대\", \"30대\"]\n",
    "   - **\"40세 이하\" → \"연령대\": [\"10대\", \"20대\", \"30대\", \"40대\"]** ⭐\n",
    "   - **\"40대 이하\" → \"연령대\": [\"10대\", \"20대\", \"30대\", \"40대\"]** ⭐\n",
    "\n",
    "5. **성별 정규화**\n",
    "   - \"남성\", \"남자\", \"남\" → \"남자\"\n",
    "   - \"여성\", \"여자\", \"여\" → \"여자\"\n",
    "\n",
    "6. **결혼여부 추출** (⭐⭐⭐ 가장 중요! 절대 지켜야 함!)\n",
    "   - 반드시 \"결혼여부\" 키만 사용 (다른 키 사용 절대 금지!)\n",
    "   - \"기혼\", \"결혼한\", \"결혼한 사람\", \"결혼함\" → \"결혼여부\": \"기혼\"\n",
    "   - \"미혼\", \"미혼인\", \"결혼 안한\" → \"결혼여부\": \"미혼\"\n",
    "   - ⚠️ 절대 사용 금지 키: \"결혼상태\", \"결혼상황\", \"혼인\", \"결혼\" (이런 키 쓰면 안됨!)\n",
    "\n",
    "7. **자녀수/가족수 추출** (⭐⭐⭐ 매우 중요!)\n",
    "   - 반드시 \"자녀수\", \"가족수\" 키만 사용 (다른 키 사용 절대 금지!)\n",
    "   - \"자녀 2명\" → \"자녀수\": 2\n",
    "   - \"가족 3명\", \"가족 구성 3명\" → \"가족수\": 3\n",
    "   - **\"혼자 사는\", \"1인 가구\", \"독거\", \"혼자 거주\" → \"가족수\": 1** ⭐\n",
    "   - **\"2인 가구\" → \"가족수\": 2** ⭐\n",
    "   - ⚠️ 절대 사용 금지 키: \"가구형태\", \"가구유형\", \"거주형태\" (이런 키 쓰면 안됨!)\n",
    "\n",
    "8. **학력 추출**\n",
    "   - \"고졸\", \"고등학교 졸업\" → \"학력\": \"고등학교 졸업 이하\"\n",
    "   - \"대학생\", \"대학 재학\" → \"학력\": \"대학교 재학\"\n",
    "   - \"대졸\", \"대학교 졸업\" → \"학력\": \"대학교 졸업\"\n",
    "   - \"대학원\", \"석사\", \"박사\" → \"학력\": \"대학원 재학/졸업 이상\"\n",
    "\n",
    "9. **직업 추출** (⭐ 중요: 정규화하여 추출)\n",
    "   - \"전문직\", \"의사\", \"간호사\", \"변호사\" 등 → \"직업\": \"전문직\"\n",
    "   - \"교직\", \"교수\", \"교사\", \"강사\" → \"직업\": \"교직\"\n",
    "   - \"경영관리직\", \"사장\", \"임원\" → \"직업\": \"경영관리직\"\n",
    "   - \"사무직\", \"공무원\", \"직장인\" → \"직업\": \"사무직\"\n",
    "   - \"자영업\", \"사업\" → \"직업\": \"자영업\"\n",
    "   - \"판매직\", \"세일즈\" → \"직업\": \"판매직\"\n",
    "   - \"서비스직\" → \"직업\": \"서비스직\"\n",
    "   - \"생산직\", \"노무직\" → \"직업\": \"생산/노무직\"\n",
    "   - \"기능직\", \"기술직\" → \"직업\": \"기능직\"\n",
    "   - \"농업\", \"임업\", \"축산업\", \"수산업\" → \"직업\": \"농업/임업/축산업/광업/수산업\"\n",
    "   - \"임대업\" → \"직업\": \"임대업\"\n",
    "   - \"학생\", \"중학생\", \"고등학생\" → \"직업\": \"중/고등학생\"\n",
    "   - \"대학생\", \"대학원생\" → \"직업\": \"대학생/대학원생\"\n",
    "   - \"전업주부\", \"주부\" → \"직업\": \"전업주부\"\n",
    "   - \"퇴직\", \"은퇴\", \"연금생활자\" → \"직업\": \"퇴직/연금생활자\"\n",
    "   - \"일하는\", \"근무하는\", \"종사하는\" 등의 표현에서 직업 추출\n",
    "\n",
    "10. **모호한 표현 해석**\n",
    "   - \"젊은층\", \"청년\" → \"연령대\": [\"20대\", \"30대\"]\n",
    "   - \"중년층\", \"장년\" → \"연령대\": [\"40대\", \"50대\"]\n",
    "   - \"MZ세대\" → \"연령대\": [\"20대\", \"30대\"]\n",
    "\n",
    "11. **전국/전체는 빈 값으로 처리**\n",
    "   - \"전국\" → 지역 필드 생성하지 않음\n",
    "\n",
    "12. **수도권 특별 처리**\n",
    "   - \"수도권\" → \"지역\": [\"서울\", \"경기\", \"인천\"]\n",
    "\n",
    "=== 예시 ===\n",
    "\n",
    "입력: \"서울 강남구 27세 기혼 남자\"\n",
    "출력:\n",
    "{{\n",
    "    \"지역\": \"서울\",\n",
    "    \"지역구\": \"강남구\",\n",
    "    \"나이\": 27,\n",
    "    \"연령대\": \"20대\",\n",
    "    \"결혼여부\": \"기혼\",\n",
    "    \"성별\": \"남자\"\n",
    "}}\n",
    "\n",
    "입력: \"전문직에서 일하는 사람\"\n",
    "출력:\n",
    "{{\n",
    "    \"직업\": \"전문직\"\n",
    "}}\n",
    "\n",
    "입력: \"의사 선생님\"\n",
    "출력:\n",
    "{{\n",
    "    \"직업\": \"전문직\"\n",
    "}}\n",
    "\n",
    "입력: \"교사로 근무하는 30대\"\n",
    "출력:\n",
    "{{\n",
    "    \"직업\": \"교직\",\n",
    "    \"연령대\": \"30대\"\n",
    "}}\n",
    "\n",
    "입력: \"회사원\"\n",
    "출력:\n",
    "{{\n",
    "    \"직업\": \"사무직\"\n",
    "}}\n",
    "\n",
    "입력: \"대학생\"\n",
    "출력:\n",
    "{{\n",
    "    \"직업\": \"대학생/대학원생\"\n",
    "}}\n",
    "\n",
    "질의: {query}\n",
    "\n",
    "⚠️⚠️⚠️ 필수 주의사항:\n",
    "- 직업은 15개 보기 중 하나로 정규화하여 추출 (정확히 매칭)\n",
    "- 결혼 관련 정보는 반드시 \"결혼여부\" 키만 사용!\n",
    "- 가족/가구 관련 정보는 반드시 \"가족수\" 키만 사용!\n",
    "- \"혼자 사는\", \"1인 가구\", \"독거\" 등은 모두 \"가족수\": 1로 변환!\n",
    "- \"XX세 이하\"는 해당 연령대까지 모든 연령대를 리스트로 반환\n",
    "\n",
    "JSON만 반환하세요. 다른 설명은 하지 마세요.\n",
    "\"\"\"\n",
    "\n",
    "        try:\n",
    "            response = self.client.messages.create(\n",
    "                model=self.model,\n",
    "                max_tokens=1024,\n",
    "                temperature=0.0,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "            )\n",
    "\n",
    "            text = response.content[0].text\n",
    "            \n",
    "            # JSON 파싱 (코드블록 제거)\n",
    "            if '```json' in text:\n",
    "                json_text = text.split('```json')[1].split('```')[0].strip()\n",
    "            elif '```' in text:\n",
    "                json_text = text.split('```')[1].strip()\n",
    "            else:\n",
    "                json_text = text.strip()\n",
    "            \n",
    "            metadata = json.loads(json_text)\n",
    "            \n",
    "            # ===== 후처리: 키 이름 및 값 정규화 =====\n",
    "            print(f\"\\n[메타데이터 추출 - LLM 원본] {metadata}\")\n",
    "\n",
    "            # 1. 지역 키 정규화\n",
    "            if \"거주지\" in metadata and \"지역\" not in metadata:\n",
    "                metadata[\"지역\"] = metadata.pop(\"거주지\")\n",
    "            if \"거주\" in metadata and \"지역\" not in metadata:\n",
    "                metadata[\"지역\"] = metadata.pop(\"거주\")\n",
    "\n",
    "            # 2. 결혼여부 키 정규화\n",
    "            marriage_keys = [\"결혼상태\", \"결혼상황\", \"혼인\", \"혼인여부\", \"결혼\"]\n",
    "            for key in marriage_keys:\n",
    "                if key in metadata and \"결혼여부\" not in metadata:\n",
    "                    metadata[\"결혼여부\"] = metadata.pop(key)\n",
    "                    print(f\"   [후처리] '{key}' → '결혼여부'로 키 정규화\")\n",
    "                    break\n",
    "\n",
    "            # 3. 결혼여부 값 정규화\n",
    "            if \"결혼여부\" in metadata:\n",
    "                marriage = metadata[\"결혼여부\"]\n",
    "                if isinstance(marriage, str):\n",
    "                    original = marriage\n",
    "                    if marriage in [\"결혼함\", \"결혼\", \"결혼한\", \"기혼자\", \"유부남\", \"유부녀\"]:\n",
    "                        metadata[\"결혼여부\"] = \"기혼\"\n",
    "                        print(f\"   [후처리] 결혼여부 값 '{original}' → '기혼'으로 정규화\")\n",
    "                    elif marriage in [\"미혼인\", \"결혼 안함\", \"미혼자\"]:\n",
    "                        metadata[\"결혼여부\"] = \"미혼\"\n",
    "                        print(f\"   [후처리] 결혼여부 값 '{original}' → '미혼'으로 정규화\")\n",
    "\n",
    "            # 4. 가족수 키 정규화\n",
    "            household_keys = [\"가구형태\", \"가구유형\", \"거주형태\", \"가구구성\"]\n",
    "            for key in household_keys:\n",
    "                if key in metadata and \"가족수\" not in metadata:\n",
    "                    value = metadata.pop(key)\n",
    "                    if isinstance(value, str):\n",
    "                        import re\n",
    "                        match = re.search(r'(\\d+)인', value)\n",
    "                        if match:\n",
    "                            metadata[\"가족수\"] = int(match.group(1))\n",
    "                            print(f\"   [후처리] '{key}: {value}' → '가족수: {metadata['가족수']}'로 변환\")\n",
    "                    break\n",
    "\n",
    "            # 5. ⭐ 직업 정규화 (15개 보기로 매핑)\n",
    "            if \"직업\" in metadata:\n",
    "                job = metadata[\"직업\"]\n",
    "                job_normalized = self._normalize_job(job)\n",
    "                if job_normalized != job:\n",
    "                    print(f\"   [후처리] 직업 '{job}' → '{job_normalized}'로 정규화\")\n",
    "                    metadata[\"직업\"] = job_normalized\n",
    "\n",
    "            # 6. 성별 정규화\n",
    "            if \"성별\" in metadata:\n",
    "                gender = metadata[\"성별\"]\n",
    "                if isinstance(gender, str):\n",
    "                    if gender in [\"남성\", \"남자\", \"male\", \"M\"]:\n",
    "                        metadata[\"성별\"] = \"남\"\n",
    "                    elif gender in [\"여성\", \"여자\", \"female\", \"F\"]:\n",
    "                        metadata[\"성별\"] = \"여\"\n",
    "                elif isinstance(gender, list):\n",
    "                    normalized = []\n",
    "                    for g in gender:\n",
    "                        if g in [\"남성\", \"남자\", \"male\", \"M\"]:\n",
    "                            normalized.append(\"남\")\n",
    "                        elif g in [\"여성\", \"여자\", \"female\", \"F\"]:\n",
    "                            normalized.append(\"여\")\n",
    "                        else:\n",
    "                            normalized.append(g)\n",
    "                    metadata[\"성별\"] = normalized\n",
    "            \n",
    "            print(f\"[메타데이터 추출 - 최종] {metadata}\")\n",
    "            return metadata\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] 메타데이터 추출 실패: {e}\")\n",
    "            return {}\n",
    "\n",
    "    def _normalize_job(self, job: str) -> str:\n",
    "        \"\"\"직업을 15개 보기 중 하나로 정규화\"\"\"\n",
    "        job_lower = job.lower()\n",
    "        \n",
    "        # 15개 보기 매핑\n",
    "        if any(kw in job_lower for kw in [\"전문직\", \"의사\", \"간호사\", \"변호사\", \"회계사\", \"예술가\", \"종교인\", \"엔지니어\", \"프로그래머\", \"기술사\"]):\n",
    "            return \"전문직\"\n",
    "        elif any(kw in job_lower for kw in [\"교직\", \"교수\", \"교사\", \"강사\"]):\n",
    "            return \"교직\"\n",
    "        elif any(kw in job_lower for kw in [\"경영\", \"관리직\", \"사장\", \"임원\", \"대기업 간부\", \"고위 공무원\"]):\n",
    "            return \"경영/관리직\"\n",
    "        elif any(kw in job_lower for kw in [\"사무직\", \"공무원\", \"회사원\", \"직장인\", \"은행원\", \"군인\", \"경찰\", \"소방관\"]):\n",
    "            return \"사무직\"\n",
    "        elif any(kw in job_lower for kw in [\"자영업\", \"사업\"]):\n",
    "            return \"자영업\"\n",
    "        elif any(kw in job_lower for kw in [\"판매직\", \"세일즈\", \"보험설계사\", \"영업\"]):\n",
    "            return \"판매직\"\n",
    "        elif any(kw in job_lower for kw in [\"서비스직\", \"미용\", \"요식업\"]):\n",
    "            return \"서비스직\"\n",
    "        elif any(kw in job_lower for kw in [\"생산직\", \"노무직\", \"운전\", \"현장직\"]):\n",
    "            return \"생산/노무직\"\n",
    "        elif any(kw in job_lower for kw in [\"기능직\", \"기술직\", \"제빵\", \"목수\", \"전기공\", \"정비사\", \"배관공\"]):\n",
    "            return \"기능직\"\n",
    "        elif any(kw in job_lower for kw in [\"농업\", \"임업\", \"축산\", \"수산\", \"광업\"]):\n",
    "            return \"농업/임업/축산업/광업/수산업\"\n",
    "        elif \"임대\" in job_lower:\n",
    "            return \"임대업\"\n",
    "        elif any(kw in job_lower for kw in [\"중학생\", \"고등학생\", \"학생\"]) and \"대학\" not in job_lower:\n",
    "            return \"중/고등학생\"\n",
    "        elif any(kw in job_lower for kw in [\"대학생\", \"대학원생\"]):\n",
    "            return \"대학생/대학원생\"\n",
    "        elif any(kw in job_lower for kw in [\"주부\", \"전업주부\"]):\n",
    "            return \"전업주부\"\n",
    "        elif any(kw in job_lower for kw in [\"퇴직\", \"은퇴\", \"연금\"]):\n",
    "            return \"퇴직/연금생활자\"\n",
    "        \n",
    "        # 15개 보기에 해당하지 않으면 그대로 반환\n",
    "        return job\n",
    "\n",
    "\n",
    "print(\"MetadataExtractor 클래스 정의 완료 (직업 15개 보기 정규화 추가)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 메타데이터 필터 추출기\n",
    "\n",
    "카테고리별로 사용할 메타데이터 필터를 추출합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ MetadataFilterExtractor 클래스 정의 완료 (직업/소득 필터 제거, 벡터 검색으로만 처리)\n"
     ]
    }
   ],
   "source": [
    "class MetadataFilterExtractor:\n",
    "    \"\"\"LLM으로 카테고리별 메타데이터 필터 추출 및 정규화 (복수 값 지원)\"\"\"\n",
    "\n",
    "    def __init__(self, api_key: str):\n",
    "        self.client = Anthropic(api_key=api_key)\n",
    "        self.model = \"claude-sonnet-4-5-20250929\"\n",
    "\n",
    "    def extract_filters(self, metadata: Dict[str, Any], category: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        특정 카테고리에 적용할 메타데이터 필터를 추출 및 정규화\n",
    "        \n",
    "        Args:\n",
    "            metadata: 전체 메타데이터\n",
    "            category: 카테고리명 (예: \"기본정보\")\n",
    "        \n",
    "        Returns:\n",
    "            정규화된 메타데이터 필터 (복수 값 포함)\n",
    "            예: {\"지역\": [\"서울\", \"경기\"], \"연령대\": [\"10대\", \"20대\"], \"성별\": \"남\", \"결혼여부\": \"기혼\"}\n",
    "        \"\"\"\n",
    "        # 카테고리별 메타데이터 매핑\n",
    "        # ⚠️ 주의: \"직업\", \"소득\"은 ChromaDB에 메타데이터로 저장되지 않았으므로 제외\n",
    "        # → 벡터 유사도 검색으로만 처리\n",
    "        CATEGORY_METADATA_MAPPING = {\n",
    "            \"기본정보\": [\"지역\", \"지역구\", \"연령대\", \"성별\", \"나이\", \"결혼여부\", \"자녀수\", \"가족수\", \"학력\"],\n",
    "            \"직업소득\": [\"학력\"],  # ⭐ \"직업\", \"소득\" 제거 (벡터 검색으로만 처리)\n",
    "            \"건강\": [\"활동\", \"운동\"],\n",
    "        }\n",
    "        \n",
    "        applicable_keys = CATEGORY_METADATA_MAPPING.get(category, [])\n",
    "        \n",
    "        if not applicable_keys:\n",
    "            return {}\n",
    "        \n",
    "        # 해당 카테고리에 적용 가능한 메타데이터만 추출\n",
    "        relevant_metadata = {}\n",
    "        for key in applicable_keys:\n",
    "            if key in metadata:\n",
    "                relevant_metadata[key] = metadata[key]\n",
    "        \n",
    "        if not relevant_metadata:\n",
    "            return {}\n",
    "        \n",
    "        # ⭐ 복수 값 보존을 위해 rule-based 정규화 직접 사용\n",
    "        # LLM이 리스트를 단일 값으로 변환하는 문제를 해결\n",
    "        normalized_filter = self._rule_based_normalize(relevant_metadata)\n",
    "        \n",
    "        print(f\"   [{category}] 필터 정규화: {relevant_metadata} → {normalized_filter}\")\n",
    "        return normalized_filter\n",
    "\n",
    "    def _rule_based_normalize(self, metadata: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"규칙 기반 정규화 (복수 값 지원, 새 필터 포함)\"\"\"\n",
    "        filter_dict = {}\n",
    "        \n",
    "        # 지역명 매핑\n",
    "        region_mapping = {\n",
    "            \"서울특별시\": \"서울\", \"서울시\": \"서울\",\n",
    "            \"부산광역시\": \"부산\", \"부산시\": \"부산\",\n",
    "            \"대구광역시\": \"대구\", \"대구시\": \"대구\",\n",
    "            \"인천광역시\": \"인천\", \"인천시\": \"인천\",\n",
    "            \"광주광역시\": \"광주\", \"광주시\": \"광주\",\n",
    "            \"대전광역시\": \"대전\", \"대전시\": \"대전\",\n",
    "            \"울산광역시\": \"울산\", \"울산시\": \"울산\",\n",
    "            \"세종특별자치시\": \"세종\", \"세종시\": \"세종\",\n",
    "            \"경기도\": \"경기\", \"강원도\": \"강원\", \"강원특별자치도\": \"강원\",\n",
    "            \"충청북도\": \"충북\", \"충북도\": \"충북\",\n",
    "            \"충청남도\": \"충남\", \"충남도\": \"충남\",\n",
    "            \"전라북도\": \"전북\", \"전북도\": \"전북\", \"전북특별자치도\": \"전북\",\n",
    "            \"전라남도\": \"전남\", \"전남도\": \"전남\",\n",
    "            \"경상북도\": \"경북\", \"경북도\": \"경북\",\n",
    "            \"경상남도\": \"경남\", \"경남도\": \"경남\",\n",
    "            \"제주특별자치도\": \"제주\", \"제주도\": \"제주\", \"제주시\": \"제주\",\n",
    "            \"해외\": \"해외\", \"외국\": \"해외\", \"국외\": \"해외\",\n",
    "        }\n",
    "        \n",
    "        # 학력 매핑 (텍스트 정규화)\n",
    "        education_mapping = {\n",
    "            \"고졸\": \"고등학교 졸업 이하\",\n",
    "            \"고등학교\": \"고등학교 졸업 이하\",\n",
    "            \"고등학교 졸업\": \"고등학교 졸업 이하\",\n",
    "            \"대학생\": \"대학교 재학\",\n",
    "            \"대학 재학\": \"대학교 재학\",\n",
    "            \"대학교 재학\": \"대학교 재학\",\n",
    "            \"대재\": \"대학교 재학\",\n",
    "            \"대졸\": \"대학교 졸업\",\n",
    "            \"대학 졸업\": \"대학교 졸업\",\n",
    "            \"대학교 졸업\": \"대학교 졸업\",\n",
    "            \"대학원\": \"대학원 재학/졸업 이상\",\n",
    "            \"석사\": \"대학원 재학/졸업 이상\",\n",
    "            \"박사\": \"대학원 재학/졸업 이상\",\n",
    "            \"대학원 재학\": \"대학원 재학/졸업 이상\",\n",
    "            \"대학원 졸업\": \"대학원 재학/졸업 이상\",\n",
    "        }\n",
    "        \n",
    "        for key, value in metadata.items():\n",
    "            if not value or value == '':\n",
    "                continue\n",
    "            \n",
    "            # 리스트인 경우 모든 값을 정규화\n",
    "            if isinstance(value, list):\n",
    "                normalized_list = []\n",
    "                for item in value:\n",
    "                    if key == \"지역\":\n",
    "                        normalized_list.append(region_mapping.get(item, item))\n",
    "                    elif key == \"성별\":\n",
    "                        if item in [\"남성\", \"남자\", \"male\", \"M\"]:\n",
    "                            normalized_list.append(\"남\")\n",
    "                        elif item in [\"여성\", \"여자\", \"female\", \"F\"]:\n",
    "                            normalized_list.append(\"여\")\n",
    "                        else:\n",
    "                            normalized_list.append(item)\n",
    "                    elif key == \"학력\":\n",
    "                        normalized_list.append(education_mapping.get(item, item))\n",
    "                    else:\n",
    "                        normalized_list.append(item)\n",
    "                filter_dict[key] = normalized_list\n",
    "            else:\n",
    "                # 단일 값인 경우\n",
    "                if key == \"지역\":\n",
    "                    value = region_mapping.get(value, value)\n",
    "                elif key == \"성별\":\n",
    "                    if value in [\"남성\", \"남자\", \"male\", \"M\"]:\n",
    "                        value = \"남\"\n",
    "                    elif value in [\"여성\", \"여자\", \"female\", \"F\"]:\n",
    "                        value = \"여\"\n",
    "                elif key == \"학력\":\n",
    "                    value = education_mapping.get(value, value)\n",
    "                elif key == \"결혼여부\":\n",
    "                    # 결혼여부 정규화: \"기혼\", \"미혼\", \"기타\" 중 하나\n",
    "                    if value in [\"결혼\", \"결혼한\", \"기혼자\"]:\n",
    "                        value = \"기혼\"\n",
    "                    elif value in [\"미혼자\", \"결혼 안한\"]:\n",
    "                        value = \"미혼\"\n",
    "                # 나이, 자녀수, 가족수는 숫자 그대로 유지\n",
    "                elif key in [\"나이\", \"자녀수\", \"가족수\"]:\n",
    "                    # 문자열이면 int로 변환 시도\n",
    "                    if isinstance(value, str) and value.isdigit():\n",
    "                        value = int(value)\n",
    "                \n",
    "                filter_dict[key] = value\n",
    "        \n",
    "        return filter_dict\n",
    "\n",
    "\n",
    "print(\"✅ MetadataFilterExtractor 클래스 정의 완료 (직업/소득 필터 제거, 벡터 검색으로만 처리)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 카테고리 분류기 (간소화)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CategoryClassifier 클래스 정의 완료\n"
     ]
    }
   ],
   "source": [
    "class CategoryClassifier:\n",
    "    \"\"\"LLM으로 메타데이터를 카테고리별로 분류 (panel_search.ipynb와 동일)\"\"\"\n",
    "\n",
    "    def __init__(self, category_config: Dict[str, Any], api_key: str):\n",
    "        self.category_config = category_config\n",
    "        self.client = Anthropic(api_key=api_key)\n",
    "        self.model = \"claude-sonnet-4-5-20250929\"\n",
    "\n",
    "    def _build_prompt(self, metadata: Dict[str, Any]) -> str:\n",
    "        \"\"\"카테고리 설명 + 메타데이터를 포함한 LLM용 프롬프트 생성\"\"\"\n",
    "        \n",
    "        # 카테고리 설명\n",
    "        category_desc = \"\\n\".join([\n",
    "            f\"- {cat}: {info.get('description', ', '.join(info.get('keywords', [])))}\"\n",
    "            for cat, info in self.category_config.items()\n",
    "        ])\n",
    "\n",
    "        # 키: 값 형식으로 메타데이터 나열\n",
    "        meta_lines = [f\"{k}: {v}\" for k, v in metadata.items()]\n",
    "        meta_text = \"\\n\".join(meta_lines)\n",
    "\n",
    "        # 사용 가능한 키 이름 목록\n",
    "        meta_keys = \", \".join(metadata.keys())\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "당신은 메타데이터를 카테고리로 분류하는 전문가입니다.\n",
    "\n",
    "다음은 사용할 수 있는 카테고리 목록과 설명입니다:\n",
    "{category_desc}\n",
    "\n",
    "다음은 분류해야 할 메타데이터입니다 (키: 값 형식):\n",
    "{meta_text}\n",
    "\n",
    "이때 사용할 수 있는 '키 이름' 목록은 다음과 같습니다:\n",
    "{meta_keys}\n",
    "\n",
    "당신의 작업:\n",
    "각 메타데이터의 \"키 이름\"을 정확히 하나의 카테고리에 배정하세요.\n",
    "\n",
    "출력은 반드시 아래 JSON 형식을 따라야 합니다 (예시는 구조만 참고):\n",
    "\n",
    "{{\n",
    "  \"기본정보\": [\"지역\", \"성별\"],\n",
    "  \"미디어\": [\"조건\"],\n",
    "  \"스트레스\": [],\n",
    "  \"기타\": []\n",
    "}}\n",
    "\n",
    "카테고리 작업 규칙:\n",
    "1. 각 메타데이터 키는 반드시 1개의 카테고리에만 속해야 합니다.\n",
    "2. \"키: 값\" 전체를 쓰지 말고, 오직 '키 이름'만 써야 합니다.\n",
    "3. 값(value)이나 새로운 문장, 설명문, 여분의 텍스트는 절대 포함하지 마세요.\n",
    "4. 반드시 위에 나열된 키 이름만 사용하세요. 값이나 문장을 JSON에 넣으면 안 됩니다.\n",
    "\n",
    "JSON만 반환하세요:\n",
    "\"\"\"\n",
    "        return prompt.strip()\n",
    "\n",
    "    def classify(self, metadata: Dict[str, Any]) -> Dict[str, List[str]]:\n",
    "        \"\"\"\n",
    "        메타데이터를 LLM을 통해 카테고리별로 분류\n",
    "\n",
    "        Returns:\n",
    "            {\"카테고리명\": [\"키: 값\", \"키: 값\", ...]}\n",
    "        \"\"\"\n",
    "        if not metadata:\n",
    "            return {}\n",
    "\n",
    "        prompt = self._build_prompt(metadata)\n",
    "\n",
    "        try:\n",
    "            # LLM 호출\n",
    "            response = self.client.messages.create(\n",
    "                model=self.model,\n",
    "                max_tokens=1024,\n",
    "                temperature=0.2,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "            )\n",
    "            \n",
    "            raw_output = response.content[0].text.strip()\n",
    "\n",
    "            # JSON 파싱\n",
    "            mapping_tokens = self._parse_llm_output(raw_output)\n",
    "\n",
    "            # 토큰들을 실제 메타데이터 키로 매핑\n",
    "            categorized: Dict[str, List[str]] = {}\n",
    "            used_keys: set = set()\n",
    "\n",
    "            for cat, tokens in mapping_tokens.items():\n",
    "                for token in tokens:\n",
    "                    meta_key = self._match_llm_token_to_key(token, metadata, used_keys)\n",
    "                    if meta_key is None:\n",
    "                        continue\n",
    "                    categorized.setdefault(cat, []).append(f\"{meta_key}: {metadata[meta_key]}\")\n",
    "                    used_keys.add(meta_key)\n",
    "\n",
    "            # 아무 것도 매핑 안 됐으면 rule-based로 폴백\n",
    "            if not categorized:\n",
    "                print(\"[WARN] LLM 기반 분류 결과 매핑 실패 -> rule-based로 대체\")\n",
    "                return self._rule_based_classify(metadata)\n",
    "\n",
    "            print(f\"\\n[카테고리 분류] {dict(categorized)}\")\n",
    "            return categorized\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] LLM 분류/파싱 실패 ({e}) -> rule-based로 대체\")\n",
    "            return self._rule_based_classify(metadata)\n",
    "\n",
    "    def _parse_llm_output(self, raw_output: str) -> Dict[str, List[str]]:\n",
    "        \"\"\"LLM이 반환한 raw 문자열을 JSON으로 파싱\"\"\"\n",
    "        # 코드블록 제거\n",
    "        if \"```json\" in raw_output:\n",
    "            try:\n",
    "                raw_output = raw_output.split(\"```json\", 1)[1].split(\"```\", 1)[0].strip()\n",
    "            except:\n",
    "                pass\n",
    "        elif \"```\" in raw_output:\n",
    "            try:\n",
    "                raw_output = raw_output.split(\"```\", 1)[1].split(\"```\", 1)[0].strip()\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        # JSON 파싱\n",
    "        parsed = json.loads(raw_output)\n",
    "\n",
    "        # 값들을 전부 리스트[str] 형태로 정규화\n",
    "        mapping_tokens: Dict[str, List[str]] = {}\n",
    "        for cat, vals in parsed.items():\n",
    "            if isinstance(vals, list):\n",
    "                tokens = [str(v).strip() for v in vals if str(v).strip()]\n",
    "            elif isinstance(vals, str):\n",
    "                tokens = [vals.strip()] if vals.strip() else []\n",
    "            elif isinstance(vals, dict):\n",
    "                tokens = [str(k).strip() for k in vals.keys() if str(k).strip()]\n",
    "            else:\n",
    "                tokens = [str(vals).strip()]\n",
    "\n",
    "            if tokens:\n",
    "                mapping_tokens[cat] = tokens\n",
    "\n",
    "        return mapping_tokens\n",
    "\n",
    "    def _match_llm_token_to_key(self, token: str, metadata: Dict[str, Any], used_keys: set) -> Optional[str]:\n",
    "        \"\"\"LLM이 JSON에 넣은 토큰을 실제 메타데이터 키로 매핑\"\"\"\n",
    "        t = token.strip()\n",
    "        if not t:\n",
    "            return None\n",
    "\n",
    "        # 1) 정확히 같은 키 이름\n",
    "        if t in metadata and t not in used_keys:\n",
    "            return t\n",
    "\n",
    "        # 2) \"키: 값\" 형식으로 온 경우\n",
    "        if \":\" in t:\n",
    "            left = t.split(\":\", 1)[0].strip()\n",
    "            if left in metadata and left not in used_keys:\n",
    "                return left\n",
    "\n",
    "        # 3) 값 문자열과의 유사 매칭\n",
    "        t_lower = t.lower()\n",
    "        for meta_key, meta_value in metadata.items():\n",
    "            if meta_key in used_keys:\n",
    "                continue\n",
    "            v_lower = str(meta_value).lower()\n",
    "\n",
    "            if t_lower in v_lower or v_lower in t_lower:\n",
    "                return meta_key\n",
    "\n",
    "        return None\n",
    "\n",
    "    def _rule_based_classify(self, metadata: Dict[str, Any]) -> Dict[str, List[str]]:\n",
    "        \"\"\"백업용: 기존 키워드 기반 규칙 분류\"\"\"\n",
    "        categorized: Dict[str, List[str]] = {}\n",
    "        for meta_key, meta_value in metadata.items():\n",
    "            matched_categories = self._match_categories(meta_value)\n",
    "            for category in matched_categories:\n",
    "                categorized.setdefault(category, []).append(f\"{meta_key}: {meta_value}\")\n",
    "        return categorized\n",
    "\n",
    "    def _match_categories(self, value) -> List[str]:\n",
    "        matched: List[str] = []\n",
    "        if isinstance(value, list):\n",
    "            for item in value:\n",
    "                if isinstance(item, str):\n",
    "                    matched.extend(self._match_single_value(item))\n",
    "        elif isinstance(value, str):\n",
    "            matched = self._match_single_value(value)\n",
    "        return list(set(matched))\n",
    "\n",
    "    def _match_single_value(self, value: str) -> List[str]:\n",
    "        matched: List[str] = []\n",
    "        value_lower = value.lower()\n",
    "        for category_name, category_info in self.category_config.items():\n",
    "            for keyword in category_info.get(\"keywords\", []):\n",
    "                if keyword.lower() in value_lower:\n",
    "                    matched.append(category_name)\n",
    "                    break\n",
    "        return matched\n",
    "\n",
    "\n",
    "print(\"CategoryClassifier 클래스 정의 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 텍스트 생성기 (LLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CategoryTextGenerator 클래스 정의 완료 (ChromaDB 저장 형식 + 직업 상세 설명)\n"
     ]
    }
   ],
   "source": [
    "class CategoryTextGenerator:\n",
    "    \"\"\"카테고리별로 자연어 텍스트 생성 (ChromaDB 저장 형식에 맞춤)\"\"\"\n",
    "\n",
    "    def __init__(self, api_key: str):\n",
    "        self.client = Anthropic(api_key=api_key)\n",
    "        self.model = \"claude-sonnet-4-5-20250929\"\n",
    "\n",
    "    def generate(self, category: str, metadata_items: List[str]) -> str:\n",
    "        \"\"\"\n",
    "        카테고리별 자연어 텍스트 생성 (ChromaDB 실제 저장 형식 참고)\n",
    "        \n",
    "        ⭐ 중요: ChromaDB에 저장된 텍스트 형식을 최대한 유사하게 생성해야 벡터 유사도가 높아짐\n",
    "        \"\"\"\n",
    "        if not metadata_items:\n",
    "            return \"\"\n",
    "\n",
    "        # 메타데이터를 딕셔너리로 파싱\n",
    "        metadata_dict = {}\n",
    "        for item in metadata_items:\n",
    "            if \": \" in item:\n",
    "                key, value = item.split(\": \", 1)\n",
    "                metadata_dict[key] = value\n",
    "\n",
    "        try:\n",
    "            # 카테고리별 템플릿 기반 텍스트 생성\n",
    "            text = self._generate_by_template(category, metadata_dict)\n",
    "            \n",
    "            if text:\n",
    "                print(f\"\\n[{category}] {text[:80]}...\")\n",
    "                return text\n",
    "            \n",
    "            # 템플릿이 없으면 LLM으로 생성\n",
    "            return self._generate_by_llm(category, metadata_items)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] 텍스트 생성 실패 ({category}): {e}\")\n",
    "            return \", \".join(metadata_items)\n",
    "\n",
    "    def _generate_by_template(self, category: str, metadata: Dict[str, str]) -> str:\n",
    "        \"\"\"\n",
    "        ChromaDB 저장 형식을 참고한 템플릿 기반 텍스트 생성\n",
    "        \n",
    "        실제 ChromaDB 저장 예시:\n",
    "        - 인구: \"경기 성남시에 거주하는 48세 남이며 미혼, 가족 구성은 2명, 최종 학력은 대학교 재학입니다.\"\n",
    "        - 직업소득: \"현재 직업은 전문직 (의사, 간호사, 변호사, 회계사, 예술가, 종교인, 엔지니어, 프로그래머, 기술사 등)이며, 직무는 IT입니다. 월평균 개인 소득은 월 600~699만원이고, 가구 소득은 월 600~699만원입니다.\"\n",
    "        \"\"\"\n",
    "        \n",
    "        if category == \"기본정보\":\n",
    "            # ChromaDB topic=\"인구\" 형식\n",
    "            parts = []\n",
    "            \n",
    "            # 지역 정보\n",
    "            if \"지역\" in metadata or \"지역구\" in metadata:\n",
    "                region_text = \"\"\n",
    "                if \"지역\" in metadata and \"지역구\" in metadata:\n",
    "                    region_text = f\"{metadata['지역']} {metadata['지역구']}\"\n",
    "                elif \"지역구\" in metadata:\n",
    "                    region_text = metadata['지역구']\n",
    "                elif \"지역\" in metadata:\n",
    "                    region_text = metadata['지역']\n",
    "                \n",
    "                if region_text:\n",
    "                    parts.append(f\"{region_text}에 거주하는\")\n",
    "            \n",
    "            # 나이\n",
    "            if \"나이\" in metadata:\n",
    "                parts.append(f\"{metadata['나이']}세\")\n",
    "            \n",
    "            # 성별\n",
    "            if \"성별\" in metadata:\n",
    "                parts.append(metadata['성별'])\n",
    "            \n",
    "            # 기본 정보 연결\n",
    "            base_text = \" \".join(parts) if parts else \"\"\n",
    "            \n",
    "            # 추가 정보 (이며 ~)\n",
    "            additional = []\n",
    "            if \"결혼여부\" in metadata:\n",
    "                additional.append(metadata['결혼여부'])\n",
    "            \n",
    "            if \"자녀수\" in metadata:\n",
    "                additional.append(f\"자녀는 {metadata['자녀수']}명\")\n",
    "            \n",
    "            if \"가족수\" in metadata:\n",
    "                additional.append(f\"가족 구성은 {metadata['가족수']}명\")\n",
    "            \n",
    "            if \"학력\" in metadata:\n",
    "                additional.append(f\"최종 학력은 {metadata['학력']}\")\n",
    "            \n",
    "            # 최종 조합\n",
    "            if base_text and additional:\n",
    "                return f\"{base_text}이며 {', '.join(additional)}입니다.\"\n",
    "            elif base_text:\n",
    "                return f\"{base_text}입니다.\"\n",
    "            elif additional:\n",
    "                return f\"{', '.join(additional)}입니다.\"\n",
    "            \n",
    "            return \"\"\n",
    "        \n",
    "        elif category == \"직업소득\":\n",
    "            # ChromaDB topic=\"직업소득\" 형식\n",
    "            # ⭐ 핵심: 실제 저장 형식은 매우 상세함\n",
    "            # \"현재 직업은 전문직 (의사, 간호사, 변호사, 회계사, 예술가, 종교인, 엔지니어, 프로그래머, 기술사 등)이며, 직무는 IT입니다. 월평균 개인 소득은 월 600~699만원이고, 가구 소득은 월 600~699만원입니다.\"\n",
    "            \n",
    "            # 직업별 상세 설명 매핑 (ChromaDB 실제 패턴)\n",
    "            job_details = {\n",
    "                \"전문직\": \" (의사, 간호사, 변호사, 회계사, 예술가, 종교인, 엔지니어, 프로그래머, 기술사 등)\",\n",
    "                \"사무직\": \" (일반 사무직, 은행원, 공무원, 군인, 경찰, 소방관 등)\",\n",
    "                \"서비스직\": \" (미용, 통신, 안내, 요식업 직원 등)\",\n",
    "                \"판매직\": \" (매장 판매직, 세일즈, 보험설계사, 텔레마케터, 영업 등)\",\n",
    "                \"생산직\": \" (차량운전자, 현장직, 생산직 등)\",\n",
    "                \"생산/노무직\": \" (차량운전자, 현장직, 생산직 등)\",\n",
    "                \"교직\": \" (교수, 교사, 강사 등)\",\n",
    "                \"자영업\": \" (제조업, 건설업, 도소매업, 운수업, 무역업, 서비스업 경영)\",\n",
    "                \"농/임/수산/축산업\": \"\",\n",
    "                \"대학생/대학원생\": \"\",\n",
    "                \"중/고등학생\": \"\",\n",
    "                \"전업주부\": \"\",\n",
    "                \"무직\": \"\",\n",
    "                \"은퇴\": \"\",\n",
    "                \"프리랜서\": \"\",\n",
    "                \"회사원\": \"\",  # 일반적인 경우\n",
    "            }\n",
    "            \n",
    "            parts = []\n",
    "            \n",
    "            if \"직업\" in metadata:\n",
    "                job = metadata['직업']\n",
    "                # 상세 설명 추가\n",
    "                job_detail = job_details.get(job, \"\")\n",
    "                parts.append(f\"현재 직업은 {job}{job_detail}입니다\")\n",
    "            \n",
    "            # 학력이 있으면 추가 (직업 정보와 함께)\n",
    "            if \"학력\" in metadata:\n",
    "                parts.append(f\"최종 학력은 {metadata['학력']}입니다\")\n",
    "            \n",
    "            # 소득 정보는 쿼리에서 제공되지 않으므로 생략\n",
    "            # (실제 ChromaDB에는 있지만, 검색 시에는 직업만으로 충분)\n",
    "            \n",
    "            return \". \".join(parts) + \".\" if parts else \"\"\n",
    "        \n",
    "        elif category == \"전자제품\":\n",
    "            # ChromaDB topic=\"전자제품\" 형식\n",
    "            # \"TV, 냉장고, 세탁기 등 전자제품을 보유하고 있습니다.\"\n",
    "            if \"전자제품\" in metadata:\n",
    "                products = metadata['전자제품']\n",
    "                return f\"{products} 등 전자제품을 보유하고 있습니다.\"\n",
    "            return \"\"\n",
    "        \n",
    "        elif category == \"휴대폰\":\n",
    "            # ChromaDB topic=\"휴대폰\" 형식\n",
    "            # \"현재 사용 중인 휴대폰은 삼성전자의 갤럭시 M 시리즈입니다.\"\n",
    "            if \"휴대폰\" in metadata:\n",
    "                return f\"현재 사용 중인 휴대폰은 {metadata['휴대폰']}입니다.\"\n",
    "            return \"\"\n",
    "        \n",
    "        elif category == \"자동차\":\n",
    "            # ChromaDB topic=\"자동차\" 형식\n",
    "            # \"현재 보유 차량은 없습니다.\" 또는 \"지프 컴패스 모델의 자동차를 보유하고 있습니다.\"\n",
    "            if \"자동차\" in metadata:\n",
    "                car = metadata['자동차']\n",
    "                if car in [\"없음\", \"없습니다\", \"보유하지 않음\"]:\n",
    "                    return \"현재 보유 차량은 없습니다.\"\n",
    "                else:\n",
    "                    return f\"{car} 모델의 자동차를 보유하고 있습니다.\"\n",
    "            return \"\"\n",
    "        \n",
    "        elif category == \"흡연\":\n",
    "            # ChromaDB topic=\"흡연\" 형식\n",
    "            # \"일반 담배를 경험한 적이 있습니다.\"\n",
    "            if \"흡연\" in metadata:\n",
    "                smoking = metadata['흡연']\n",
    "                if smoking in [\"흡연\", \"일반담배\", \"담배\"]:\n",
    "                    return \"일반 담배를 경험한 적이 있습니다.\"\n",
    "                elif smoking in [\"비흡연\", \"없음\"]:\n",
    "                    return \"흡연 경험이 없습니다.\"\n",
    "                else:\n",
    "                    return f\"{smoking}를 경험한 적이 있습니다.\"\n",
    "            return \"\"\n",
    "        \n",
    "        elif category == \"음주\":\n",
    "            # ChromaDB topic=\"음주\" 형식\n",
    "            # \"음주 경험이 있는 술 종류는 소주, 맥주입니다.\"\n",
    "            if \"음주\" in metadata:\n",
    "                drinks = metadata['음주']\n",
    "                return f\"음주 경험이 있는 술 종류는 {drinks}입니다.\"\n",
    "            return \"\"\n",
    "        \n",
    "        elif category == \"건강\":\n",
    "            # ChromaDB에는 건강 topic이 없지만, 활동/운동 정보 생성\n",
    "            parts = []\n",
    "            if \"활동\" in metadata:\n",
    "                parts.append(f\"{metadata['활동']} 활동을 합니다\")\n",
    "            if \"운동\" in metadata:\n",
    "                parts.append(f\"{metadata['운동']} 운동을 합니다\")\n",
    "            return \". \".join(parts) + \".\" if parts else \"\"\n",
    "        \n",
    "        elif category == \"미디어\":\n",
    "            # ChromaDB에는 미디어 topic 형식 참고\n",
    "            if \"OTT\" in metadata:\n",
    "                return f\"현재 이용 중인 OTT 서비스는 {metadata['OTT']}개입니다.\"\n",
    "            return \"\"\n",
    "        \n",
    "        # 기본 템플릿이 없는 경우\n",
    "        return \"\"\n",
    "\n",
    "    def _generate_by_llm(self, category: str, metadata_items: List[str]) -> str:\n",
    "        \"\"\"LLM으로 텍스트 생성 (템플릿이 없는 경우)\"\"\"\n",
    "        metadata_str = \", \".join(metadata_items)\n",
    "        \n",
    "        prompt = f\"\"\"다음 메타데이터를 자연스러운 한국어 문장으로 변환하세요.\n",
    "\n",
    "카테고리: {category}\n",
    "메타데이터: {metadata_str}\n",
    "\n",
    "규칙:\n",
    "- 존댓말 사용 (입니다/습니다)\n",
    "- 제공된 정보만 사용\n",
    "- 카테고리 이름 포함하지 말 것\n",
    "\n",
    "문장만 출력하세요:\"\"\"\n",
    "\n",
    "        try:\n",
    "            response = self.client.messages.create(\n",
    "                model=self.model,\n",
    "                max_tokens=512,\n",
    "                temperature=0.3,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "            )\n",
    "            \n",
    "            text = response.content[0].text.strip()\n",
    "            text = text.replace('\"', '').replace(\"'\", '').replace('```', '').strip()\n",
    "            \n",
    "            print(f\"\\n[{category}] {text[:80]}...\")\n",
    "            return text\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] LLM 텍스트 생성 실패: {e}\")\n",
    "            return metadata_str\n",
    "\n",
    "\n",
    "print(\"CategoryTextGenerator 클래스 정의 완료 (ChromaDB 저장 형식 + 직업 상세 설명)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 임베딩 생성기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ EmbeddingGenerator 클래스 정의 완료\n"
     ]
    }
   ],
   "source": [
    "class EmbeddingGenerator:\n",
    "    \"\"\"Upstage Solar로 임베딩 생성\"\"\"\n",
    "\n",
    "    def __init__(self, api_key: str):\n",
    "        self.embeddings = UpstageEmbeddings(\n",
    "            api_key=api_key,\n",
    "            model=\"solar-embedding-1-large-query\"\n",
    "        )\n",
    "\n",
    "    def generate(self, texts: Dict[str, str]) -> Dict[str, List[float]]:\n",
    "        \"\"\"카테고리별 임베딩 생성\"\"\"\n",
    "        result = {}\n",
    "\n",
    "        for category, text in texts.items():\n",
    "            if not text:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                embedding = self.embeddings.embed_query(text)\n",
    "                result[category] = embedding\n",
    "                print(f\"✅ [{category}] 임베딩 생성 완료\")\n",
    "            except Exception as e:\n",
    "                print(f\"❌ [{category}] 임베딩 생성 실패: {e}\")\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "print(\"✅ EmbeddingGenerator 클래스 정의 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. ChromaDB 검색기 (Topic + 메타데이터 필터링) ⭐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ChromaPanelSearcher 클래스 정의 완료 (복수 값 OR 조건, 필터 키 존재 확인)\n"
     ]
    }
   ],
   "source": [
    "class ChromaPanelSearcher:\n",
    "    \"\"\"ChromaDB에서 topic + 단계적 완화 필터링 검색 (복수 값 OR 조건 지원)\"\"\"\n",
    "\n",
    "    def __init__(self, chroma_base_dir: str, category_config: Dict[str, Any], upstage_api_key: str):\n",
    "        self.chroma_base_dir = chroma_base_dir\n",
    "        self.category_config = category_config\n",
    "        self.embeddings = UpstageEmbeddings(\n",
    "            api_key=upstage_api_key,\n",
    "            model=\"solar-embedding-1-large\"\n",
    "        )\n",
    "\n",
    "    def get_available_panels(self) -> List[str]:\n",
    "        \"\"\"사용 가능한 패널 목록\"\"\"\n",
    "        if not os.path.exists(self.chroma_base_dir):\n",
    "            return []\n",
    "\n",
    "        panels = []\n",
    "        for item in os.listdir(self.chroma_base_dir):\n",
    "            full_path = os.path.join(self.chroma_base_dir, item)\n",
    "            if os.path.isdir(full_path) and item.startswith(\"panel_\"):\n",
    "                mb_sn = item.replace(\"panel_\", \"\").replace(\"_\", \"-\")\n",
    "                panels.append(mb_sn)\n",
    "\n",
    "        return panels\n",
    "\n",
    "    def _is_no_response(self, text: str) -> bool:\n",
    "        \"\"\"텍스트가 무응답인지 확인\"\"\"\n",
    "        no_response_patterns = [\n",
    "            \"무응답\", \"응답하지 않았\", \"정보 없음\", \"해당 없음\",\n",
    "            \"해당사항 없음\", \"기록 없음\", \"데이터 없음\"\n",
    "        ]\n",
    "        text_lower = text.lower()\n",
    "        return any(pattern in text_lower for pattern in no_response_patterns)\n",
    "\n",
    "    def _has_valid_metadata(self, doc_metadata: Dict[str, Any], required_keys: List[str]) -> bool:\n",
    "        \"\"\"\n",
    "        메타데이터가 유효한지 확인 (빈 문자열이 아닌 실제 값이 있는지)\n",
    "        \n",
    "        Args:\n",
    "            doc_metadata: 문서의 메타데이터\n",
    "            required_keys: 확인할 키 목록 (예: [\"지역\", \"연령대\", \"성별\"])\n",
    "        \n",
    "        Returns:\n",
    "            최소 1개 이상의 키에 빈 문자열이 아닌 값이 있으면 True\n",
    "        \"\"\"\n",
    "        for key in required_keys:\n",
    "            value = doc_metadata.get(key, '')\n",
    "            if value and value != '':\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def _has_all_required_keys(self, doc_metadata: Dict[str, Any], required_keys: List[str]) -> bool:\n",
    "        \"\"\"\n",
    "        문서 메타데이터에 필요한 모든 키가 존재하고 값이 있는지 확인\n",
    "        \n",
    "        Args:\n",
    "            doc_metadata: 문서의 메타데이터\n",
    "            required_keys: 필수 키 목록\n",
    "        \n",
    "        Returns:\n",
    "            모든 키가 존재하고 빈 문자열이 아니면 True\n",
    "        \"\"\"\n",
    "        for key in required_keys:\n",
    "            value = doc_metadata.get(key, '')\n",
    "            if not value or value == '':\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def _build_filter_condition(self, key: str, value: Any) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        메타데이터 필터 조건 생성 (리스트는 OR 조건으로 변환)\n",
    "\n",
    "        Args:\n",
    "            key: 메타데이터 키\n",
    "            value: 단일 값 또는 리스트\n",
    "\n",
    "        Returns:\n",
    "            ChromaDB 필터 조건\n",
    "            - 단일 값: {key: value}\n",
    "            - 리스트: {\"$or\": [{key: v1}, {key: v2}, ...]}\n",
    "        \"\"\"\n",
    "        if isinstance(value, list) and len(value) > 0:\n",
    "            # 리스트인 경우 OR 조건으로 변환\n",
    "            return {\"$or\": [{key: item} for item in value]}\n",
    "        else:\n",
    "            # 단일 값인 경우\n",
    "            return {key: value}\n",
    "\n",
    "    def _partial_match_score(self, doc_metadata: Dict[str, Any], required_filters: Dict[str, Any]) -> float:\n",
    "        \"\"\"\n",
    "        부분 매칭 스코어 계산 (복수 값 OR 조건 지원)\n",
    "\n",
    "        Returns:\n",
    "            0.0 ~ 1.0 (일치하는 필터 비율)\n",
    "        \"\"\"\n",
    "        if not required_filters:\n",
    "            return 1.0\n",
    "\n",
    "        matched = 0\n",
    "        total = len(required_filters)\n",
    "\n",
    "        for key, expected_value in required_filters.items():\n",
    "            actual_value = doc_metadata.get(key, '')\n",
    "\n",
    "            # 빈값 체크\n",
    "            if not actual_value or actual_value == '':\n",
    "                continue\n",
    "\n",
    "            # expected_value가 리스트인 경우 OR 조건 (하나라도 일치하면 매칭)\n",
    "            if isinstance(expected_value, list):\n",
    "                if str(actual_value) in [str(v) for v in expected_value]:\n",
    "                    matched += 1\n",
    "            else:\n",
    "                # 단일 값인 경우 정확히 일치\n",
    "                if str(actual_value) == str(expected_value):\n",
    "                    matched += 1\n",
    "\n",
    "        return matched / total if total > 0 else 0.0\n",
    "\n",
    "    def search_by_category(\n",
    "        self,\n",
    "        mb_sn: str,\n",
    "        category: str,\n",
    "        query_embedding: List[float],\n",
    "        metadata_filter: Dict[str, Any] = None,\n",
    "        top_k: int = 5\n",
    "    ) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        특정 패널의 특정 카테고리에서 단계적 완화 필터링 검색 (복수 값 OR 조건 지원)\n",
    "\n",
    "        1단계: 모든 메타데이터 필터 적용 (리스트는 OR 조건)\n",
    "        2단계: 부분 매칭 (일부 메타데이터만 일치, 모든 필터 키가 존재해야 함)\n",
    "        ** 3단계 제거: topic만으로 검색하면 빈 메타데이터도 반환되므로 제거 **\n",
    "\n",
    "        예시:\n",
    "            metadata_filter = {\"지역\": [\"서울\", \"경기\"], \"성별\": \"남\"}\n",
    "            → WHERE topic=\"인구\" AND (지역=\"서울\" OR 지역=\"경기\") AND 성별=\"남\"\n",
    "        \"\"\"\n",
    "        topic = self.category_config.get(category, {}).get(\"pinecone_topic\", category)\n",
    "        collection_name = f\"panel_{mb_sn}\".replace(\"-\", \"_\")\n",
    "        persist_directory = os.path.join(self.chroma_base_dir, collection_name)\n",
    "\n",
    "        if not os.path.exists(persist_directory):\n",
    "            return None\n",
    "\n",
    "        vectorstore = None\n",
    "        try:\n",
    "            vectorstore = Chroma(\n",
    "                collection_name=collection_name,\n",
    "                embedding_function=self.embeddings,\n",
    "                persist_directory=persist_directory\n",
    "            )\n",
    "\n",
    "            # ===== 1단계: 엄격한 필터링 (모든 메타데이터 일치, 리스트는 OR 조건) =====\n",
    "            if metadata_filter:\n",
    "                filter_conditions = [{\"topic\": topic}]\n",
    "                for key, value in metadata_filter.items():\n",
    "                    if value:\n",
    "                        # 리스트는 OR 조건으로, 단일 값은 그대로 추가\n",
    "                        condition = self._build_filter_condition(key, value)\n",
    "                        filter_conditions.append(condition)\n",
    "                where_filter = {\"$and\": filter_conditions}\n",
    "            else:\n",
    "                where_filter = {\"topic\": topic}\n",
    "\n",
    "            results = vectorstore.similarity_search_by_vector_with_relevance_scores(\n",
    "                embedding=query_embedding,\n",
    "                k=top_k * 10,\n",
    "                filter=where_filter\n",
    "            )\n",
    "\n",
    "            # 무응답 제외\n",
    "            valid_results = []\n",
    "            for doc, score in results:\n",
    "                if not self._is_no_response(doc.page_content):\n",
    "                    valid_results.append((doc, score))\n",
    "\n",
    "            # 1단계 성공\n",
    "            if valid_results:\n",
    "                best_doc, best_score = valid_results[0]\n",
    "                return {\n",
    "                    \"mb_sn\": mb_sn,\n",
    "                    \"category\": category,\n",
    "                    \"topic\": best_doc.metadata.get(\"topic\"),\n",
    "                    \"score\": float(best_score),\n",
    "                    \"metadata\": best_doc.metadata,\n",
    "                    \"text\": best_doc.page_content[:200],\n",
    "                    \"filter_level\": \"strict\"\n",
    "                }\n",
    "\n",
    "            # ===== 2단계: 부분 매칭 (topic만 필터링 후 후처리, 모든 필터 키 존재 필수) =====\n",
    "            if metadata_filter:\n",
    "                results = vectorstore.similarity_search_by_vector_with_relevance_scores(\n",
    "                    embedding=query_embedding,\n",
    "                    k=top_k * 20,\n",
    "                    filter={\"topic\": topic}\n",
    "                )\n",
    "\n",
    "                # 부분 매칭 + 무응답 제외 + 모든 필터 키 존재 확인\n",
    "                partial_results = []\n",
    "                required_keys = list(metadata_filter.keys())\n",
    "                \n",
    "                for doc, score in results:\n",
    "                    if self._is_no_response(doc.page_content):\n",
    "                        continue\n",
    "                    \n",
    "                    # ⭐ 핵심 수정: 모든 필터 키가 존재하고 값이 있어야 함\n",
    "                    # 예: {\"결혼여부\": \"기혼\"} 필터인데 문서에 \"결혼여부\" 키가 없으면 제외\n",
    "                    if not self._has_all_required_keys(doc.metadata, required_keys):\n",
    "                        continue\n",
    "\n",
    "                    match_score = self._partial_match_score(doc.metadata, metadata_filter)\n",
    "                    if match_score > 0:  # 최소 1개 이상 일치\n",
    "                        # 스코어 = 유사도 * 부분매칭비율\n",
    "                        combined_score = score * (0.5 + 0.5 * match_score)\n",
    "                        partial_results.append((doc, combined_score, match_score))\n",
    "\n",
    "                # 부분 매칭 스코어로 정렬\n",
    "                partial_results.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "                if partial_results:\n",
    "                    best_doc, combined_score, match_ratio = partial_results[0]\n",
    "                    return {\n",
    "                        \"mb_sn\": mb_sn,\n",
    "                        \"category\": category,\n",
    "                        \"topic\": best_doc.metadata.get(\"topic\"),\n",
    "                        \"score\": float(combined_score),\n",
    "                        \"metadata\": best_doc.metadata,\n",
    "                        \"text\": best_doc.page_content[:200],\n",
    "                        \"filter_level\": \"partial\",\n",
    "                        \"match_ratio\": match_ratio\n",
    "                    }\n",
    "\n",
    "            # ⭐ 3단계 제거: 메타데이터 필터가 있는 경우 topic만으로 검색하지 않음\n",
    "            # 이유: 빈 메타데이터 패널도 반환되어 검색 품질이 떨어짐\n",
    "            \n",
    "            return None\n",
    "\n",
    "        except Exception as e:\n",
    "            return None\n",
    "        finally:\n",
    "            if vectorstore is not None:\n",
    "                try:\n",
    "                    if hasattr(vectorstore, '_client'):\n",
    "                        vectorstore._client = None\n",
    "                    del vectorstore\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "\n",
    "print(\"✅ ChromaPanelSearcher 클래스 정의 완료 (복수 값 OR 조건, 필터 키 존재 확인)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 결과 필터 (단계적 필터링)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ResultFilter 클래스 정의 완료 (병렬 검색 + 연결 관리)\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import gc\n",
    "\n",
    "class ResultFilter:\n",
    "    \"\"\"단계적 필터링으로 최종 후보 선별 (병렬 검색 최적화)\"\"\"\n",
    "\n",
    "    def __init__(self, searcher: ChromaPanelSearcher, max_workers: int = 5):  # ⭐ 20 → 5로 감소\n",
    "        self.searcher = searcher\n",
    "        self.max_workers = max_workers\n",
    "\n",
    "    def filter_by_categories(\n",
    "        self,\n",
    "        available_panels: List[str],\n",
    "        category_embeddings: Dict[str, List[float]],\n",
    "        category_filters: Dict[str, Dict[str, Any]],\n",
    "        category_order: List[str],\n",
    "        final_count: int = 10\n",
    "    ) -> List[str]:\n",
    "        \"\"\"\n",
    "        단계적 필터링 (병렬 검색)\n",
    "\n",
    "        Args:\n",
    "            available_panels: 검색 대상 패널 리스트\n",
    "            category_embeddings: 카테고리별 임베딩\n",
    "            category_filters: 카테고리별 메타데이터 필터\n",
    "            category_order: 카테고리 적용 순서\n",
    "            final_count: 최종 반환 개수\n",
    "\n",
    "        Returns:\n",
    "            최종 선별된 mb_sn 리스트\n",
    "        \"\"\"\n",
    "        print(f\"\\n단계적 필터링 시작 (병렬 검색 활성화, workers={self.max_workers})\")\n",
    "        print(f\"   초기 후보: {len(available_panels)}개\")\n",
    "        print(f\"   카테고리 순서: {category_order}\")\n",
    "        print(\"=\" * 80)\n",
    "\n",
    "        # 1단계: 첫 번째 카테고리로 초기 후보 선별 (병렬 검색)\n",
    "        first_category = category_order[0]\n",
    "        first_embedding = category_embeddings[first_category]\n",
    "        first_filter = category_filters.get(first_category, {})\n",
    "\n",
    "        print(f\"\\n[1단계] {first_category} 카테고리로 검색 (병렬)\")\n",
    "        print(f\"   메타데이터 필터: {first_filter}\")\n",
    "        \n",
    "        candidate_scores = {}\n",
    "\n",
    "        # 병렬 검색 실행\n",
    "        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:\n",
    "            future_to_mb_sn = {\n",
    "                executor.submit(\n",
    "                    self.searcher.search_by_category,\n",
    "                    mb_sn,\n",
    "                    first_category,\n",
    "                    first_embedding,\n",
    "                    first_filter,\n",
    "                    1\n",
    "                ): mb_sn\n",
    "                for mb_sn in available_panels\n",
    "            }\n",
    "\n",
    "            for future in as_completed(future_to_mb_sn):\n",
    "                mb_sn = future_to_mb_sn[future]\n",
    "                try:\n",
    "                    result = future.result()\n",
    "                    if result:\n",
    "                        candidate_scores[mb_sn] = result[\"score\"]\n",
    "                except Exception as e:\n",
    "                    pass\n",
    "\n",
    "        # ⭐ 가비지 컬렉션으로 메모리 정리\n",
    "        gc.collect()\n",
    "\n",
    "        candidates = sorted(candidate_scores.items(), key=lambda x: x[1])[:100]\n",
    "        candidate_mb_sns = [mb_sn for mb_sn, _ in candidates]\n",
    "\n",
    "        print(f\"   -> {len(candidate_mb_sns)}개 후보 선별\")\n",
    "\n",
    "        # 2단계 이후: 순차적으로 필터링 (병렬 검색)\n",
    "        for step, category in enumerate(category_order[1:], 2):\n",
    "            if category not in category_embeddings:\n",
    "                continue\n",
    "\n",
    "            print(f\"\\n[{step}단계] {category} 카테고리로 필터링 (병렬)\")\n",
    "            embedding = category_embeddings[category]\n",
    "            cat_filter = category_filters.get(category, {})\n",
    "            print(f\"   메타데이터 필터: {cat_filter}\")\n",
    "\n",
    "            new_scores = {}\n",
    "\n",
    "            # 병렬 검색 실행\n",
    "            with ThreadPoolExecutor(max_workers=self.max_workers) as executor:\n",
    "                future_to_mb_sn = {\n",
    "                    executor.submit(\n",
    "                        self.searcher.search_by_category,\n",
    "                        mb_sn,\n",
    "                        category,\n",
    "                        embedding,\n",
    "                        cat_filter,\n",
    "                        1\n",
    "                    ): mb_sn\n",
    "                    for mb_sn in candidate_mb_sns\n",
    "                }\n",
    "\n",
    "                for future in as_completed(future_to_mb_sn):\n",
    "                    mb_sn = future_to_mb_sn[future]\n",
    "                    try:\n",
    "                        result = future.result()\n",
    "                        if result:\n",
    "                            prev_score = candidate_scores.get(mb_sn, 0)\n",
    "                            new_scores[mb_sn] = prev_score + result[\"score\"]\n",
    "                    except Exception as e:\n",
    "                        pass\n",
    "\n",
    "            # ⭐ 가비지 컬렉션\n",
    "            gc.collect()\n",
    "\n",
    "            candidates = sorted(new_scores.items(), key=lambda x: x[1])[:final_count * 3]\n",
    "            candidate_mb_sns = [mb_sn for mb_sn, _ in candidates]\n",
    "            candidate_scores = dict(candidates)\n",
    "\n",
    "            print(f\"   -> {len(candidate_mb_sns)}개 후보로 축소\")\n",
    "\n",
    "        final_mb_sns = candidate_mb_sns[:final_count]\n",
    "\n",
    "        print(f\"\\n최종 {len(final_mb_sns)}개 패널 선별 완료\")\n",
    "        print(\"=\" * 80)\n",
    "\n",
    "        return final_mb_sns\n",
    "\n",
    "\n",
    "print(\"✅ ResultFilter 클래스 정의 완료 (병렬 검색 + 연결 관리)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 전체 검색 파이프라인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PanelSearchPipeline 클래스 정의 완료 (LLM 기반 필터)\n"
     ]
    }
   ],
   "source": [
    "class PanelSearchPipeline:\n",
    "    \"\"\"전체 검색 파이프라인 (LLM 기반 메타데이터 필터 적용)\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        chroma_base_dir: str,\n",
    "        category_config: Dict[str, Any],\n",
    "        anthropic_api_key: str,\n",
    "        upstage_api_key: str\n",
    "    ):\n",
    "        self.metadata_extractor = MetadataExtractor(anthropic_api_key)\n",
    "        self.filter_extractor = MetadataFilterExtractor(anthropic_api_key)  # ⭐ LLM 기반 필터 추출기 추가\n",
    "        self.category_classifier = CategoryClassifier(category_config, anthropic_api_key)\n",
    "        self.text_generator = CategoryTextGenerator(anthropic_api_key)\n",
    "        self.embedding_generator = EmbeddingGenerator(upstage_api_key)\n",
    "        self.searcher = ChromaPanelSearcher(chroma_base_dir, category_config, upstage_api_key)\n",
    "        self.result_filter = ResultFilter(self.searcher)\n",
    "\n",
    "    def search(self, query: str, top_k: int = 10) -> List[str]:\n",
    "        \"\"\"\n",
    "        자연어 쿼리로 패널 검색\n",
    "\n",
    "        Args:\n",
    "            query: 검색 쿼리 (예: \"서울 20대 남자\")\n",
    "            top_k: 반환할 패널 수\n",
    "\n",
    "        Returns:\n",
    "            mb_sn 리스트\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(f\"검색 쿼리: '{query}'\")\n",
    "        print(\"=\" * 80)\n",
    "\n",
    "        # 1단계: 메타데이터 추출\n",
    "        print(\"\\n[1단계] 메타데이터 추출\")\n",
    "        metadata = self.metadata_extractor.extract(query)\n",
    "\n",
    "        if not metadata:\n",
    "            print(\"[ERROR] 메타데이터 추출 실패\")\n",
    "            return []\n",
    "\n",
    "        # 2단계: 카테고리 분류\n",
    "        print(\"\\n[2단계] 카테고리 분류\")\n",
    "        classified = self.category_classifier.classify(metadata)\n",
    "\n",
    "        if not classified:\n",
    "            print(\"[ERROR] 카테고리 분류 실패\")\n",
    "            return []\n",
    "\n",
    "        # 2.5단계: LLM으로 카테고리별 메타데이터 필터 추출 및 정규화\n",
    "        print(\"\\n[2.5단계] 카테고리별 메타데이터 필터 추출 (LLM)\")\n",
    "        category_filters = {}\n",
    "        for category in classified.keys():\n",
    "            cat_filter = self.filter_extractor.extract_filters(metadata, category)  # ⭐ LLM 사용\n",
    "            if cat_filter:\n",
    "                category_filters[category] = cat_filter\n",
    "\n",
    "        # 3단계: 자연어 텍스트 생성\n",
    "        print(\"\\n[3단계] 자연어 텍스트 생성\")\n",
    "        texts = {}\n",
    "        for category, items in classified.items():\n",
    "            text = self.text_generator.generate(category, items)\n",
    "            if text:\n",
    "                texts[category] = text\n",
    "\n",
    "        # 4단계: 임베딩 생성\n",
    "        print(\"\\n[4단계] 임베딩 생성\")\n",
    "        embeddings = self.embedding_generator.generate(texts)\n",
    "\n",
    "        if not embeddings:\n",
    "            print(\"[ERROR] 임베딩 생성 실패\")\n",
    "            return []\n",
    "\n",
    "        # 5단계: 단계적 필터링 검색\n",
    "        available_panels = self.searcher.get_available_panels()\n",
    "        print(f\"\\n[5단계] 검색 가능한 패널: {len(available_panels)}개\")\n",
    "\n",
    "        category_order = list(embeddings.keys())\n",
    "        final_mb_sns = self.result_filter.filter_by_categories(\n",
    "            available_panels=available_panels,\n",
    "            category_embeddings=embeddings,\n",
    "            category_filters=category_filters,\n",
    "            category_order=category_order,\n",
    "            final_count=top_k\n",
    "        )\n",
    "\n",
    "        return final_mb_sns\n",
    "\n",
    "\n",
    "print(\"PanelSearchPipeline 클래스 정의 완료 (LLM 기반 필터)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. 파이프라인 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[SUCCESS] 검색 파이프라인 재초기화 완료 (복수 값 OR 조건 지원)\n"
     ]
    }
   ],
   "source": [
    "# 검색 파이프라인 재초기화 (수정된 클래스 적용)\n",
    "\n",
    "# 이전 파이프라인 객체가 있으면 정리\n",
    "if 'pipeline' in locals() or 'pipeline' in globals():\n",
    "    try:\n",
    "        if hasattr(pipeline, 'searcher') and hasattr(pipeline.searcher, 'embeddings'):\n",
    "            del pipeline.searcher.embeddings\n",
    "        if hasattr(pipeline, 'embedding_generator') and hasattr(pipeline.embedding_generator, 'embeddings'):\n",
    "            del pipeline.embedding_generator.embeddings\n",
    "        del pipeline\n",
    "        print(\"기존 파이프라인 객체 정리 완료\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# 가비지 컬렉션 강제 실행\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "try:\n",
    "    pipeline = PanelSearchPipeline(\n",
    "        chroma_base_dir=CHROMA_BASE_DIR,\n",
    "        category_config=CATEGORY_CONFIG,\n",
    "        anthropic_api_key=ANTHROPIC_API_KEY,\n",
    "        upstage_api_key=UPSTAGE_API_KEY\n",
    "    )\n",
    "    print(\"\\n[SUCCESS] 검색 파이프라인 재초기화 완료 (복수 값 OR 조건 지원)\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n[ERROR] 파이프라인 초기화 실패:\")\n",
    "    print(f\"  오류 타입: {type(e).__name__}\")\n",
    "    print(f\"  오류 메시지: {str(e)}\")\n",
    "    print(\"\\n⚠️ 해결 방법: Kernel → Restart를 실행한 후 모든 셀을 다시 실행하세요\")\n",
    "    import traceback\n",
    "    print(f\"\\n상세 오류:\")\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. 테스트: 검색 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "검색 쿼리: '전문직에서 일하는 사람'\n",
      "================================================================================\n",
      "\n",
      "[1단계] 메타데이터 추출\n",
      "\n",
      "[메타데이터 추출 - LLM 원본] {'직업': '전문직'}\n",
      "[메타데이터 추출 - 최종] {'직업': '전문직'}\n",
      "\n",
      "[2단계] 카테고리 분류\n",
      "\n",
      "[카테고리 분류] {'직업소득': ['직업: 전문직']}\n",
      "\n",
      "[2.5단계] 카테고리별 메타데이터 필터 추출 (LLM)\n",
      "\n",
      "[3단계] 자연어 텍스트 생성\n",
      "\n",
      "[직업소득] 현재 직업은 전문직 (의사, 간호사, 변호사, 회계사, 예술가, 종교인, 엔지니어, 프로그래머, 기술사 등)입니다....\n",
      "\n",
      "[4단계] 임베딩 생성\n",
      "✅ [직업소득] 임베딩 생성 완료\n",
      "\n",
      "[5단계] 검색 가능한 패널: 1000개\n",
      "\n",
      "단계적 필터링 시작 (병렬 검색 활성화, workers=5)\n",
      "   초기 후보: 1000개\n",
      "   카테고리 순서: ['직업소득']\n",
      "================================================================================\n",
      "\n",
      "[1단계] 직업소득 카테고리로 검색 (병렬)\n",
      "   메타데이터 필터: {}\n",
      "   -> 100개 후보 선별\n",
      "\n",
      "최종 10개 패널 선별 완료\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "최종 검색 결과\n",
      "================================================================================\n",
      "\n",
      "총 10개 패널 발견\n",
      "\n",
      "패널 목록:\n",
      "  1. w306685176992186\n",
      "  2. w204143358246717\n",
      "  3. w13098273102471\n",
      "  4. w400924534362360\n",
      "  5. w172120326756432\n",
      "  6. w14921881\n",
      "  7. w442231461680470\n",
      "  8. w239359745099662\n",
      "  9. w318138049327041\n",
      "  10. w6681942458341\n",
      "\n",
      "================================================================================\n",
      "\n",
      "상세 메타데이터 확인을 위해 아래 셀을 실행하세요.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# 테스트 쿼리: \"서울 20대 남자\"\n",
    "# → 메타데이터 필터: {\"지역\": \"서울\", \"연령대\": \"20대\", \"성별\": \"남\"}\n",
    "test_query = \"전문직에서 일하는 사람\"\n",
    "\n",
    "# 검색 실행\n",
    "results = pipeline.search(test_query, top_k=10)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"최종 검색 결과\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\n총 {len(results)}개 패널 발견\")\n",
    "\n",
    "if len(results) > 0:\n",
    "    print(\"\\n패널 목록:\")\n",
    "    for i, mb_sn in enumerate(results, 1):\n",
    "        print(f\"  {i}. {mb_sn}\")\n",
    "else:\n",
    "    print(\"\\n조건에 맞는 패널이 없습니다.\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"\\n상세 메타데이터 확인을 위해 아래 셀을 실행하세요.\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. 검색 결과 상세 확인\n",
    "\n",
    "**주의**: 이 셀은 검색 결과(results)가 있을 때만 실행하세요."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
