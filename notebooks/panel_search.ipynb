{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# íŒ¨ë„ ê²€ìƒ‰ ì‹œìŠ¤í…œ - ë©”íƒ€ë°ì´í„° í•„í„° ê°•í™” ë²„ì „\n",
    "\n",
    "## ì£¼ìš” ê°œì„ ì‚¬í•­ ğŸ¯\n",
    "\n",
    "### 1. **ê¸°ë³¸ì •ë³´ ë©”íƒ€ë°ì´í„° í•„í„° ì¶”ê°€**\n",
    "- **\"ì„œìš¸ 20ëŒ€ ì—¬ì\"** ê°™ì€ ì¿¼ë¦¬ì—ì„œ ì§€ì—­, ì—°ë ¹ëŒ€, ì„±ë³„ì„ **ì •í™•í•˜ê²Œ í•„í„°ë§**\n",
    "- Pineconeì˜ ë©”íƒ€ë°ì´í„° í•„í„°ë¥¼ í™œìš©í•˜ì—¬ **ë²¡í„° ê²€ìƒ‰ ì „ì— ì •í™•í•œ ì¡°ê±´ìœ¼ë¡œ ì‚¬ì „ í•„í„°ë§**\n",
    "- ê¸°ì¡´: ë²¡í„° ìœ ì‚¬ë„ë§Œìœ¼ë¡œ ê²€ìƒ‰ â†’ ì •í™•ë„ ë‚®ìŒ\n",
    "- ê°œì„ : **ë©”íƒ€ë°ì´í„° í•„í„° + ë²¡í„° ìœ ì‚¬ë„** â†’ ì •í™•ë„ ë†’ìŒ\n",
    "\n",
    "### 2. **ì‘ë™ ë°©ì‹**\n",
    "\n",
    "```\n",
    "ìì—°ì–´ ì§ˆì˜ â†’ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ â†’ ê¸°ë³¸ì •ë³´ í•„í„° ìƒì„± â†’ Pinecone ê²€ìƒ‰\n",
    "```\n",
    "\n",
    "#### ì˜ˆì‹œ: \"ì„œìš¸ 20ëŒ€ ì—¬ì\"\n",
    "1. **ë©”íƒ€ë°ì´í„° ì¶”ì¶œ**: `{\"ì§€ì—­\": \"ì„œìš¸\", \"ì—°ë ¹ëŒ€\": \"20ëŒ€\", \"ì„±ë³„\": \"ì—¬ì\"}`\n",
    "2. **Pinecone í•„í„° ìƒì„±**: `{\"ì§€ì—­\": \"ì„œìš¸\", \"ì—°ë ¹ëŒ€\": \"20ëŒ€\", \"ì„±ë³„\": \"ì—¬ì\"}`\n",
    "3. **Pinecone ê²€ìƒ‰**: í•„í„° ì¡°ê±´ì„ **ì •í™•íˆ ë§Œì¡±í•˜ëŠ”** ë²¡í„°ë§Œ ê²€ìƒ‰\n",
    "4. **ê²°ê³¼**: ì„œìš¸ ê±°ì£¼ 20ëŒ€ ì—¬ì„±ë§Œ ë°˜í™˜ (100% ì •í™•)\n",
    "\n",
    "### 3. **ì¹´í…Œê³ ë¦¬ë³„ ì²˜ë¦¬**\n",
    "\n",
    "- **ê¸°ë³¸ì •ë³´ (ì¸êµ¬)**: ë©”íƒ€ë°ì´í„° í•„í„° + ë²¡í„° ìœ ì‚¬ë„ (ì •í™•ë„ ìµœìš°ì„ )\n",
    "- **ê±´ê°•, ë¯¸ë””ì–´, AIì„œë¹„ìŠ¤ ë“±**: ë²¡í„° ìœ ì‚¬ë„ë§Œ ì‚¬ìš© (ìœ ì—°ì„± ìš°ì„ )\n",
    "\n",
    "### 4. **í”„ë¡œì„¸ìŠ¤ í”Œë¡œìš°**\n",
    "\n",
    "```\n",
    "1. ë©”íƒ€ë°ì´í„° ì¶”ì¶œ\n",
    "   - LLMìœ¼ë¡œ ìì—°ì–´ì—ì„œ ì§€ì—­, ì—°ë ¹ëŒ€, ì„±ë³„ ë“± ì¶”ì¶œ\n",
    "   - ì„±ë³„ ì •ê·œí™” (\"ë‚¨ì„±\" â†’ \"ë‚¨ì\", \"ì—¬ì„±\" â†’ \"ì—¬ì\")\n",
    "\n",
    "2. ê¸°ë³¸ì •ë³´ í•„í„° ìƒì„±\n",
    "   - ì§€ì—­, ì—°ë ¹ëŒ€, ì„±ë³„ì„ Pinecone ë©”íƒ€ë°ì´í„° í•„í„°ë¡œ ë³€í™˜\n",
    "\n",
    "3. ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜\n",
    "   - ê¸°ë³¸ì •ë³´ë¥¼ ìµœìš°ì„ ìœ¼ë¡œ ë°°ì¹˜\n",
    "\n",
    "4. Pinecone ê²€ìƒ‰\n",
    "   - ê¸°ë³¸ì •ë³´: ë©”íƒ€ë°ì´í„° í•„í„° í™œì„±í™” âœ…\n",
    "   - ë‹¤ë¥¸ ì¹´í…Œê³ ë¦¬: ë²¡í„° ìœ ì‚¬ë„ë§Œ ì‚¬ìš©\n",
    "\n",
    "5. ë‹¨ê³„ì  í•„í„°ë§\n",
    "   - ê¸°ë³¸ì •ë³´ë¡œ ì •í™•í•œ í›„ë³´ ì„ ë³„ â†’ ë‹¤ë¥¸ ì¹´í…Œê³ ë¦¬ë¡œ ì •ì œ\n",
    "```\n",
    "\n",
    "### 5. **ê¸°ëŒ€ íš¨ê³¼**\n",
    "\n",
    "- âœ… **ì§€ì—­, ì—°ë ¹ëŒ€, ì„±ë³„ ì •í™•ë„ 100%** (ë©”íƒ€ë°ì´í„° í•„í„°ë§)\n",
    "- âœ… **ë¹ ë¥¸ ê²€ìƒ‰ ì†ë„** (ì‚¬ì „ í•„í„°ë§ìœ¼ë¡œ ê²€ìƒ‰ ë²”ìœ„ ì¶•ì†Œ)\n",
    "- âœ… **ìœ ì—°í•œ ê²€ìƒ‰** (ë‹¤ë¥¸ ì¹´í…Œê³ ë¦¬ëŠ” ë²¡í„° ìœ ì‚¬ë„ í™œìš©)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. í™˜ê²½ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from typing import Dict, List, Any, Tuple, Set, Optional\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# LangChain\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "# Upstage Embeddings\n",
    "from langchain_upstage import UpstageEmbeddings\n",
    "\n",
    "# Pinecone\n",
    "from pinecone import Pinecone\n",
    "\n",
    "print(\"âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… LangChain íŒ¨ì¹˜ ì ìš© ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# LangChain verbose ë¬¸ì œ í•´ê²° íŒ¨ì¹˜\n",
    "import langchain\n",
    "if not hasattr(langchain, 'verbose'):\n",
    "    langchain.verbose = False\n",
    "\n",
    "print(\"âœ… LangChain íŒ¨ì¹˜ ì ìš© ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ì¹´í…Œê³ ë¦¬ ì„¤ì • ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] ì¹´í…Œê³ ë¦¬ ì„¤ì • ì™„ë£Œ: ì´ 17ê°œ ì¹´í…Œê³ ë¦¬ (category_config.json íŒŒì¼ì—ì„œ ë¡œë“œ)\n"
     ]
    }
   ],
   "source": [
    "# ì¹´í…Œê³ ë¦¬ ì„¤ì • ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# í˜„ì¬ íŒŒì¼ê³¼ ê°™ì€ ë””ë ‰í† ë¦¬ì˜ category_config.json íŒŒì¼ ë¡œë“œ\n",
    "config_path = Path(__file__).parent / \"category_config.json\" if '__file__' in globals() else Path(\"category_config.json\")\n",
    "\n",
    "with open(config_path, 'r', encoding='utf-8') as f:\n",
    "    CATEGORY_CONFIG = json.load(f)\n",
    "\n",
    "print(f\"[OK] ì¹´í…Œê³ ë¦¬ ì„¤ì • ì™„ë£Œ: ì´ {len(CATEGORY_CONFIG)}ê°œ ì¹´í…Œê³ ë¦¬ (category_config.json íŒŒì¼ì—ì„œ ë¡œë“œ)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ì‹œìŠ¤í…œ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì„¤ì • ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    \"\"\"ì‹œìŠ¤í…œ ì„¤ì •\"\"\"\n",
    "    \n",
    "    # LLM (ë©”íƒ€ë°ì´í„° ì¶”ì¶œìš©)\n",
    "    llm_model: str = \"claude-haiku-4-5-20251001\"\n",
    "    llm_temperature: float = 0.0\n",
    "    \n",
    "    # Upstage Embedding\n",
    "    embedding_model: str = \"solar-embedding-1-large-query\"\n",
    "    embedding_dim: int = 4096\n",
    "    \n",
    "    # Pinecone\n",
    "    pinecone_index_name: str = \"panel-features\"\n",
    "    top_k: int = 10\n",
    "\n",
    "config = Config()\n",
    "\n",
    "# API í‚¤ ì„¤ì •\n",
    "os.environ[\"ANTHROPIC_API_KEY\"] = \"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\"\n",
    "os.environ[\"UPSTAGE_API_KEY\"] = \"up_2KGGBmZpBmlePxUyk3ouWBf9iqOmJ\"\n",
    "os.environ[\"PINECONE_API_KEY\"] = \"pcsk_63j8FW_3eWWVh5DCy25QrF64bktm48aoTCS4z2Yhk7kL6RsH973TfsfVyDdsryAZwBWHD9\"\n",
    "\n",
    "print(\"âœ… ì„¤ì • ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ë©”íƒ€ë°ì´í„° ì¶”ì¶œê¸° (MetadataExtractor)\n",
    "\n",
    "ìì—°ì–´ ì§ˆì˜ì—ì„œ ìˆœìˆ˜ ë©”íƒ€ë°ì´í„°ë§Œ ì¶”ì¶œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… MetadataExtractor ì •ì˜ ì™„ë£Œ (ì§ì—…ì†Œë“ í•„í„° ì œê±° + ë‚˜ë¨¸ì§€ Fallback ì§€ì›)\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# panel_search.ipynbì˜ \"## 4. ë©”íƒ€ë°ì´í„° ì¶”ì¶œê¸° (MetadataExtractor)\" ì…€ì„\n",
    "# ì•„ë˜ ì½”ë“œë¡œ ì™„ì „íˆ êµì²´í•˜ì„¸ìš”\n",
    "# ========================================\n",
    "\n",
    "import re\n",
    "import json\n",
    "from typing import Dict, List, Any, Optional\n",
    "\n",
    "class MetadataExtractor:\n",
    "    \"\"\"ìì—°ì–´ ì§ˆì˜ì—ì„œ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ (ë‹¤ì¤‘ ê°’/ë²”ìœ„ ì§€ì›, ì „ì²´ topic í•„í„° ì§€ì›)\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Config):\n",
    "        self.llm = ChatAnthropic(\n",
    "            model=config.llm_model,\n",
    "            temperature=0.0  # ì¼ê´€ì„±ì„ ìœ„í•´ 0ìœ¼ë¡œ ì„¤ì •\n",
    "        )\n",
    "        \n",
    "        self.prompt = PromptTemplate(\n",
    "            input_variables=[\"query\"],\n",
    "            template=\"\"\"ë‹¹ì‹ ì€ ìì—°ì–´ ì§ˆì˜ì—ì„œ ë©”íƒ€ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
    "\n",
    "ìì—°ì–´ ì§ˆì˜ë¥¼ ë¶„ì„í•˜ì—¬ ëª¨ë“  ì •ë³´ë¥¼ ë©”íƒ€ë°ì´í„°ë¡œ ì¶”ì¶œí•˜ì„¸ìš”.\n",
    "\n",
    "=== ì¶”ì¶œ ê·œì¹™ ===\n",
    "\n",
    "1. **ë‹¤ì¤‘ ê°’ì€ ë¦¬ìŠ¤íŠ¸ë¡œ í‘œí˜„**\n",
    "   - \"ì„œìš¸, ê²½ê¸°\" â†’ \"ì§€ì—­\": [\"ì„œìš¸\", \"ê²½ê¸°\"]\n",
    "   - \"ì„œìš¸ ë˜ëŠ” ê²½ê¸°\" â†’ \"ì§€ì—­\": [\"ì„œìš¸\", \"ê²½ê¸°\"]\n",
    "   - \"ì„œìš¸ì´ë‚˜ ê²½ê¸°\" â†’ \"ì§€ì—­\": [\"ì„œìš¸\", \"ê²½ê¸°\"]\n",
    "   - \"20ëŒ€, 30ëŒ€\" â†’ \"ì—°ë ¹ëŒ€\": [\"20ëŒ€\", \"30ëŒ€\"]\n",
    "\n",
    "2. **ë²”ìœ„ëŠ” ì—°ë ¹ëŒ€ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜**\n",
    "   - \"10~20ì„¸\" â†’ \"ì—°ë ¹ëŒ€\": [\"10ëŒ€\", \"20ëŒ€\"]\n",
    "   - \"20ëŒ€~30ëŒ€\" â†’ \"ì—°ë ¹ëŒ€\": [\"20ëŒ€\", \"30ëŒ€\"]\n",
    "   - \"20-30ëŒ€\" â†’ \"ì—°ë ¹ëŒ€\": [\"20ëŒ€\", \"30ëŒ€\"]\n",
    "\n",
    "3. **ì„±ë³„ ì •ê·œí™”**\n",
    "   - \"ë‚¨ì„±\", \"ë‚¨ì\", \"ë‚¨\" â†’ \"ë‚¨ì\"\n",
    "   - \"ì—¬ì„±\", \"ì—¬ì\", \"ì—¬\" â†’ \"ì—¬ì\"\n",
    "\n",
    "4. **ëª¨í˜¸í•œ í‘œí˜„ í•´ì„**\n",
    "   - \"ì Šì€ì¸µ\", \"ì²­ë…„\", \"ì²­ë…„ì¸µ\" â†’ \"ì—°ë ¹ëŒ€\": [\"20ëŒ€\", \"30ëŒ€\"]\n",
    "   - \"ì¤‘ë…„ì¸µ\", \"ì¥ë…„\", \"ì¥ë…„ì¸µ\" â†’ \"ì—°ë ¹ëŒ€\": [\"40ëŒ€\", \"50ëŒ€\"]\n",
    "   - \"ë…¸ë…„ì¸µ\", \"ì‹œë‹ˆì–´\", \"ê³ ë ¹ì¸µ\" â†’ \"ì—°ë ¹ëŒ€\": [\"60ëŒ€\", \"70ëŒ€\"]\n",
    "   - \"MZì„¸ëŒ€\", \"MZ\" â†’ \"ì—°ë ¹ëŒ€\": [\"20ëŒ€\", \"30ëŒ€\"]\n",
    "\n",
    "5. **ì „êµ­/ì „ì²´ëŠ” ë¹ˆ ê°’ìœ¼ë¡œ ì²˜ë¦¬**\n",
    "   - \"ì „êµ­\" â†’ ì§€ì—­ í•„ë“œ ìƒì„±í•˜ì§€ ì•ŠìŒ\n",
    "\n",
    "6. **ëª…ì‹œì  ì •ë³´ë§Œ ì¶”ì¶œ** (ì¶”ë¡  ê¸ˆì§€)\n",
    "\n",
    "7. **ìˆ˜ë„ê¶Œ íŠ¹ë³„ ì²˜ë¦¬**\n",
    "   - \"ìˆ˜ë„ê¶Œ\" â†’ \"ì§€ì—­\": [\"ì„œìš¸\", \"ê²½ê¸°\", \"ì¸ì²œ\"]\n",
    "\n",
    "=== ì˜ˆì‹œ ===\n",
    "\n",
    "ì…ë ¥: \"ì„œìš¸ 20ëŒ€ í—¬ìŠ¤í•˜ëŠ” ë‚¨ì\"\n",
    "ì¶œë ¥:\n",
    "{{\n",
    "    \"ì§€ì—­\": \"ì„œìš¸\",\n",
    "    \"ì—°ë ¹ëŒ€\": \"20ëŒ€\",\n",
    "    \"í™œë™\": \"í—¬ìŠ¤í•˜ëŠ”\",\n",
    "    \"ì„±ë³„\": \"ë‚¨ì\"\n",
    "}}\n",
    "\n",
    "ì…ë ¥: \"ì„œìš¸, ê²½ê¸° 20ëŒ€ ì—¬ì„±\"\n",
    "ì¶œë ¥:\n",
    "{{\n",
    "    \"ì§€ì—­\": [\"ì„œìš¸\", \"ê²½ê¸°\"],\n",
    "    \"ì—°ë ¹ëŒ€\": \"20ëŒ€\",\n",
    "    \"ì„±ë³„\": \"ì—¬ì\"\n",
    "}}\n",
    "\n",
    "ì…ë ¥: \"ë¶€ì‚° 20~30ëŒ€ ë‚¨ì\"\n",
    "ì¶œë ¥:\n",
    "{{\n",
    "    \"ì§€ì—­\": \"ë¶€ì‚°\",\n",
    "    \"ì—°ë ¹ëŒ€\": [\"20ëŒ€\", \"30ëŒ€\"],\n",
    "    \"ì„±ë³„\": \"ë‚¨ì\"\n",
    "}}\n",
    "\n",
    "ì…ë ¥: \"ì„œìš¸ ë˜ëŠ” ì¸ì²œ ì Šì€ì¸µ 10ëª…\"\n",
    "ì¶œë ¥:\n",
    "{{\n",
    "    \"ì§€ì—­\": [\"ì„œìš¸\", \"ì¸ì²œ\"],\n",
    "    \"ì—°ë ¹ëŒ€\": [\"20ëŒ€\", \"30ëŒ€\"],\n",
    "    \"ì¸ì›\": \"10ëª…\"\n",
    "}}\n",
    "\n",
    "ì…ë ¥: \"ì „êµ­ ì¤‘ë…„ì¸µ ë‚¨ì„±\"\n",
    "ì¶œë ¥:\n",
    "{{\n",
    "    \"ì—°ë ¹ëŒ€\": [\"40ëŒ€\", \"50ëŒ€\"],\n",
    "    \"ì„±ë³„\": \"ë‚¨ì\"\n",
    "}}\n",
    "\n",
    "ì…ë ¥: \"ìˆ˜ë„ê¶Œ MZì„¸ëŒ€\"\n",
    "ì¶œë ¥:\n",
    "{{\n",
    "    \"ì§€ì—­\": [\"ì„œìš¸\", \"ê²½ê¸°\", \"ì¸ì²œ\"],\n",
    "    \"ì—°ë ¹ëŒ€\": [\"20ëŒ€\", \"30ëŒ€\"]\n",
    "}}\n",
    "\n",
    "ì…ë ¥: \"ê²½ê¸° 10ëŒ€~20ëŒ€ ì—¬ì ë„·í”Œë¦­ìŠ¤ ë³´ëŠ”\"\n",
    "ì¶œë ¥:\n",
    "{{\n",
    "    \"ì§€ì—­\": \"ê²½ê¸°\",\n",
    "    \"ì—°ë ¹ëŒ€\": [\"10ëŒ€\", \"20ëŒ€\"],\n",
    "    \"ì„±ë³„\": \"ì—¬ì\",\n",
    "    \"í™œë™\": \"ë„·í”Œë¦­ìŠ¤ ë³´ëŠ”\"\n",
    "}}\n",
    "\n",
    "ì…ë ¥: \"ê°•ë‚¨êµ¬, ì†¡íŒŒêµ¬ ì²­ë…„ í—¬ìŠ¤í•˜ëŠ”\"\n",
    "ì¶œë ¥:\n",
    "{{\n",
    "    \"ì§€ì—­\": [\"ê°•ë‚¨êµ¬\", \"ì†¡íŒŒêµ¬\"],\n",
    "    \"ì—°ë ¹ëŒ€\": [\"20ëŒ€\", \"30ëŒ€\"],\n",
    "    \"í™œë™\": \"í—¬ìŠ¤í•˜ëŠ”\"\n",
    "}}\n",
    "\n",
    "ì§ˆì˜: {query}\n",
    "\n",
    "JSONë§Œ ë°˜í™˜í•˜ì„¸ìš”. ë‹¤ë¥¸ ì„¤ëª…ì€ í•˜ì§€ ë§ˆì„¸ìš”.\n",
    "\"\"\"\n",
    "        )\n",
    "    \n",
    "    def extract(self, query: str) -> Dict[str, Any]:\n",
    "        \"\"\"ë©”íƒ€ë°ì´í„° ì¶”ì¶œ (ë‹¤ì¤‘ ê°’/ë²”ìœ„ ì§€ì›)\"\"\"\n",
    "        try:\n",
    "            prompt_text = self.prompt.format(query=query)\n",
    "            response = self.llm.invoke(prompt_text)\n",
    "            response_text = response.content\n",
    "            \n",
    "            # JSON íŒŒì‹±\n",
    "            if '```json' in response_text:\n",
    "                json_text = response_text.split('```json')[1].split('```')[0].strip()\n",
    "            elif '```' in response_text:\n",
    "                json_text = response_text.split('```')[1].strip()\n",
    "            else:\n",
    "                json_text = response_text\n",
    "            \n",
    "            metadata = json.loads(json_text)\n",
    "            \n",
    "            # ì„±ë³„ ì •ê·œí™” (ë‹¨ì¼ ê°’ ë˜ëŠ” ë¦¬ìŠ¤íŠ¸) - Pinecone ë©”íƒ€ë°ì´í„° ê°’ì— ë§ì¶¤: \"ë‚¨\", \"ì—¬\"\n",
    "            if \"ì„±ë³„\" in metadata:\n",
    "                gender = metadata[\"ì„±ë³„\"]\n",
    "                if isinstance(gender, str):\n",
    "                    if gender in [\"ë‚¨ì„±\", \"ë‚¨ì\", \"male\", \"M\"]:\n",
    "                        metadata[\"ì„±ë³„\"] = \"ë‚¨\"\n",
    "                    elif gender in [\"ì—¬ì„±\", \"ì—¬ì\", \"female\", \"F\"]:\n",
    "                        metadata[\"ì„±ë³„\"] = \"ì—¬\"\n",
    "                elif isinstance(gender, list):\n",
    "                    # ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° ê° í•­ëª© ì •ê·œí™”\n",
    "                    normalized = []\n",
    "                    for g in gender:\n",
    "                        if g in [\"ë‚¨ì„±\", \"ë‚¨ì\", \"male\", \"M\"]:\n",
    "                            normalized.append(\"ë‚¨\")\n",
    "                        elif g in [\"ì—¬ì„±\", \"ì—¬ì\", \"female\", \"F\"]:\n",
    "                            normalized.append(\"ì—¬\")\n",
    "                        else:\n",
    "                            normalized.append(g)\n",
    "                    metadata[\"ì„±ë³„\"] = normalized\n",
    "            \n",
    "            return metadata\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {e}\")\n",
    "            print(f\"   ì‘ë‹µ ë‚´ìš©: {response_text[:200]}\")\n",
    "            return {}\n",
    "    \n",
    "    def extract_basic_info_filter(self, metadata: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        ê¸°ë³¸ì •ë³´ ë©”íƒ€ë°ì´í„°ë¥¼ Pinecone í•„í„°ë¡œ ë³€í™˜ (ë‹¤ì¤‘ ê°’/ë²”ìœ„ ì§€ì›)\n",
    "\n",
    "        ì§€ì›í•˜ëŠ” íŒ¨í„´:\n",
    "        - ë‹¨ì¼ ê°’: {\"ì§€ì—­\": \"ì„œìš¸\"} â†’ {\"ì§€ì—­\": \"ì„œìš¸\"}\n",
    "        - ë‹¤ì¤‘ ê°’: {\"ì§€ì—­\": [\"ì„œìš¸\", \"ê²½ê¸°\"]} â†’ {\"ì§€ì—­\": {\"$in\": [\"ì„œìš¸\", \"ê²½ê¸°\"]}}\n",
    "        - ë²”ìœ„: {\"ì—°ë ¹ëŒ€\": [\"20ëŒ€\", \"30ëŒ€\"]} â†’ {\"ì—°ë ¹ëŒ€\": {\"$in\": [\"20ëŒ€\", \"30ëŒ€\"]}}\n",
    "\n",
    "        Returns:\n",
    "            Pinecone ë©”íƒ€ë°ì´í„° í•„í„°\n",
    "        \"\"\"\n",
    "        filter_conditions = []\n",
    "\n",
    "        # 1. ì§€ì—­ í•„í„°\n",
    "        if \"ì§€ì—­\" in metadata:\n",
    "            region = metadata[\"ì§€ì—­\"]\n",
    "\n",
    "            # \"ì „êµ­\"ì¸ ê²½ìš° í•„í„°ì— ì¶”ê°€í•˜ì§€ ì•ŠìŒ\n",
    "            if region == \"ì „êµ­\":\n",
    "                pass\n",
    "            elif isinstance(region, list):\n",
    "                # ë‹¤ì¤‘ ì§€ì—­: [\"ì„œìš¸\", \"ê²½ê¸°\"] â†’ $in ì—°ì‚°ì\n",
    "                if len(region) > 0:\n",
    "                    filter_conditions.append({\n",
    "                        \"ì§€ì—­\": {\"$in\": region}\n",
    "                    })\n",
    "            else:\n",
    "                # ë‹¨ì¼ ì§€ì—­: \"ì„œìš¸\"\n",
    "                filter_conditions.append({\n",
    "                    \"ì§€ì—­\": region\n",
    "                })\n",
    "\n",
    "        # 2. ì—°ë ¹ëŒ€ í•„í„°\n",
    "        if \"ì—°ë ¹ëŒ€\" in metadata:\n",
    "            age_group = metadata[\"ì—°ë ¹ëŒ€\"]\n",
    "\n",
    "            if isinstance(age_group, list):\n",
    "                # ë‹¤ì¤‘ ì—°ë ¹ëŒ€: [\"20ëŒ€\", \"30ëŒ€\"] â†’ $in ì—°ì‚°ì\n",
    "                if len(age_group) > 0:\n",
    "                    filter_conditions.append({\n",
    "                        \"ì—°ë ¹ëŒ€\": {\"$in\": age_group}\n",
    "                    })\n",
    "            else:\n",
    "                # ë‹¨ì¼ ì—°ë ¹ëŒ€: \"20ëŒ€\"\n",
    "                filter_conditions.append({\n",
    "                    \"ì—°ë ¹ëŒ€\": age_group\n",
    "                })\n",
    "\n",
    "        # 3. ì„±ë³„ í•„í„°\n",
    "        if \"ì„±ë³„\" in metadata:\n",
    "            gender = metadata[\"ì„±ë³„\"]\n",
    "\n",
    "            if isinstance(gender, list):\n",
    "                # ë‹¤ì¤‘ ì„±ë³„ (ë“œë¬¼ì§€ë§Œ ì§€ì›)\n",
    "                if len(gender) > 0:\n",
    "                    filter_conditions.append({\n",
    "                        \"ì„±ë³„\": {\"$in\": gender}\n",
    "                    })\n",
    "            else:\n",
    "                # ë‹¨ì¼ ì„±ë³„\n",
    "                filter_conditions.append({\n",
    "                    \"ì„±ë³„\": gender\n",
    "                })\n",
    "\n",
    "        # í•„í„° ì¡°ê±´ ê²°í•©\n",
    "        if len(filter_conditions) == 0:\n",
    "            # í•„í„° ì—†ìŒ\n",
    "            return {}\n",
    "        elif len(filter_conditions) == 1:\n",
    "            # ë‹¨ì¼ í•„í„°\n",
    "            return filter_conditions[0]\n",
    "        else:\n",
    "            # ì—¬ëŸ¬ ì¡°ê±´ì€ ANDë¡œ ê²°í•©\n",
    "            return {\"$and\": filter_conditions}\n",
    "\n",
    "    def extract_topic_filters(self, metadata: Dict[str, Any]) -> Dict[str, Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        ëª¨ë“  topicë³„ ë©”íƒ€ë°ì´í„° í•„í„° ì¶”ì¶œ\n",
    "\n",
    "        Returns:\n",
    "            {\n",
    "                \"ê¸°ë³¸ì •ë³´\": {...},\n",
    "                \"ì „ìì œí’ˆ\": {...},\n",
    "                \"ìë™ì°¨\": {...},\n",
    "                \"í¡ì—°\": {...},\n",
    "                \"ìŒì£¼\": {...}\n",
    "            }\n",
    "        \n",
    "        NOTE: ì§ì—…ì†Œë“ì€ Pineconeì— ì €ì¥ëœ ê°’ì´ \"íšŒì‚¬ì› (ì‚¬ë¬´, ê¸°ìˆ , ê´€ë¦¬ ë“±)\" í˜•íƒœë¡œ\n",
    "              ì •í™•í•œ ë§¤ì¹­ì´ ì–´ë ¤ìš°ë¯€ë¡œ í•„í„°ë¥¼ ì œê±°í•˜ê³  ë²¡í„° ìœ ì‚¬ë„ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "              (ì„±ëŠ¥ ìµœì í™”: ë¶ˆí•„ìš”í•œ Fallback API í˜¸ì¶œ ì œê±°)\n",
    "        \"\"\"\n",
    "        filters = {}\n",
    "\n",
    "        # ê¸°ë³¸ì •ë³´ í•„í„° (Fallback ì§€ì›)\n",
    "        basic_filter = self.extract_basic_info_filter(metadata)\n",
    "        if basic_filter:\n",
    "            filters[\"ê¸°ë³¸ì •ë³´\"] = basic_filter\n",
    "\n",
    "        # ğŸš« ì§ì—…ì†Œë“ í•„í„°ëŠ” ì œê±° (í•­ìƒ ë²¡í„° ìœ ì‚¬ë„ë§Œ ì‚¬ìš©)\n",
    "        # ì´ìœ : Pinecone ì €ì¥ í˜•ì‹ì´ \"íšŒì‚¬ì› (ì‚¬ë¬´, ê¸°ìˆ , ê´€ë¦¬ ë“±)\"ì´ë¼ ì •í™•í•œ ë§¤ì¹­ ë¶ˆê°€\n",
    "        # ì„±ëŠ¥: ë¶ˆí•„ìš”í•œ Fallback API í˜¸ì¶œ ì œê±°\n",
    "\n",
    "        # ì „ìì œí’ˆ í•„í„° (Fallback ì§€ì›)\n",
    "        electronics_filter = self._extract_electronics_filter(metadata)\n",
    "        if electronics_filter:\n",
    "            filters[\"ì „ìì œí’ˆ\"] = electronics_filter\n",
    "\n",
    "        # ìë™ì°¨ í•„í„° (Fallback ì§€ì›)\n",
    "        car_filter = self._extract_car_filter(metadata)\n",
    "        if car_filter:\n",
    "            filters[\"ìë™ì°¨\"] = car_filter\n",
    "\n",
    "        # í¡ì—° í•„í„° (Fallback ì§€ì›)\n",
    "        smoking_filter = self._extract_smoking_filter(metadata)\n",
    "        if smoking_filter:\n",
    "            filters[\"í¡ì—°\"] = smoking_filter\n",
    "\n",
    "        # ìŒì£¼ í•„í„° (Fallback ì§€ì›)\n",
    "        drinking_filter = self._extract_drinking_filter(metadata)\n",
    "        if drinking_filter:\n",
    "            filters[\"ìŒì£¼\"] = drinking_filter\n",
    "\n",
    "        return filters\n",
    "\n",
    "    def _extract_electronics_filter(self, metadata: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"ì „ìì œí’ˆ í•„í„° ì¶”ì¶œ\"\"\"\n",
    "        # ì „ìì œí’ˆ í‚¤ì›Œë“œ (ì˜ˆ: ë¬´ì„ ì²­ì†Œê¸°, ë…¸íŠ¸ë¶ ë“±)\n",
    "        electronics_keywords = [\n",
    "            \"ë¬´ì„ ì²­ì†Œê¸°\", \"ë…¸íŠ¸ë¶\", \"íƒœë¸”ë¦¿\", \"ìŠ¤ë§ˆíŠ¸ì›Œì¹˜\", \"ì—ì–´í”„ë¼ì´ì–´\",\n",
    "            \"ì»¤í”¼ë¨¸ì‹ \", \"ì œìŠµê¸°\", \"ê³µê¸°ì²­ì •ê¸°\", \"ëƒ‰ì¥ê³ \", \"ì„¸íƒê¸°\", \"ì—ì–´ì»¨\"\n",
    "        ]\n",
    "\n",
    "        # ë©”íƒ€ë°ì´í„°ì—ì„œ ì „ìì œí’ˆ ê´€ë ¨ í‚¤ì›Œë“œ ì°¾ê¸°\n",
    "        found_electronics = []\n",
    "        for key, value in metadata.items():\n",
    "            value_str = str(value).lower()\n",
    "            for electronics in electronics_keywords:\n",
    "                if electronics in value_str:\n",
    "                    found_electronics.append(electronics)\n",
    "\n",
    "        if found_electronics:\n",
    "            # ì „ìì œí’ˆëª©ë¡ í•„í„° (ë°°ì—´ êµì§‘í•©)\n",
    "            return {\"ì „ìì œí’ˆëª©ë¡\": {\"$in\": found_electronics}}\n",
    "\n",
    "        return {}\n",
    "\n",
    "    def _extract_car_filter(self, metadata: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"ìë™ì°¨ í•„í„° ì¶”ì¶œ\"\"\"\n",
    "        filter_conditions = []\n",
    "\n",
    "        # ë¸Œëœë“œ í•„í„°\n",
    "        if \"ë¸Œëœë“œ\" in metadata or \"ìë™ì°¨ë¸Œëœë“œ\" in metadata:\n",
    "            brand = metadata.get(\"ë¸Œëœë“œ\") or metadata.get(\"ìë™ì°¨ë¸Œëœë“œ\")\n",
    "            if isinstance(brand, list):\n",
    "                filter_conditions.append({\"ë¸Œëœë“œ\": {\"$in\": brand}})\n",
    "            else:\n",
    "                filter_conditions.append({\"ë¸Œëœë“œ\": brand})\n",
    "\n",
    "        # ëª¨ë¸ í•„í„°\n",
    "        if \"ëª¨ë¸\" in metadata or \"ìë™ì°¨ëª¨ë¸\" in metadata:\n",
    "            model = metadata.get(\"ëª¨ë¸\") or metadata.get(\"ìë™ì°¨ëª¨ë¸\")\n",
    "            if isinstance(model, list):\n",
    "                filter_conditions.append({\"ëª¨ë¸\": {\"$in\": model}})\n",
    "            else:\n",
    "                filter_conditions.append({\"ëª¨ë¸\": model})\n",
    "\n",
    "        # í•„í„° ì¡°ê±´ ê²°í•©\n",
    "        if len(filter_conditions) == 0:\n",
    "            return {}\n",
    "        elif len(filter_conditions) == 1:\n",
    "            return filter_conditions[0]\n",
    "        else:\n",
    "            return {\"$and\": filter_conditions}\n",
    "\n",
    "    def _extract_smoking_filter(self, metadata: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"í¡ì—° í•„í„° ì¶”ì¶œ\"\"\"\n",
    "        # í¡ì—° í‚¤ì›Œë“œ ê°ì§€\n",
    "        for key, value in metadata.items():\n",
    "            value_str = str(value).lower()\n",
    "            if any(keyword in value_str for keyword in [\"í¡ì—°\", \"ë‹´ë°°\", \"í”¼ìš°ëŠ”\", \"í”¼ëŠ”\"]):\n",
    "                # í¡ì—°ì í•„í„°\n",
    "                return {\"í¡ì—°ì—¬ë¶€\": True}\n",
    "\n",
    "        return {}\n",
    "\n",
    "    def _extract_drinking_filter(self, metadata: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"ìŒì£¼ í•„í„° ì¶”ì¶œ\"\"\"\n",
    "        # ìŒì£¼ í‚¤ì›Œë“œ ê°ì§€\n",
    "        drink_keywords = [\"ìŒì£¼\", \"ìˆ \", \"ì†Œì£¼\", \"ë§¥ì£¼\", \"ì™€ì¸\", \"ë§ˆì‹œëŠ”\", \"ìŒìš©\"]\n",
    "\n",
    "        for key, value in metadata.items():\n",
    "            value_str = str(value).lower()\n",
    "            if any(keyword in value_str for keyword in drink_keywords):\n",
    "                # ìŒì£¼ì í•„í„°\n",
    "                return {\"ìŒì£¼ì—¬ë¶€\": True}\n",
    "\n",
    "        return {}\n",
    "\n",
    "print(\"âœ… MetadataExtractor ì •ì˜ ì™„ë£Œ (ì§ì—…ì†Œë“ í•„í„° ì œê±° + ë‚˜ë¨¸ì§€ Fallback ì§€ì›)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ê¸° (CategoryClassifier)\n",
    "\n",
    "ë©”íƒ€ë°ì´í„°ë¥¼ ì¹´í…Œê³ ë¦¬ ì„¤ì •ê³¼ ë§¤ì¹­í•˜ì—¬ ë¶„ë¥˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class CategoryClassifier:\n",
    "    \"\"\"LLM ê¸°ë°˜: ë©”íƒ€ë°ì´í„°ë¥¼ ì¹´í…Œê³ ë¦¬ë¡œ ì˜ë¯¸ì ìœ¼ë¡œ ë¶„ë¥˜\"\"\"\n",
    "\n",
    "    def __init__(self, category_config: Dict[str, Any], llm_model: str = \"claude-3-5-haiku-20241022\"):\n",
    "        self.category_config = category_config\n",
    "        self.llm = ChatAnthropic(model=llm_model, temperature=0.2)\n",
    "\n",
    "    def classify(self, metadata: Dict[str, str]) -> Dict[str, List[str]]:\n",
    "        \"\"\"\n",
    "        ë©”íƒ€ë°ì´í„°ë¥¼ LLMì„ í†µí•´ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë¶„ë¥˜\n",
    "\n",
    "        Returns:\n",
    "            {\"ì¹´í…Œê³ ë¦¬ëª…\": [\"í‚¤: ê°’\", \"í‚¤: ê°’\", ...]}\n",
    "        \"\"\"\n",
    "        prompt = self._build_prompt(metadata)\n",
    "\n",
    "        try:\n",
    "            # 1) LLM í˜¸ì¶œ\n",
    "            response = self.llm.invoke(prompt)\n",
    "            raw_output = response.content.strip()\n",
    "\n",
    "            # 2) ì½”ë“œë¸”ëŸ­ ì œê±° ë° JSON íŒŒì‹± + 1ì°¨ ì •ê·œí™”\n",
    "            mapping_tokens = self._parse_llm_output(raw_output)\n",
    "\n",
    "            # 3) í† í°ë“¤ì„ ì‹¤ì œ ë©”íƒ€ë°ì´í„° í‚¤ë¡œ ë§¤í•‘\n",
    "            categorized: Dict[str, List[str]] = {}\n",
    "            used_keys: Set[str] = set()  # í•œ í‚¤ëŠ” í•˜ë‚˜ì˜ ì¹´í…Œê³ ë¦¬ì—ë§Œ ë§¤í•‘\n",
    "\n",
    "            for cat, tokens in mapping_tokens.items():\n",
    "                # tokens: LLMì´ ë°˜í™˜í•œ \"í‚¤ ì´ë¦„\" ë˜ëŠ” \"ê°’ ì¼ë¶€\" ë“± ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸\n",
    "                for token in tokens:\n",
    "                    meta_key = self._match_llm_token_to_key(token, metadata, used_keys)\n",
    "                    if meta_key is None:\n",
    "                        continue\n",
    "                    categorized.setdefault(cat, []).append(f\"{meta_key}: {metadata[meta_key]}\")\n",
    "                    used_keys.add(meta_key)\n",
    "\n",
    "            # 4) ì•„ë¬´ ê²ƒë„ ë§¤í•‘ ì•ˆ ëìœ¼ë©´ rule-basedë¡œ í´ë°±\n",
    "            if not categorized:\n",
    "                print(\" LLM ê¸°ë°˜ ë¶„ë¥˜ ê²°ê³¼ ë§¤í•‘ ì‹¤íŒ¨ â†’ rule-basedë¡œ ëŒ€ì²´\")\n",
    "                return self._rule_based_classify(metadata)\n",
    "\n",
    "            return categorized\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\" LLM ë¶„ë¥˜/íŒŒì‹± ì‹¤íŒ¨ ({e}) â†’ rule-basedë¡œ ëŒ€ì²´\")\n",
    "            return self._rule_based_classify(metadata)\n",
    "\n",
    "    def _build_prompt(self, metadata: Dict[str, str]) -> str:\n",
    "        \"\"\"ì¹´í…Œê³ ë¦¬ ì„¤ëª… + ë©”íƒ€ë°ì´í„°ë¥¼ í¬í•¨í•œ LLMìš© í”„ë¡¬í”„íŠ¸ ìƒì„±\"\"\"\n",
    "        # ì¹´í…Œê³ ë¦¬ ì„¤ëª…\n",
    "        category_desc = \"\\n\".join(\n",
    "            [\n",
    "                f\"- {cat}: {info.get('description', ', '.join(info.get('keywords', [])))}\"\n",
    "                for cat, info in self.category_config.items()\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # í‚¤: ê°’ í˜•ì‹ìœ¼ë¡œ ë©”íƒ€ë°ì´í„° ë‚˜ì—´\n",
    "        meta_lines = [f\"{k}: {v}\" for k, v in metadata.items()]\n",
    "        meta_text = \"\\n\".join(meta_lines)\n",
    "\n",
    "        # ì‚¬ìš© ê°€ëŠ¥í•œ í‚¤ ì´ë¦„ ëª©ë¡(LLMì—ê²Œ í‚¤/ê°’ êµ¬ë¶„ì„ ë” ëª…í™•íˆ ë³´ì—¬ì£¼ê¸°)\n",
    "        meta_keys = \", \".join(metadata.keys())\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "ë‹¹ì‹ ì€ ë©”íƒ€ë°ì´í„°ë¥¼ ì¹´í…Œê³ ë¦¬ë¡œ ë¶„ë¥˜í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
    "\n",
    "ë‹¤ìŒì€ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì¹´í…Œê³ ë¦¬ ëª©ë¡ê³¼ ì„¤ëª…ì…ë‹ˆë‹¤:\n",
    "{category_desc}\n",
    "\n",
    "ë‹¤ìŒì€ ë¶„ë¥˜í•´ì•¼ í•  ë©”íƒ€ë°ì´í„°ì…ë‹ˆë‹¤ (í‚¤: ê°’ í˜•ì‹):\n",
    "{meta_text}\n",
    "\n",
    "ì´ë•Œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” 'í‚¤ ì´ë¦„' ëª©ë¡ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
    "{meta_keys}\n",
    "\n",
    "ë‹¹ì‹ ì˜ ì‘ì—…:\n",
    "ê° ë©”íƒ€ë°ì´í„°ì˜ \"í‚¤ ì´ë¦„\"ì„ ì •í™•íˆ í•˜ë‚˜ì˜ ì¹´í…Œê³ ë¦¬ì— ë°°ì •í•˜ì„¸ìš”.\n",
    "\n",
    "ì¶œë ¥ì€ ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ì„ ë”°ë¼ì•¼ í•©ë‹ˆë‹¤ (ì˜ˆì‹œëŠ” êµ¬ì¡°ë§Œ ì°¸ê³ ):\n",
    "\n",
    "{{\n",
    "  \"ê¸°ë³¸ì •ë³´\": [\"ì§€ì—­\", \"ì„±ë³„\"],\n",
    "  \"ë¯¸ë””ì–´\": [\"ì¡°ê±´\"],\n",
    "  \"ìŠ¤íŠ¸ë ˆìŠ¤\": [],\n",
    "  \"ê¸°íƒ€\": []\n",
    "}}\n",
    "\n",
    "ì¹´í…Œê³ ë¦¬ ì‘ì—… ê·œì¹™:\n",
    "1. ê° ë©”íƒ€ë°ì´í„° í‚¤ëŠ” ë°˜ë“œì‹œ 1ê°œì˜ ì¹´í…Œê³ ë¦¬ì—ë§Œ ì†í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "2. \"í‚¤: ê°’\" ì „ì²´ë¥¼ ì“°ì§€ ë§ê³ , ì˜¤ì§ 'í‚¤ ì´ë¦„'ë§Œ ì¨ì•¼ í•©ë‹ˆë‹¤.\n",
    "3. ê°’(value)ì´ë‚˜ ìƒˆë¡œìš´ ë¬¸ì¥, ì„¤ëª…ë¬¸, ì—¬ë¶„ì˜ í…ìŠ¤íŠ¸ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.\n",
    "4. ë°˜ë“œì‹œ ìœ„ì— ë‚˜ì—´ëœ í‚¤ ì´ë¦„ë§Œ ì‚¬ìš©í•˜ì„¸ìš”. ê°’ì´ë‚˜ ë¬¸ì¥ì„ JSONì— ë„£ìœ¼ë©´ ì•ˆ ë©ë‹ˆë‹¤.\n",
    "\"\"\"\n",
    "        return prompt.strip()\n",
    "\n",
    "    def _parse_llm_output(self, raw_output: str) -> Dict[str, List[str]]:\n",
    "        \"\"\"\n",
    "        LLMì´ ë°˜í™˜í•œ raw ë¬¸ìì—´ì„ JSONìœ¼ë¡œ íŒŒì‹±í•˜ê³ ,\n",
    "        {ì¹´í…Œê³ ë¦¬ëª…: [í† í°1, í† í°2, ...]} í˜•íƒœë¡œ ì •ê·œí™”.\n",
    "        (ì—¬ê¸°ì„œëŠ” 'í† í°'ì´ ì•„ì§ ì‹¤ì œ ë©”íƒ€ë°ì´í„° í‚¤ë¼ëŠ” ë³´ì¥ì€ ì—†ìŒ)\n",
    "        \"\"\"\n",
    "        # ```json ì½”ë“œë¸”ë¡ ì œê±°\n",
    "        if \"```json\" in raw_output:\n",
    "            try:\n",
    "                raw_output = raw_output.split(\"```json\", 1)[1].split(\"```\", 1)[0].strip()\n",
    "            except Exception:\n",
    "                # split ì‹¤íŒ¨ì‹œ ê·¸ëŒ€ë¡œ ì§„í–‰\n",
    "                pass\n",
    "        elif \"```\" in raw_output:\n",
    "            # ì¼ë°˜ ì½”ë“œë¸”ë¡ì¼ ê²½ìš°ë„ í•œ ë²ˆ ë°©ì–´\n",
    "            try:\n",
    "                raw_output = raw_output.split(\"```\", 1)[1].split(\"```\", 1)[0].strip()\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        # JSON íŒŒì‹±\n",
    "        parsed = json.loads(raw_output)\n",
    "\n",
    "        # ê°’ë“¤ì„ ì „ë¶€ ë¦¬ìŠ¤íŠ¸[str] í˜•íƒœë¡œ ì •ê·œí™”\n",
    "        mapping_tokens: Dict[str, List[str]] = {}\n",
    "        for cat, vals in parsed.items():\n",
    "            if isinstance(vals, list):\n",
    "                tokens = [str(v).strip() for v in vals if str(v).strip()]\n",
    "            elif isinstance(vals, str):\n",
    "                tokens = [vals.strip()] if vals.strip() else []\n",
    "            elif isinstance(vals, dict):\n",
    "                # dictê°€ ë‚˜ì˜¤ë©´ key/valueë¥¼ ë‹¤ í† í°ìœ¼ë¡œ ì“¸ ìˆ˜ ìˆì§€ë§Œ\n",
    "                # ì—¬ê¸°ì„œëŠ” keyë§Œ ì‚¬ìš©í•˜ëŠ” í¸ì´ ì•ˆì „í•¨\n",
    "                tokens = [str(k).strip() for k in vals.keys() if str(k).strip()]\n",
    "            else:\n",
    "                tokens = [str(vals).strip()]\n",
    "\n",
    "            if tokens:\n",
    "                mapping_tokens[cat] = tokens\n",
    "\n",
    "        return mapping_tokens\n",
    "\n",
    "    def _match_llm_token_to_key(\n",
    "        self,\n",
    "        token: str,\n",
    "        metadata: Dict[str, str],\n",
    "        used_keys: Set[str]\n",
    "    ) -> Optional[str]:\n",
    "        \"\"\"\n",
    "        LLMì´ JSONì— ë„£ì€ í† í°(ì˜ˆ: \"ì¡°ê±´\", \"OTT ì´ìš© 4ê°œ ì´ìƒ\", \"ì§€ì—­: ê²½ê¸°\")ì„\n",
    "        ì‹¤ì œ ë©”íƒ€ë°ì´í„° í‚¤ë¡œ ë§¤í•‘í•œë‹¤.\n",
    "        - ìš°ì„ ìˆœìœ„:\n",
    "          1) ì •í™•íˆ ê°™ì€ í‚¤ ì´ë¦„\n",
    "          2) \"í‚¤: ê°’\" í˜•ì‹ì—ì„œ í‚¤ ë¶€ë¶„ë§Œ ì¶”ì¶œ\n",
    "          3) ê°’(value)ì— ëŒ€í•œ ë¶€ë¶„ ë¬¸ìì—´ ë§¤ì¹­\n",
    "        \"\"\"\n",
    "        t = token.strip()\n",
    "        if not t:\n",
    "            return None\n",
    "\n",
    "        # 1) ì •í™•íˆ ê°™ì€ í‚¤ ì´ë¦„\n",
    "        if t in metadata and t not in used_keys:\n",
    "            return t\n",
    "\n",
    "        # 2) \"í‚¤: ê°’\" í˜•ì‹ìœ¼ë¡œ ì˜¨ ê²½ìš°\n",
    "        if \":\" in t:\n",
    "            left = t.split(\":\", 1)[0].strip()\n",
    "            if left in metadata and left not in used_keys:\n",
    "                return left\n",
    "\n",
    "        # 3) ê°’ ë¬¸ìì—´ê³¼ì˜ ìœ ì‚¬ ë§¤ì¹­\n",
    "        t_lower = t.lower()\n",
    "        for meta_key, meta_value in metadata.items():\n",
    "            if meta_key in used_keys:\n",
    "                continue\n",
    "            v_lower = str(meta_value).lower()\n",
    "\n",
    "            # (í† í° âŠ‚ ê°’) ë˜ëŠ” (ê°’ âŠ‚ í† í°)\n",
    "            if t_lower in v_lower or v_lower in t_lower:\n",
    "                return meta_key\n",
    "\n",
    "        # ë§¤ì¹­ ì‹¤íŒ¨\n",
    "        return None\n",
    "\n",
    "    def _rule_based_classify(self, metadata: Dict[str, str]) -> Dict[str, List[str]]:\n",
    "        \"\"\"ë°±ì—…ìš©: ê¸°ì¡´ í‚¤ì›Œë“œ ê¸°ë°˜ ê·œì¹™ ë¶„ë¥˜\"\"\"\n",
    "        categorized: Dict[str, List[str]] = {}\n",
    "        for meta_key, meta_value in metadata.items():\n",
    "            matched_categories = self._match_categories(meta_value)\n",
    "            for category in matched_categories:\n",
    "                categorized.setdefault(category, []).append(f\"{meta_key}: {meta_value}\")\n",
    "        return categorized\n",
    "\n",
    "    def _match_categories(self, value) -> List[str]:\n",
    "        matched: List[str] = []\n",
    "        if isinstance(value, list):\n",
    "            for item in value:\n",
    "                if isinstance(item, str):\n",
    "                    matched.extend(self._match_single_value(item))\n",
    "        elif isinstance(value, str):\n",
    "            matched = self._match_single_value(value)\n",
    "        return list(set(matched))\n",
    "\n",
    "    def _match_single_value(self, value: str) -> List[str]:\n",
    "        matched: List[str] = []\n",
    "        value_lower = value.lower()\n",
    "        for category_name, category_info in self.category_config.items():\n",
    "            for keyword in category_info.get(\"keywords\", []):\n",
    "                if keyword.lower() in value_lower:\n",
    "                    matched.append(category_name)\n",
    "                    break\n",
    "        return matched\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. í…ìŠ¤íŠ¸í™” (CategoryTextGenerator)\n",
    "\n",
    "ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë¶„ë¥˜ëœ ë©”íƒ€ë°ì´í„°ë¥¼ ìì—°ì–´ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… CategoryTextGenerator ì •ì˜ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "class CategoryTextGenerator:\n",
    "    \"\"\"ì¹´í…Œê³ ë¦¬ë³„ ë©”íƒ€ë°ì´í„°ë¥¼ ìì—°ì–´ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ (LLM ì‚¬ìš©)\"\"\"\n",
    "\n",
    "    def __init__(self, config: Config):\n",
    "        self.llm = ChatAnthropic(\n",
    "            model=config.llm_model,\n",
    "            temperature=0.3  # ì•½ê°„ì˜ ì°½ì˜ì„± í—ˆìš©\n",
    "        )\n",
    "\n",
    "        # ì¹´í…Œê³ ë¦¬ë³„ í…ìŠ¤íŠ¸ ìƒì„± í…œí”Œë¦¿\n",
    "        self.category_templates = {\n",
    "            \"ê¸°ë³¸ì •ë³´\": \"\"\"ë©”íƒ€ë°ì´í„°: {metadata}\n",
    "\n",
    "ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë²¡í„°DBì— ì €ì¥ëœ ìŠ¤íƒ€ì¼ë¡œ ìì—°ìŠ¤ëŸ¬ìš´ í•œ ë¬¸ì¥ì„ ìƒì„±í•˜ì„¸ìš”.\n",
    "\n",
    "ì°¸ê³  ì˜ˆì‹œ (ë²¡í„°DB ìŠ¤íƒ€ì¼):\n",
    "- \"ì„œìš¸ì— ê±°ì£¼í•˜ëŠ” 25ì„¸ ì—¬ì„±ìœ¼ë¡œ ë¯¸í˜¼ì´ë©°, 1ëª…ì˜ ê°€ì¡± êµ¬ì„±ì›ìœ¼ë¡œ í˜¼ì ê±°ì£¼í•˜ê³  ìˆìŠµë‹ˆë‹¤.\"\n",
    "- \"ë¶€ì‚°ì— ì‚¬ëŠ” 30ëŒ€ ë‚¨ì„±ìœ¼ë¡œ ê¸°í˜¼ì´ë©°, 3ëª…ì˜ ê°€ì¡±ê³¼ í•¨ê»˜ ê±°ì£¼í•©ë‹ˆë‹¤.\"\n",
    "- \"ê²½ê¸°ë„ì— ê±°ì£¼í•˜ëŠ” 42ì„¸ ì—¬ì„±ìœ¼ë¡œ ëŒ€í•™êµë¥¼ ì¡¸ì—…í–ˆìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "ê·œì¹™:\n",
    "1. ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±\n",
    "2. ì¡´ëŒ“ë§ ì‚¬ìš© (ì…ë‹ˆë‹¤/ìŠµë‹ˆë‹¤)\n",
    "3. ì§€ì—­, ë‚˜ì´, ì„±ë³„ ì •ë³´ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°\n",
    "4. ì¹´í…Œê³ ë¦¬ ì´ë¦„ì„ í¬í•¨í•˜ì§€ ë§ ê²ƒ\n",
    "\n",
    "ë¬¸ì¥ë§Œ ì¶œë ¥í•˜ì„¸ìš”:\"\"\",\n",
    "\n",
    "            \"ê±´ê°•\": \"\"\"ë©”íƒ€ë°ì´í„°: {metadata}\n",
    "\n",
    "ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê±´ê°•/ìš´ë™ ìŠµê´€ì— ëŒ€í•œ ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ì„ ìƒì„±í•˜ì„¸ìš”.\n",
    "\n",
    "ì°¸ê³  ì˜ˆì‹œ:\n",
    "- \"í—¬ìŠ¤ì¥ì—ì„œ ì£¼ 3íšŒ ì›¨ì´íŠ¸ íŠ¸ë ˆì´ë‹ì„ í•˜ë©° ì²´ë ¥ê´€ë¦¬ë¥¼ í•©ë‹ˆë‹¤.\"\n",
    "- \"ìš”ê°€ì™€ í•„ë¼í…ŒìŠ¤ë¥¼ ì¦ê¸°ë©° ê±´ê°•í•œ ë¼ì´í”„ìŠ¤íƒ€ì¼ì„ ìœ ì§€í•©ë‹ˆë‹¤.\"\n",
    "- \"ì¡°ê¹…ê³¼ ë“±ì‚°ì„ í†µí•´ ê¾¸ì¤€íˆ ìš´ë™í•˜ê³  ìˆìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "ê·œì¹™:\n",
    "1. ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ ë¬¸ì¥\n",
    "2. ì¡´ëŒ“ë§ ì‚¬ìš©\n",
    "3. ìš´ë™/ê±´ê°• í™œë™ì„ êµ¬ì²´ì ìœ¼ë¡œ í‘œí˜„\n",
    "\n",
    "ë¬¸ì¥ë§Œ ì¶œë ¥í•˜ì„¸ìš”:\"\"\",\n",
    "\n",
    "            \"ì§ì—…ì†Œë“\": \"\"\"ë©”íƒ€ë°ì´í„°: {metadata}\n",
    "\n",
    "ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë²¡í„°DBì— ì €ì¥ëœ ìŠ¤íƒ€ì¼ë¡œ ì§ì—…ê³¼ ì†Œë“ì— ëŒ€í•œ ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ì„ ìƒì„±í•˜ì„¸ìš”. ì§ì—…ê³¼ ì†Œë“ ì¤‘ ì¡´ì¬í•˜ëŠ” ë©”íƒ€ë°ì´í„°ë¡œë§Œ ë¬¸ì¥ì„ ìƒì„±í•˜ì„¸ìš”.\n",
    "\n",
    "ì°¸ê³  ì˜ˆì‹œ (ë²¡í„°DB ìŠ¤íƒ€ì¼):\n",
    "- \"í˜„ì¬ ëŒ€í•™ìƒ/ëŒ€í•™ì›ìƒìœ¼ë¡œ í™œë™í•˜ê³  ìˆìŠµë‹ˆë‹¤.\"\n",
    "- \"ì›”í‰ê·  ê°œì¸ì†Œë“ì€ 100ë§Œì› ë¯¸ë§Œì…ë‹ˆë‹¤. ê°€êµ¬ì†Œë“ ì—­ì‹œ ì›” 100ë§Œì› ë¯¸ë§Œìœ¼ë¡œ ë‚˜íƒ€ë‚©ë‹ˆë‹¤.\"\n",
    "- \"íšŒì‚¬ì›ìœ¼ë¡œ ê·¼ë¬´í•˜ê³  ìˆìŠµë‹ˆë‹¤.\"\n",
    "- \"ì›”í‰ê·  ê°œì¸ì†Œë“ì€ 300ë§Œì›ëŒ€ì…ë‹ˆë‹¤.\"\n",
    "\n",
    "ê·œì¹™:\n",
    "1. ì§ì—…, ê°œì¸ì†Œë“, ê°€êµ¬ì†Œë“ ì •ë³´ë¥¼ í¬í•¨\n",
    "2. ì¡´ëŒ“ë§ ì‚¬ìš© (ì…ë‹ˆë‹¤/ìŠµë‹ˆë‹¤)\n",
    "3. êµ¬ì²´ì ì¸ ê¸ˆì•¡ ë²”ìœ„ í‘œí˜„\n",
    "\n",
    "ë¬¸ì¥ë§Œ ì¶œë ¥í•˜ì„¸ìš”:\"\"\",\n",
    "\n",
    "            \"ì „ìì œí’ˆ\": \"\"\"ë©”íƒ€ë°ì´í„°: {metadata}\n",
    "\n",
    "ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë²¡í„°DBì— ì €ì¥ëœ ìŠ¤íƒ€ì¼ë¡œ ì „ìì œí’ˆ ë³´ìœ  í˜„í™©ì— ëŒ€í•œ ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ì„ ìƒì„±í•˜ì„¸ìš”.\n",
    "\n",
    "ì°¸ê³  ì˜ˆì‹œ (ë²¡í„°DB ìŠ¤íƒ€ì¼):\n",
    "- \"ëƒ‰ì¥ê³ , ì„¸íƒê¸°, ì—ì–´ì»¨, ì œìŠµê¸°, ë¬´ì„ ì²­ì†Œê¸°, ì»¤í”¼ ë¨¸ì‹ , ì—ì–´í”„ë¼ì´ê¸°, ë…¸íŠ¸ë¶, íƒœë¸”ë¦¿PC, ìŠ¤ë§ˆíŠ¸ ì›Œì¹˜ ë“± ë‹¤ì–‘í•œ ì „ìì œí’ˆì„ ë³´ìœ í•˜ê³  ìˆìŠµë‹ˆë‹¤. íœ´ëŒ€í°ì€ ì• í”Œ ì•„ì´í° 13/13 mini ëª¨ë¸ì„ ì‚¬ìš©í•˜ê³  ìˆìŠµë‹ˆë‹¤.\"\n",
    "- \"ë…¸íŠ¸ë¶, íƒœë¸”ë¦¿PCë¥¼ ë³´ìœ í•˜ê³  ìˆìœ¼ë©°, íœ´ëŒ€í°ì€ ì‚¼ì„± ê°¤ëŸ­ì‹œ S21 ëª¨ë¸ì„ ì‚¬ìš©í•˜ê³  ìˆìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "ê·œì¹™:\n",
    "1. ë³´ìœ í•œ ì „ìì œí’ˆì„ ë‚˜ì—´ì‹ìœ¼ë¡œ í‘œí˜„\n",
    "2. íœ´ëŒ€í° ëª¨ë¸ì€ êµ¬ì²´ì ìœ¼ë¡œ ëª…ì‹œ\n",
    "3. ì¡´ëŒ“ë§ ì‚¬ìš© (ì…ë‹ˆë‹¤)\n",
    "\n",
    "ë¬¸ì¥ë§Œ ì¶œë ¥í•˜ì„¸ìš”:\"\"\",\n",
    "\n",
    "            \"ìë™ì°¨\": \"\"\"ë©”íƒ€ë°ì´í„°: {metadata}\n",
    "\n",
    "ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë²¡í„°DBì— ì €ì¥ëœ ìŠ¤íƒ€ì¼ë¡œ ìë™ì°¨ ë³´ìœ ì— ëŒ€í•œ ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ì„ ìƒì„±í•˜ì„¸ìš”.\n",
    "\n",
    "ì°¸ê³  ì˜ˆì‹œ (ë²¡í„°DB ìŠ¤íƒ€ì¼):\n",
    "- \"ì§€í”„ ì»´íŒ¨ìŠ¤ ëª¨ë¸ì˜ ìë™ì°¨ë¥¼ ë³´ìœ í•˜ê³  ìˆìŠµë‹ˆë‹¤.\"\n",
    "- \"í˜„ëŒ€ ê·¸ëœì € ëª¨ë¸ì˜ ìë™ì°¨ë¥¼ ë³´ìœ í•˜ê³  ìˆìŠµë‹ˆë‹¤.\"\n",
    "- \"ê¸°ì•„ K5ì™€ í˜„ëŒ€ ì˜ë‚˜íƒ€ ë‘ ëŒ€ì˜ ìë™ì°¨ë¥¼ ë³´ìœ í•˜ê³  ìˆìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "ê·œì¹™:\n",
    "1. ë¸Œëœë“œì™€ ëª¨ë¸ëª…ì„ êµ¬ì²´ì ìœ¼ë¡œ í‘œí˜„\n",
    "2. ì¡´ëŒ“ë§ ì‚¬ìš© (ì…ë‹ˆë‹¤)\n",
    "3. ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ì‘ì„±\n",
    "\n",
    "ë¬¸ì¥ë§Œ ì¶œë ¥í•˜ì„¸ìš”:\"\"\",\n",
    "\n",
    "            \"í¡ì—°\": \"\"\"ë©”íƒ€ë°ì´í„°: {metadata}\n",
    "\n",
    "ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë²¡í„°DBì— ì €ì¥ëœ ìŠ¤íƒ€ì¼ë¡œ í¡ì—° ìŠµê´€ì— ëŒ€í•œ ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ì„ ìƒì„±í•˜ì„¸ìš”.\n",
    "\n",
    "ì°¸ê³  ì˜ˆì‹œ (ë²¡í„°DB ìŠ¤íƒ€ì¼):\n",
    "- \"ì¼ë°˜ ë‹´ë°°, ê¶ë ¨í˜• ì „ìë‹´ë°°, ì•¡ìƒí˜• ì „ìë‹´ë°° ë“± ë‹¤ì–‘í•œ í¡ì—° ê²½í—˜ì´ ìˆìœ¼ë©°, ë§ë³´ë¡œ ë‹´ë°°ì™€ ê¸€ë¡œ ê°€ì—´ì‹ ë‹´ë°°ë¥¼ ì‚¬ìš©í•œ ê²½í—˜ì´ ìˆìŠµë‹ˆë‹¤.\"\n",
    "- \"ì¼ë°˜ ë‹´ë°°, ê¶ë ¨í˜• ì „ìë‹´ë°°, ì•¡ìƒí˜• ì „ìë‹´ë°° ë“± ë‹¤ì–‘í•œ í¡ì—° ê²½í—˜ì´ ìˆìŠµë‹ˆë‹¤. ë””ìŠ¤í”ŒëŸ¬ìŠ¤, ë§ë³´ë¡œ, íŒ”ë¦¬ì•„ë©˜íŠ¸, ë˜í ë“±ì˜ ë‹´ë°° ë¸Œëœë“œë¥¼ ì‚¬ìš©í–ˆìœ¼ë©°, ì•„ì´ì½”ìŠ¤ì™€ ê¸€ë¡œ ê°™ì€ ê¶ë ¨í˜• ì „ìë‹´ë°°ë„ ì´ìš©í•œ ê²½í—˜ì´ ìˆìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "ê·œì¹™:\n",
    "1. í¡ì—° ì œí’ˆ ì¢…ë¥˜ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ë‚˜ì—´ (ì¼ë°˜ ë‹´ë°°, ê¶ë ¨í˜• ì „ìë‹´ë°°, ì•¡ìƒí˜• ì „ìë‹´ë°° ë“±)\n",
    "2. ë¸Œëœë“œëª…ì„ í¬í•¨í•  ê²½ìš° êµ¬ì²´ì ìœ¼ë¡œ í‘œí˜„\n",
    "3. ì¡´ëŒ“ë§ ì‚¬ìš© (ì…ë‹ˆë‹¤)\n",
    "\n",
    "ë¬¸ì¥ë§Œ ì¶œë ¥í•˜ì„¸ìš”:\"\"\",\n",
    "\n",
    "            \"ìŒì£¼\": \"\"\"ë©”íƒ€ë°ì´í„°: {metadata}\n",
    "\n",
    "ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë²¡í„°DBì— ì €ì¥ëœ ìŠ¤íƒ€ì¼ë¡œ ìŒì£¼ ìŠµê´€ì— ëŒ€í•œ ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ì„ ìƒì„±í•˜ì„¸ìš”.\n",
    "\n",
    "ì°¸ê³  ì˜ˆì‹œ (ë²¡í„°DB ìŠ¤íƒ€ì¼):\n",
    "- \"ì†Œì£¼ë¥¼ ìŒìš©í•œ ê²½í—˜ì´ ìˆìŠµë‹ˆë‹¤.\"\n",
    "- \"ì†Œì£¼, ë§¥ì£¼, ì €ë„ì£¼, ë§‰ê±¸ë¦¬/íƒì£¼, ì–‘ì£¼, ì™€ì¸, ê³¼ì¼ì¹µí…Œì¼ì£¼ ë“± ë‹¤ì–‘í•œ ì¢…ë¥˜ì˜ ìˆ ì„ ìŒìš©í•œ ê²½í—˜ì´ ìˆìŠµë‹ˆë‹¤.\"\n",
    "- \"ìµœê·¼ 1ë…„ ì´ë‚´ì— ìˆ ì„ ë§ˆì‹œì§€ ì•Šì•˜ìœ¼ë©°, í˜„ì¬ ìŒì£¼ í™œë™ì´ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "ê·œì¹™:\n",
    "1. ìŒì£¼ ì¢…ë¥˜ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ë‚˜ì—´ (ì†Œì£¼, ë§¥ì£¼, ì™€ì¸ ë“±)\n",
    "2. ìŒì£¼ ë¹ˆë„ë‚˜ ìƒíƒœë¥¼ ëª…í™•í•˜ê²Œ í‘œí˜„\n",
    "3. ì¡´ëŒ“ë§ ì‚¬ìš© (ì…ë‹ˆë‹¤)\n",
    "\n",
    "ë¬¸ì¥ë§Œ ì¶œë ¥í•˜ì„¸ìš”:\"\"\",\n",
    "\n",
    "            \"ìŠ¤íŠ¸ë ˆìŠ¤\": \"\"\"ë©”íƒ€ë°ì´í„°: {metadata}\n",
    "\n",
    "ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë²¡í„°DBì— ì €ì¥ëœ ìŠ¤íƒ€ì¼ë¡œ ìŠ¤íŠ¸ë ˆìŠ¤ì— ëŒ€í•œ ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ì„ ìƒì„±í•˜ì„¸ìš”.\n",
    "\n",
    "ì°¸ê³  ì˜ˆì‹œ (ë²¡í„°DB ìŠ¤íƒ€ì¼):\n",
    "- \"ìŠ¤íŠ¸ë ˆìŠ¤ë¥¼ ê°€ì¥ ë§ì´ ëŠë¼ëŠ” ìƒí™©ì€ ì¸ê°„ê´€ê³„ (ê°€ì¡±, ì¹œêµ¬, ì§ì¥ ë“±)ì…ë‹ˆë‹¤.\"\n",
    "- \"ìŠ¤íŠ¸ë ˆìŠ¤ë¥¼ ë°›ì„ ë•Œ ì£¼ë¡œ ìˆ˜ë©´í•˜ë©° í•´ì†Œí•©ë‹ˆë‹¤.\"\n",
    "- \"ì´ì‚¬í•  ë•Œ ê°€ì¥ ìŠ¤íŠ¸ë ˆìŠ¤ë¥¼ ë°›ëŠ” ë¶€ë¶„ì€ ë¹„ìš© ë¶€ë‹´ì…ë‹ˆë‹¤.\"\n",
    "\n",
    "ê·œì¹™:\n",
    "1. ìŠ¤íŠ¸ë ˆìŠ¤ ìƒí™©ì„ êµ¬ì²´ì ìœ¼ë¡œ ëª…ì‹œ (ì¸ê°„ê´€ê³„, ì—…ë¬´, ì´ì‚¬ ë“±)\n",
    "2. ìŠ¤íŠ¸ë ˆìŠ¤ í•´ì†Œ ë°©ë²•ì´ë‚˜ ì›ì¸ì„ ëª…í™•í•˜ê²Œ í‘œí˜„\n",
    "3. ì¡´ëŒ“ë§ ì‚¬ìš© (ì…ë‹ˆë‹¤)\n",
    "\n",
    "ë¬¸ì¥ë§Œ ì¶œë ¥í•˜ì„¸ìš”:\"\"\",\n",
    "\n",
    "            \"ë¯¸ìš©\": \"\"\"ë©”íƒ€ë°ì´í„°: {metadata}\n",
    "\n",
    "ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë²¡í„°DBì— ì €ì¥ëœ ìŠ¤íƒ€ì¼ë¡œ ë·°í‹°(ë¯¸ìš©)ì— ëŒ€í•œ ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ì„ ìƒì„±í•˜ì„¸ìš”.\n",
    "\n",
    "ì°¸ê³  ì˜ˆì‹œ (ë²¡í„°DB ìŠ¤íƒ€ì¼):\n",
    "- \"ë³¸ì¸ì˜ í”¼ë¶€ ìƒíƒœëŠ” ë³´í†µì´ë‹¤ì…ë‹ˆë‹¤.\"\n",
    "- \"í•œ ë‹¬ ê¸°ì¤€ìœ¼ë¡œ ìŠ¤í‚¨ì¼€ì–´ ì œí’ˆì— í‰ê· ì ìœ¼ë¡œ 3ë§Œì› ë¯¸ë§Œì„ ì†Œë¹„í•©ë‹ˆë‹¤.\"\n",
    "- \"ìŠ¤í‚¨ì¼€ì–´ ì œí’ˆì„ êµ¬ë§¤í•  ë•Œ ê°€ì¥ ì¤‘ìš”í•˜ê²Œ ê³ ë ¤í•˜ëŠ” ìš”ì†ŒëŠ” ì¹œí™˜ê²½/ë¹„ê±´ ì œí’ˆ ì—¬ë¶€ì…ë‹ˆë‹¤.\"\n",
    "\n",
    "ê·œì¹™:\n",
    "1. í”¼ë¶€ ìƒíƒœ, ìŠ¤í‚¨ì¼€ì–´ ì†Œë¹„ ê¸ˆì•¡, êµ¬ë§¤ ê³ ë ¤ ìš”ì†Œ ë“±ì„ êµ¬ì²´ì ìœ¼ë¡œ ëª…ì‹œ\n",
    "2. ë·°í‹° ê´€ë ¨ í‘œí˜„ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì‚¬ìš©\n",
    "3. ì¡´ëŒ“ë§ ì‚¬ìš© (ì…ë‹ˆë‹¤)\n",
    "\n",
    "ë¬¸ì¥ë§Œ ì¶œë ¥í•˜ì„¸ìš”:\"\"\",\n",
    "\n",
    "            \"ì†Œë¹„\": \"\"\"ë©”íƒ€ë°ì´í„°: {metadata}\n",
    "\n",
    "ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë²¡í„°DBì— ì €ì¥ëœ ìŠ¤íƒ€ì¼ë¡œ ì†Œë¹„ ìŠµê´€ì— ëŒ€í•œ ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ì„ ìƒì„±í•˜ì„¸ìš”.\n",
    "\n",
    "ì°¸ê³  ì˜ˆì‹œ (ë²¡í„°DB ìŠ¤íƒ€ì¼):\n",
    "- \"ì „í†µì‹œì¥ì„ ë°©ë¬¸í•˜ëŠ” ë¹ˆë„ëŠ” í•œë‹¬ì— 1íšŒ ì´ìƒì…ë‹ˆë‹¤.\"\n",
    "- \"ê°€ì¥ ì„ í˜¸í•˜ëŠ” ì„¤ ì„ ë¬¼ ìœ í˜•ì€ ë°±í™”ì  ìƒí’ˆê¶Œ/í˜„ê¸ˆì…ë‹ˆë‹¤.\"\n",
    "- \"ë³¸ì¸ì„ ìœ„í•´ ì†Œë¹„í•  ë•Œ ê°€ì¥ ê¸°ë¶„ ì¢‹ì•„ì§€ëŠ” ì†Œë¹„ëŠ” ì—¬í–‰ ê°€ê¸°ì…ë‹ˆë‹¤.\"\n",
    "- \"ë¹ ë¥¸ ë°°ì†¡ ì„œë¹„ìŠ¤ë¥¼ ì£¼ë¡œ ì´ìš©í•˜ëŠ” ì œí’ˆì€ ë¹ ë¥¸ ë°°ì†¡ ì„œë¹„ìŠ¤ë¥¼ ì´ìš©í•´ ë³¸ ì  ì—†ë‹¤ì…ë‹ˆë‹¤.\"\n",
    "- \"ìµœê·¼ ê°€ì¥ ì§€ì¶œì„ ë§ì´ í•œ ê³³ì€ ì½˜ì„œíŠ¸, ì „ì‹œ ë“± ë¬¸í™”ìƒí™œì…ë‹ˆë‹¤.\"\n",
    "- \"í¬ì¸íŠ¸ ì ë¦½ì´ë‚˜ í• ì¸ í˜œíƒì— ëŒ€í•œ ê´€ì‹¬ ì •ë„ëŠ” ìì£¼ ì“°ëŠ” ê³³ë§Œ ì±™ê¸´ë‹¤ì…ë‹ˆë‹¤.\"\n",
    "\n",
    "ê·œì¹™:\n",
    "1. ì†Œë¹„ ë¹ˆë„, ì„ í˜¸ë„, ì§€ì¶œ í•­ëª© ë“±ì„ êµ¬ì²´ì ìœ¼ë¡œ ëª…ì‹œ\n",
    "2. ì†Œë¹„ íŒ¨í„´ì„ ìì—°ìŠ¤ëŸ½ê²Œ í‘œí˜„\n",
    "3. ì¡´ëŒ“ë§ ì‚¬ìš© (ì…ë‹ˆë‹¤)\n",
    "\n",
    "ë¬¸ì¥ë§Œ ì¶œë ¥í•˜ì„¸ìš”:\"\"\",\n",
    "            \"ë¯¸ë””ì–´\": \"\"\"ë©”íƒ€ë°ì´í„°: {metadata}\n",
    "\n",
    "ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë²¡í„°DBì— ì €ì¥ëœ ìŠ¤íƒ€ì¼ë¡œ ë¯¸ë””ì–´ ì†Œë¹„ ìŠµê´€ì— ëŒ€í•œ ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ì„ ìƒì„±í•˜ì„¸ìš”.\n",
    "\n",
    "ì°¸ê³  ì˜ˆì‹œ (ë²¡í„°DB ìŠ¤íƒ€ì¼):\n",
    "- \"í˜„ì¬ ì´ìš© ì¤‘ì¸ OTT ì„œë¹„ìŠ¤ì˜ ê°œìˆ˜ëŠ” 2ê°œì…ë‹ˆë‹¤.\"\n",
    "- \"ìš”ì¦˜ ê°€ì¥ ë§ì´ ì‚¬ìš©í•˜ëŠ” ì•±ì€ SNS ì•± (ì¸ìŠ¤íƒ€ê·¸ë¨, í˜ì´ìŠ¤ë¶, í‹±í†¡ ë“±)ì…ë‹ˆë‹¤.\"\n",
    "\n",
    "ê·œì¹™:\n",
    "1. OTT ì„œë¹„ìŠ¤ ê°œìˆ˜, ì£¼ë¡œ ì‚¬ìš©í•˜ëŠ” ì•± ë“±ì„ êµ¬ì²´ì ìœ¼ë¡œ ëª…ì‹œ\n",
    "2. ë¯¸ë””ì–´ ì†Œë¹„ íŒ¨í„´ì„ ìì—°ìŠ¤ëŸ½ê²Œ í‘œí˜„\n",
    "3. ì¡´ëŒ“ë§ ì‚¬ìš© (ì…ë‹ˆë‹¤)\n",
    "\n",
    "ë¬¸ì¥ë§Œ ì¶œë ¥í•˜ì„¸ìš”:\"\"\",\n",
    "\n",
    "            \"AIì„œë¹„ìŠ¤\": \"\"\"ë©”íƒ€ë°ì´í„°: {metadata}\n",
    "\n",
    "ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë²¡í„°DBì— ì €ì¥ëœ ìŠ¤íƒ€ì¼ë¡œ AI ì„œë¹„ìŠ¤ ì‚¬ìš©ì— ëŒ€í•œ ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ì„ ìƒì„±í•˜ì„¸ìš”.\n",
    "\n",
    "ì°¸ê³  ì˜ˆì‹œ (ë²¡í„°DB ìŠ¤íƒ€ì¼):\n",
    "- \"ì‚¬ìš©í•´ ë³¸ AI ì±—ë´‡ ì„œë¹„ìŠ¤ëŠ” Copilot (ë§ˆì´í¬ë¡œì†Œí”„íŠ¸), Gemini (êµ¬ê¸€)ì…ë‹ˆë‹¤.\"\n",
    "- \"ì£¼ë¡œ ì‚¬ìš©í•˜ëŠ” AI ì±—ë´‡ ì„œë¹„ìŠ¤ëŠ” Copilot (ë§ˆì´í¬ë¡œì†Œí”„íŠ¸)ì…ë‹ˆë‹¤.\"\n",
    "- \"AI ì±—ë´‡ ì„œë¹„ìŠ¤ë¥¼ ì£¼ë¡œ í™œìš©í•˜ëŠ” ìš©ë„ëŠ” ê¸°íƒ€ì…ë‹ˆë‹¤.\"\n",
    "- \"ë”¥ì‹œí¬ì™€ chatGPT ë‘ ì„œë¹„ìŠ¤ ì¤‘ ë” í˜¸ê°ì´ ê°€ëŠ” ê²ƒì€ ChatGPTì…ë‹ˆë‹¤.\"\n",
    "- \"AI ì„œë¹„ìŠ¤ë¥¼ í™œìš©í•˜ëŠ” ì£¼ìš” ë¶„ì•¼ëŠ” ì´ë¯¸ì§€ ìƒì„± ë˜ëŠ” ë””ìì¸ ì°¸ê³ ì…ë‹ˆë‹¤.\"\n",
    "\n",
    "ê·œì¹™:\n",
    "1. ì‚¬ìš©í•œ AI ì±—ë´‡ ì„œë¹„ìŠ¤, ì£¼ë¡œ ì‚¬ìš©í•˜ëŠ” ì„œë¹„ìŠ¤, í™œìš© ìš©ë„ ë“±ì„ êµ¬ì²´ì ìœ¼ë¡œ ëª…ì‹œ\n",
    "2. AI ì„œë¹„ìŠ¤ í™œìš© íŒ¨í„´ì„ ìì—°ìŠ¤ëŸ½ê²Œ í‘œí˜„\n",
    "3. ì¡´ëŒ“ë§ ì‚¬ìš© (ì…ë‹ˆë‹¤)\n",
    "\n",
    "ë¬¸ì¥ë§Œ ì¶œë ¥í•˜ì„¸ìš”:\"\"\",\n",
    "        }\n",
    "\n",
    "        # ê¸°ë³¸ í…œí”Œë¦¿ (ì¹´í…Œê³ ë¦¬ê°€ ì •ì˜ë˜ì§€ ì•Šì€ ê²½ìš°)\n",
    "        self.default_template = \"\"\"ë©”íƒ€ë°ì´í„°: {metadata}\n",
    "\n",
    "ìœ„ ì •ë³´ë¥¼ ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ ë¬¸ì¥ìœ¼ë¡œ ë³€í™˜í•˜ì„¸ìš”.\n",
    "ì¡´ëŒ“ë§ì„ ì‚¬ìš©í•˜ê³ , ì¹´í…Œê³ ë¦¬ ì´ë¦„ì„ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.\n",
    "\n",
    "ë¬¸ì¥ë§Œ ì¶œë ¥í•˜ì„¸ìš”:\"\"\"\n",
    "\n",
    "    def generate_texts(self, categorized: Dict[str, List[str]]) -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        ì¹´í…Œê³ ë¦¬ë³„ í…ìŠ¤íŠ¸ ìƒì„± (LLM ì‚¬ìš©)\n",
    "\n",
    "        Args:\n",
    "            categorized: {\"ì¹´í…Œê³ ë¦¬ëª…\": [\"ë©”íƒ€ë°ì´í„°1\", ...]}\n",
    "\n",
    "        Returns:\n",
    "            {\"ì¹´í…Œê³ ë¦¬ëª…\": \"ìì—°ì–´ í…ìŠ¤íŠ¸\"}\n",
    "        \"\"\"\n",
    "        texts = {}\n",
    "\n",
    "        for category, metadata_list in categorized.items():\n",
    "            # LLMìœ¼ë¡œ ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ ìƒì„±\n",
    "            text = self._generate_text_with_llm(category, metadata_list)\n",
    "            texts[category] = text\n",
    "\n",
    "        return texts\n",
    "\n",
    "    def _generate_text_with_llm(self, category: str, metadata_list: List[str]) -> str:\n",
    "        \"\"\"LLMì„ ì‚¬ìš©í•˜ì—¬ ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ ìƒì„±\"\"\"\n",
    "        try:\n",
    "            # ë©”íƒ€ë°ì´í„°ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜\n",
    "            metadata_str = \", \".join(metadata_list)\n",
    "\n",
    "            # ì¹´í…Œê³ ë¦¬ì— ë§ëŠ” í…œí”Œë¦¿ ì„ íƒ\n",
    "            template = self.category_templates.get(category, self.default_template)\n",
    "\n",
    "            # í”„ë¡¬í”„íŠ¸ ìƒì„±\n",
    "            prompt = template.format(metadata=metadata_str)\n",
    "\n",
    "            # LLM í˜¸ì¶œ\n",
    "            response = self.llm.invoke(prompt)\n",
    "            text = response.content.strip()\n",
    "\n",
    "            # ë”°ì˜´í‘œë‚˜ ë§ˆí¬ë‹¤ìš´ ì œê±°\n",
    "            text = text.replace('\"', '').replace(\"'\", '').replace('```', '').strip()\n",
    "\n",
    "            return text\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ í…ìŠ¤íŠ¸ ìƒì„± ì‹¤íŒ¨ ({category}): {e}\")\n",
    "            # ì‹¤íŒ¨ ì‹œ ë‹¨ìˆœ ì—°ê²°\n",
    "            return \", \".join(metadata_list)\n",
    "\n",
    "print(\"âœ… CategoryTextGenerator ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ì„ë² ë”© ìƒì„±ê¸° (EmbeddingGenerator)\n",
    "\n",
    "Upstage Solar-Large ëª¨ë¸ë¡œ ì¹´í…Œê³ ë¦¬ë³„ í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… EmbeddingGenerator ì •ì˜ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "class EmbeddingGenerator:\n",
    "    \"\"\"Upstage Solar-Largeë¡œ ì„ë² ë”© ìƒì„±\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Config):\n",
    "        self.embeddings = UpstageEmbeddings(\n",
    "            model=config.embedding_model\n",
    "        )\n",
    "    \n",
    "    def generate_embeddings(self, texts: Dict[str, str]) -> Dict[str, List[float]]:\n",
    "        \"\"\"\n",
    "        ì¹´í…Œê³ ë¦¬ë³„ í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜\n",
    "        \n",
    "        Args:\n",
    "            texts: {\"ì¹´í…Œê³ ë¦¬ëª…\": \"í…ìŠ¤íŠ¸\"}\n",
    "        \n",
    "        Returns:\n",
    "            {\"ì¹´í…Œê³ ë¦¬ëª…\": [ë²¡í„°]}\n",
    "        \"\"\"\n",
    "        embeddings_dict = {}\n",
    "        \n",
    "        for category, text in texts.items():\n",
    "            # í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜\n",
    "            embedding = self.embeddings.embed_query(text)\n",
    "            embeddings_dict[category] = embedding\n",
    "            \n",
    "            print(f\"  - {category}: ì„ë² ë”© ìƒì„± ì™„ë£Œ (ì°¨ì›: {len(embedding)})\")\n",
    "        \n",
    "        return embeddings_dict\n",
    "\n",
    "print(\"âœ… EmbeddingGenerator ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Pinecone ê²€ìƒ‰ê¸° (PineconeSearcher)\n",
    "\n",
    "ì¹´í…Œê³ ë¦¬ë³„ ì„ë² ë”©ìœ¼ë¡œ Pinecone ë²¡í„°DB ê²€ìƒ‰ (index, topic ì°¸ì¡°)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… PineconeSearcher ë° ResultFilter ì •ì˜ ì™„ë£Œ (ë©”íƒ€ë°ì´í„° í•„í„° Fallback ì§€ì›)\n"
     ]
    }
   ],
   "source": [
    "class PineconeSearcher:\n",
    "    \"\"\"Pinecone ë²¡í„°DB ê²€ìƒ‰ (ì „ì²´ topic ë©”íƒ€ë°ì´í„° í•„í„° ì§€ì› + Fallback)\"\"\"\n",
    "\n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "\n",
    "        # Pinecone ì´ˆê¸°í™”\n",
    "        pc = Pinecone(api_key=os.environ.get(\"PINECONE_API_KEY\"))\n",
    "        self.index = pc.Index(config.pinecone_index_name)\n",
    "\n",
    "        print(f\"âœ… Pinecone Index ì—°ê²°: {config.pinecone_index_name}\")\n",
    "\n",
    "    def search_by_category(\n",
    "        self,\n",
    "        query_embedding: List[float],\n",
    "        category: str,\n",
    "        top_k: int,\n",
    "        filter_mb_sns: List[str] = None,\n",
    "        metadata_filter: Dict[str, Any] = None\n",
    "    ) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        íŠ¹ì • ì¹´í…Œê³ ë¦¬ë¡œ Pinecone ê²€ìƒ‰ (ë©”íƒ€ë°ì´í„° í•„í„° + Fallback ì§€ì›)\n",
    "\n",
    "        Args:\n",
    "            query_embedding: ì¿¼ë¦¬ ì„ë² ë”© ë²¡í„°\n",
    "            category: ê²€ìƒ‰í•  ì¹´í…Œê³ ë¦¬ (ì˜ˆ: \"ê¸°ë³¸ì •ë³´\", \"ì§ì—…ì†Œë“\", \"ìë™ì°¨\")\n",
    "            top_k: ê²€ìƒ‰ ê²°ê³¼ ê°œìˆ˜\n",
    "            filter_mb_sns: í•„í„°ë§í•  mb_sn ë¦¬ìŠ¤íŠ¸ (ì´ ì¤‘ì—ì„œë§Œ ê²€ìƒ‰)\n",
    "            metadata_filter: Pinecone ë©”íƒ€ë°ì´í„° í•„í„° (topicë³„ë¡œ ë‹¤ë¦„)\n",
    "\n",
    "        Returns:\n",
    "            [{\"id\": ..., \"score\": ..., \"mb_sn\": ..., \"index\": ..., \"topic\": ..., \"text\": ...}]\n",
    "        \"\"\"\n",
    "        # top_k ìœ íš¨ì„± ê²€ì‚¬\n",
    "        if top_k <= 0:\n",
    "            print(f\"âš ï¸ top_kê°€ 0 ì´í•˜ì…ë‹ˆë‹¤ ({top_k}). ë¹ˆ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\")\n",
    "            return []\n",
    "        \n",
    "        # í›„ë³´ mb_snì´ ë¹„ì–´ìˆëŠ” ê²½ìš° ì²˜ë¦¬\n",
    "        if filter_mb_sns is not None and len(filter_mb_sns) == 0:\n",
    "            print(f\"âš ï¸ í•„í„°ë§í•  mb_snì´ ì—†ìŠµë‹ˆë‹¤. ë¹ˆ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\")\n",
    "            return []\n",
    "        \n",
    "        # ì¹´í…Œê³ ë¦¬ì— í•´ë‹¹í•˜ëŠ” Pinecone topic ê°€ì ¸ì˜¤ê¸°\n",
    "        pinecone_topic = CATEGORY_CONFIG.get(category, {}).get(\"pinecone_topic\", category)\n",
    "\n",
    "        # ê¸°ë³¸ í•„í„°: topic\n",
    "        filter_dict = {\"topic\": pinecone_topic}\n",
    "        \n",
    "        # mb_sn í•„í„° ì¶”ê°€ (ì´ì „ ë‹¨ê³„ì—ì„œ ì„ ë³„ëœ mb_snë“¤ë¡œ ì œí•œ)\n",
    "        if filter_mb_sns:\n",
    "            filter_dict[\"mb_sn\"] = {\"$in\": filter_mb_sns}\n",
    "\n",
    "        # ğŸ¯ 1ì°¨ ì‹œë„: ë©”íƒ€ë°ì´í„° í•„í„° ì ìš©\n",
    "        if metadata_filter:\n",
    "            print(f\"  [ë©”íƒ€ë°ì´í„° í•„í„° í™œì„±í™”] {category}: {metadata_filter}\")\n",
    "            filter_with_metadata = filter_dict.copy()\n",
    "            filter_with_metadata.update(metadata_filter)\n",
    "            \n",
    "            # Pinecone ê²€ìƒ‰ (ë©”íƒ€ë°ì´í„° í•„í„° í¬í•¨)\n",
    "            search_results = self.index.query(\n",
    "                vector=query_embedding,\n",
    "                top_k=top_k,\n",
    "                include_metadata=True,\n",
    "                filter=filter_with_metadata\n",
    "            )\n",
    "            \n",
    "            # ğŸ”„ Fallback: ê²°ê³¼ê°€ 0ê°œë©´ ë©”íƒ€ë°ì´í„° í•„í„° ì—†ì´ ì¬ê²€ìƒ‰\n",
    "            if len(search_results.matches) == 0:\n",
    "                print(f\"  âš ï¸ ë©”íƒ€ë°ì´í„° í•„í„°ë¡œ 0ê±´ ê²€ìƒ‰ë¨ â†’ ë²¡í„° ìœ ì‚¬ë„ë§Œìœ¼ë¡œ ì¬ê²€ìƒ‰\")\n",
    "                search_results = self.index.query(\n",
    "                    vector=query_embedding,\n",
    "                    top_k=top_k,\n",
    "                    include_metadata=True,\n",
    "                    filter=filter_dict  # ë©”íƒ€ë°ì´í„° í•„í„° ì œê±°\n",
    "                )\n",
    "        else:\n",
    "            # ë©”íƒ€ë°ì´í„° í•„í„° ì—†ì´ ê²€ìƒ‰\n",
    "            search_results = self.index.query(\n",
    "                vector=query_embedding,\n",
    "                top_k=top_k,\n",
    "                include_metadata=True,\n",
    "                filter=filter_dict\n",
    "            )\n",
    "\n",
    "        # ê²°ê³¼ ì €ì¥\n",
    "        matches = []\n",
    "        for match in search_results.matches:\n",
    "            metadata = match.metadata or {}\n",
    "            matches.append({\n",
    "                \"id\": match.id,\n",
    "                \"score\": match.score,\n",
    "                \"mb_sn\": metadata.get(\"mb_sn\", \"\"),\n",
    "                \"index\": metadata.get(\"index\", 0),\n",
    "                \"topic\": metadata.get(\"topic\", \"\"),\n",
    "                \"text\": metadata.get(\"text\", \"\"),\n",
    "                \"ì§€ì—­\": metadata.get(\"ì§€ì—­\", \"\"),\n",
    "                \"ì—°ë ¹ëŒ€\": metadata.get(\"ì—°ë ¹ëŒ€\", \"\"),\n",
    "                \"ì„±ë³„\": metadata.get(\"ì„±ë³„\", \"\")\n",
    "            })\n",
    "\n",
    "        return matches\n",
    "\n",
    "\n",
    "class ResultFilter:\n",
    "    \"\"\"ì¹´í…Œê³ ë¦¬ ìˆœì„œì— ë”°ë¼ ë‹¨ê³„ì ìœ¼ë¡œ mb_snì„ í•„í„°ë§ (ì „ì²´ topic ë©”íƒ€ë°ì´í„° í•„í„° ì§€ì›)\"\"\"\n",
    "\n",
    "    def __init__(self, pinecone_searcher: PineconeSearcher):\n",
    "        self.searcher = pinecone_searcher\n",
    "\n",
    "    def filter_by_categories(\n",
    "        self,\n",
    "        embeddings: Dict[str, List[float]],\n",
    "        category_order: List[str],\n",
    "        final_count: int,\n",
    "        topic_filters: Dict[str, Dict[str, Any]] = None\n",
    "    ) -> List[str]:\n",
    "        \"\"\"\n",
    "        ì¹´í…Œê³ ë¦¬ ìˆœì„œëŒ€ë¡œ ë‹¨ê³„ì ìœ¼ë¡œ í•„í„°ë§í•˜ì—¬ ìµœì¢… mb_sn ë¦¬ìŠ¤íŠ¸ ë°˜í™˜\n",
    "\n",
    "        Args:\n",
    "            embeddings: {\"ì¹´í…Œê³ ë¦¬ëª…\": [ì„ë² ë”© ë²¡í„°]}\n",
    "            category_order: ì¹´í…Œê³ ë¦¬ ìˆœì„œ (ì˜ˆ: [\"ê¸°ë³¸ì •ë³´\", \"ì§ì—…ì†Œë“\", \"ìë™ì°¨\"])\n",
    "            final_count: ìµœì¢… ì¶œë ¥í•  mb_sn ê°œìˆ˜\n",
    "            topic_filters: topicë³„ ë©”íƒ€ë°ì´í„° í•„í„° (ì˜ˆ: {\"ê¸°ë³¸ì •ë³´\": {...}, \"ì§ì—…ì†Œë“\": {...}})\n",
    "\n",
    "        Returns:\n",
    "            ìµœì¢… ì„ ë³„ëœ mb_sn ë¦¬ìŠ¤íŠ¸\n",
    "        \"\"\"\n",
    "        if not category_order:\n",
    "            return []\n",
    "\n",
    "        # ì²« ë²ˆì§¸ ì¹´í…Œê³ ë¦¬ë¡œ ì´ˆê¸° ì„ ë³„\n",
    "        first_category = category_order[0]\n",
    "        first_embedding = embeddings.get(first_category)\n",
    "\n",
    "        if first_embedding is None:\n",
    "            print(f\"âš ï¸ ì²« ë²ˆì§¸ ì¹´í…Œê³ ë¦¬ '{first_category}' ì„ë² ë”©ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "            return []\n",
    "\n",
    "        # ğŸ¯ ì²« ë²ˆì§¸ ì¹´í…Œê³ ë¦¬ì˜ ë©”íƒ€ë°ì´í„° í•„í„° ê°€ì ¸ì˜¤ê¸°\n",
    "        first_filter = (topic_filters or {}).get(first_category, {})\n",
    "        \n",
    "        if first_filter:\n",
    "            print(f\"\\n[1ë‹¨ê³„] '{first_category}' ì¹´í…Œê³ ë¦¬ë¡œ ê²€ìƒ‰ (ë©”íƒ€ë°ì´í„° í•„í„° ì ìš©)\")\n",
    "            print(f\"  â†’ í•„í„° ì¡°ê±´: {first_filter}\")\n",
    "        else:\n",
    "            print(f\"\\n[1ë‹¨ê³„] '{first_category}' ì¹´í…Œê³ ë¦¬ë¡œ ê²€ìƒ‰ (ë²¡í„° ìœ ì‚¬ë„)\")\n",
    "        \n",
    "        # ì´ˆê¸° ê²€ìƒ‰ ìˆ˜ ê²°ì •\n",
    "        initial_count = max(final_count * 10, 100)\n",
    "\n",
    "        first_results = self.searcher.search_by_category(\n",
    "            query_embedding=first_embedding,\n",
    "            category=first_category,\n",
    "            top_k=initial_count,\n",
    "            metadata_filter=first_filter\n",
    "        )\n",
    "\n",
    "        # ì²« ë²ˆì§¸ ì¹´í…Œê³ ë¦¬ì—ì„œ ì„ ë³„ëœ mb_sn ì¶”ì¶œ\n",
    "        candidate_mb_sns = list(set([r[\"mb_sn\"] for r in first_results if r[\"mb_sn\"]]))\n",
    "        print(f\"  â†’ {len(candidate_mb_sns)}ëª…ì˜ í›„ë³´ ì„ ë³„ ì™„ë£Œ\")\n",
    "\n",
    "        # í›„ë³´ê°€ ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜\n",
    "        if len(candidate_mb_sns) == 0:\n",
    "            print(\"âš ï¸ ì²« ë²ˆì§¸ ì¹´í…Œê³ ë¦¬ì—ì„œ í›„ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\")\n",
    "            return []\n",
    "\n",
    "        # ë‚˜ë¨¸ì§€ ì¹´í…Œê³ ë¦¬ë¡œ ì ì§„ì  í•„í„°ë§\n",
    "        for i, category in enumerate(category_order[1:], start=2):\n",
    "            embedding = embeddings.get(category)\n",
    "\n",
    "            if embedding is None:\n",
    "                print(f\"âš ï¸ ì¹´í…Œê³ ë¦¬ '{category}' ì„ë² ë”©ì´ ì—†ìŠµë‹ˆë‹¤. ìŠ¤í‚µí•©ë‹ˆë‹¤.\")\n",
    "                continue\n",
    "\n",
    "            # ğŸ¯ í˜„ì¬ ì¹´í…Œê³ ë¦¬ì˜ ë©”íƒ€ë°ì´í„° í•„í„° ê°€ì ¸ì˜¤ê¸°\n",
    "            category_filter = (topic_filters or {}).get(category, {})\n",
    "\n",
    "            # ì´ì „ ë‹¨ê³„ì˜ í›„ë³´ë“¤ ì¤‘ì—ì„œë§Œ ê²€ìƒ‰\n",
    "            if category_filter:\n",
    "                print(f\"\\n[{i}ë‹¨ê³„] '{category}' ì¹´í…Œê³ ë¦¬ë¡œ í•„í„°ë§ ì¤‘... (ë©”íƒ€ë°ì´í„° í•„í„° + í›„ë³´: {len(candidate_mb_sns)}ëª…)\")\n",
    "            else:\n",
    "                print(f\"\\n[{i}ë‹¨ê³„] '{category}' ì¹´í…Œê³ ë¦¬ë¡œ í•„í„°ë§ ì¤‘... (ë²¡í„° ìœ ì‚¬ë„ + í›„ë³´: {len(candidate_mb_sns)}ëª…)\")\n",
    "\n",
    "            # í›„ë³´ê°€ ë¹„ì–´ìˆìœ¼ë©´ í•„í„°ë§ ì¤‘ë‹¨\n",
    "            if len(candidate_mb_sns) == 0:\n",
    "                print(f\"âš ï¸ ì´ì „ ë‹¨ê³„ì—ì„œ í›„ë³´ê°€ ëª¨ë‘ ì œê±°ë˜ì—ˆìŠµë‹ˆë‹¤. í•„í„°ë§ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.\")\n",
    "                break\n",
    "\n",
    "            # í›„ë³´ê°€ ë„ˆë¬´ ë§ìœ¼ë©´ Pinecone í•„í„°ë¡œ ì²˜ë¦¬ ê°€ëŠ¥í•œ ìˆ˜ì¤€ìœ¼ë¡œ ì œí•œ\n",
    "            search_count = min(len(candidate_mb_sns) * 2, 1000)\n",
    "            \n",
    "            # search_countê°€ 0 ì´í•˜ê°€ ë˜ì§€ ì•Šë„ë¡ ë³´ì¥\n",
    "            search_count = max(search_count, 1)\n",
    "\n",
    "            results = self.searcher.search_by_category(\n",
    "                query_embedding=embedding,\n",
    "                category=category,\n",
    "                top_k=search_count,\n",
    "                filter_mb_sns=candidate_mb_sns,\n",
    "                metadata_filter=category_filter\n",
    "            )\n",
    "\n",
    "            # mb_snë³„ ìµœê³  ì ìˆ˜ ì§‘ê³„\n",
    "            mb_sn_scores = {}\n",
    "            for r in results:\n",
    "                mb_sn = r[\"mb_sn\"]\n",
    "                if mb_sn in candidate_mb_sns:\n",
    "                    if mb_sn not in mb_sn_scores or r[\"score\"] > mb_sn_scores[mb_sn]:\n",
    "                        mb_sn_scores[mb_sn] = r[\"score\"]\n",
    "\n",
    "            # ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ìƒìœ„ í›„ë³´ ì„ ë³„\n",
    "            sorted_mb_sns = sorted(mb_sn_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "            # ë‹¤ìŒ ë‹¨ê³„ë¥¼ ìœ„í•œ í›„ë³´ ìˆ˜ ê²°ì •\n",
    "            next_candidate_count = max(final_count * 3, 30)\n",
    "            candidate_mb_sns = [mb_sn for mb_sn, score in sorted_mb_sns[:next_candidate_count]]\n",
    "\n",
    "            print(f\"  â†’ {len(candidate_mb_sns)}ëª…ìœ¼ë¡œ ì¶•ì†Œ\")\n",
    "\n",
    "        # ìµœì¢… ê²°ê³¼ ë°˜í™˜\n",
    "        final_mb_sns = candidate_mb_sns[:final_count]\n",
    "        print(f\"\\n[ìµœì¢…] {len(final_mb_sns)}ëª… ì„ ë³„ ì™„ë£Œ\")\n",
    "\n",
    "        return final_mb_sns\n",
    "\n",
    "print(\"âœ… PineconeSearcher ë° ResultFilter ì •ì˜ ì™„ë£Œ (ë©”íƒ€ë°ì´í„° í•„í„° Fallback ì§€ì›)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. í†µí•© íŒŒì´í”„ë¼ì¸ (PanelSearchPipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… PanelSearchPipeline ì •ì˜ ì™„ë£Œ (ì „ì²´ topic ë©”íƒ€ë°ì´í„° í•„í„° ì§€ì›)\n"
     ]
    }
   ],
   "source": [
    "class PanelSearchPipeline:\n",
    "    \"\"\"ì „ì²´ ê²€ìƒ‰ íŒŒì´í”„ë¼ì¸ (ì „ì²´ topic ë©”íƒ€ë°ì´í„° í•„í„° ì§€ì›)\"\"\"\n",
    "\n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "\n",
    "        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”\n",
    "        self.metadata_extractor = MetadataExtractor(config)\n",
    "        self.category_classifier = CategoryClassifier(CATEGORY_CONFIG)\n",
    "        self.text_generator = CategoryTextGenerator(config)\n",
    "        self.embedding_generator = EmbeddingGenerator(config)\n",
    "        self.pinecone_searcher = PineconeSearcher(config)\n",
    "        self.result_filter = ResultFilter(self.pinecone_searcher)\n",
    "\n",
    "        print(\"âœ… íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì™„ë£Œ (ì „ì²´ topic ë©”íƒ€ë°ì´í„° í•„í„° ì§€ì›)\")\n",
    "\n",
    "    def search(self, query: str, final_count: int = 10) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        ìì—°ì–´ ì§ˆì˜ë¡œ íŒ¨ë„ ê²€ìƒ‰ (ì „ì²´ topic ë©”íƒ€ë°ì´í„° í•„í„° í™œìš©)\n",
    "\n",
    "        Args:\n",
    "            query: ìì—°ì–´ ì§ˆì˜ (ì˜ˆ: \"ì„œìš¸ 20ëŒ€ í—¬ìŠ¤í•˜ëŠ” ë‚¨ì 10ëª…\")\n",
    "            final_count: ìµœì¢… ì¶œë ¥í•  mb_sn ê°œìˆ˜ (ê¸°ë³¸ê°’: 10)\n",
    "\n",
    "        Returns:\n",
    "            ê²€ìƒ‰ ê²°ê³¼ (mb_sn ë¦¬ìŠ¤íŠ¸ í¬í•¨)\n",
    "        \"\"\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"ê²€ìƒ‰ ì§ˆì˜: {query}\")\n",
    "        print(f\"ìš”ì²­ ì¸ì›: {final_count}ëª…\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "\n",
    "        # 1ë‹¨ê³„: ë©”íƒ€ë°ì´í„° ì¶”ì¶œ\n",
    "        print(\"[1ë‹¨ê³„] ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ì¤‘...\")\n",
    "        metadata = self.metadata_extractor.extract(query)\n",
    "        print(f\"ì¶”ì¶œëœ ë©”íƒ€ë°ì´í„°: {json.dumps(metadata, ensure_ascii=False, indent=2)}\")\n",
    "        \n",
    "        # ğŸ¯ ì „ì²´ topic í•„í„° ì¶”ì¶œ\n",
    "        topic_filters = self.metadata_extractor.extract_topic_filters(metadata)\n",
    "        if topic_filters:\n",
    "            print(f\"\\ntopicë³„ ë©”íƒ€ë°ì´í„° í•„í„°:\")\n",
    "            for topic, filter_dict in topic_filters.items():\n",
    "                print(f\"  - {topic}: {json.dumps(filter_dict, ensure_ascii=False)}\")\n",
    "        print()\n",
    "\n",
    "        # 2ë‹¨ê³„: ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜\n",
    "        print(\"[2ë‹¨ê³„] ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ ì¤‘...\")\n",
    "        categorized = self.category_classifier.classify(metadata)\n",
    "        \n",
    "        # ì¹´í…Œê³ ë¦¬ ìˆœì„œ ì •ì˜ (ê¸°ë³¸ì •ë³´ë¥¼ ìµœìš°ì„ ìœ¼ë¡œ)\n",
    "        category_order = []\n",
    "        if \"ê¸°ë³¸ì •ë³´\" in categorized:\n",
    "            category_order.append(\"ê¸°ë³¸ì •ë³´\")\n",
    "        for cat in CATEGORY_CONFIG.keys():\n",
    "            if cat in categorized and cat != \"ê¸°ë³¸ì •ë³´\":\n",
    "                category_order.append(cat)\n",
    "        \n",
    "        print(f\"ë¶„ë¥˜ëœ ì¹´í…Œê³ ë¦¬ (ìˆœì„œ): {category_order}\\n\")\n",
    "\n",
    "        # 3ë‹¨ê³„: í…ìŠ¤íŠ¸í™” (LLM ì‚¬ìš©)\n",
    "        print(\"[3ë‹¨ê³„] ì¹´í…Œê³ ë¦¬ë³„ ìì—°ì–´ í…ìŠ¤íŠ¸ ìƒì„± ì¤‘...\")\n",
    "        texts = self.text_generator.generate_texts(categorized)\n",
    "        for category, text in texts.items():\n",
    "            print(f\"  - {category}: {text}\")\n",
    "        print()\n",
    "\n",
    "        # 4ë‹¨ê³„: ì„ë² ë”© ìƒì„±\n",
    "        print(\"[4ë‹¨ê³„] ì„ë² ë”© ìƒì„± ì¤‘...\")\n",
    "        embeddings = self.embedding_generator.generate_embeddings(texts)\n",
    "        print()\n",
    "\n",
    "        # 5ë‹¨ê³„: ë©”íƒ€ë°ì´í„° í•„í„°ë¥¼ í™œìš©í•œ ë‹¨ê³„ì  í•„í„°ë§\n",
    "        print(\"[5ë‹¨ê³„] ì¹´í…Œê³ ë¦¬ ìˆœì„œëŒ€ë¡œ ë‹¨ê³„ì  í•„í„°ë§ ì¤‘...\")\n",
    "        if topic_filters:\n",
    "            print(f\"  ğŸ¯ í™œì„±í™”ëœ ë©”íƒ€ë°ì´í„° í•„í„°:\")\n",
    "            for topic, filter_dict in topic_filters.items():\n",
    "                print(f\"     - {topic}: {json.dumps(filter_dict, ensure_ascii=False)}\")\n",
    "        \n",
    "        final_mb_sns = self.result_filter.filter_by_categories(\n",
    "            embeddings=embeddings,\n",
    "            category_order=category_order,\n",
    "            final_count=final_count,\n",
    "            topic_filters=topic_filters\n",
    "        )\n",
    "\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"âœ… ê²€ìƒ‰ ì™„ë£Œ!\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "\n",
    "        return {\n",
    "            \"query\": query,\n",
    "            \"final_count\": final_count,\n",
    "            \"metadata\": metadata,\n",
    "            \"topic_filters\": topic_filters,\n",
    "            \"category_order\": category_order,\n",
    "            \"categorized\": categorized,\n",
    "            \"texts\": texts,\n",
    "            \"final_mb_sns\": final_mb_sns\n",
    "        }\n",
    "\n",
    "print(\"âœ… PanelSearchPipeline ì •ì˜ ì™„ë£Œ (ì „ì²´ topic ë©”íƒ€ë°ì´í„° í•„í„° ì§€ì›)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Pinecone Index ì—°ê²°: panel-features\n",
      "âœ… íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì™„ë£Œ (ì „ì²´ topic ë©”íƒ€ë°ì´í„° í•„í„° ì§€ì›)\n",
      "\n",
      "âœ… ëª¨ë“  ì¤€ë¹„ ì™„ë£Œ! pipeline.search('ì§ˆì˜') ë¡œ ê²€ìƒ‰í•˜ì„¸ìš”.\n"
     ]
    }
   ],
   "source": [
    "# íŒŒì´í”„ë¼ì¸ ìƒì„±\n",
    "pipeline = PanelSearchPipeline(config)\n",
    "\n",
    "print(\"\\nâœ… ëª¨ë“  ì¤€ë¹„ ì™„ë£Œ! pipeline.search('ì§ˆì˜') ë¡œ ê²€ìƒ‰í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "í…ŒìŠ¤íŠ¸ 1: ì„œìš¸ ê±°ì£¼ì\n",
      "======================================================================\n",
      "\n",
      "============================================================\n",
      "ê²€ìƒ‰ ì§ˆì˜: ì„œìš¸ ê±°ì£¼ì\n",
      "ìš”ì²­ ì¸ì›: 20ëª…\n",
      "============================================================\n",
      "\n",
      "[1ë‹¨ê³„] ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ì¤‘...\n",
      "ì¶”ì¶œëœ ë©”íƒ€ë°ì´í„°: {\n",
      "  \"ì§€ì—­\": \"ì„œìš¸\"\n",
      "}\n",
      "\n",
      "topicë³„ ë©”íƒ€ë°ì´í„° í•„í„°:\n",
      "  - ê¸°ë³¸ì •ë³´: {\"ì§€ì—­\": \"ì„œìš¸\"}\n",
      "\n",
      "[2ë‹¨ê³„] ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ ì¤‘...\n",
      "ë¶„ë¥˜ëœ ì¹´í…Œê³ ë¦¬ (ìˆœì„œ): ['ê¸°ë³¸ì •ë³´']\n",
      "\n",
      "[3ë‹¨ê³„] ì¹´í…Œê³ ë¦¬ë³„ ìì—°ì–´ í…ìŠ¤íŠ¸ ìƒì„± ì¤‘...\n",
      "  - ê¸°ë³¸ì •ë³´: ì„œìš¸ì— ê±°ì£¼í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "[4ë‹¨ê³„] ì„ë² ë”© ìƒì„± ì¤‘...\n",
      "  - ê¸°ë³¸ì •ë³´: ì„ë² ë”© ìƒì„± ì™„ë£Œ (ì°¨ì›: 4096)\n",
      "\n",
      "[5ë‹¨ê³„] ì¹´í…Œê³ ë¦¬ ìˆœì„œëŒ€ë¡œ ë‹¨ê³„ì  í•„í„°ë§ ì¤‘...\n",
      "  ğŸ¯ í™œì„±í™”ëœ ë©”íƒ€ë°ì´í„° í•„í„°:\n",
      "     - ê¸°ë³¸ì •ë³´: {\"ì§€ì—­\": \"ì„œìš¸\"}\n",
      "\n",
      "[1ë‹¨ê³„] 'ê¸°ë³¸ì •ë³´' ì¹´í…Œê³ ë¦¬ë¡œ ê²€ìƒ‰ (ë©”íƒ€ë°ì´í„° í•„í„° ì ìš©)\n",
      "  â†’ í•„í„° ì¡°ê±´: {'ì§€ì—­': 'ì„œìš¸'}\n",
      "  [ë©”íƒ€ë°ì´í„° í•„í„° í™œì„±í™”] ê¸°ë³¸ì •ë³´: {'ì§€ì—­': 'ì„œìš¸'}\n",
      "  â†’ 146ëª…ì˜ í›„ë³´ ì„ ë³„ ì™„ë£Œ\n",
      "\n",
      "[ìµœì¢…] 20ëª… ì„ ë³„ ì™„ë£Œ\n",
      "\n",
      "============================================================\n",
      "âœ… ê²€ìƒ‰ ì™„ë£Œ!\n",
      "============================================================\n",
      "\n",
      "\n",
      "ê²€ìƒ‰ëœ mb_sn ë¦¬ìŠ¤íŠ¸ (20ê°œ):\n",
      "  1. w6718258566401\n",
      "  2. w260046752422801\n",
      "  3. w271738888406172\n",
      "  4. w3573848667265\n",
      "  5. w16440685994927\n",
      "  6. w5739775675732\n",
      "  7. w392725781990458\n",
      "  8. w214391744289099\n",
      "  9. w10315451814966\n",
      "  10. w233236477919156\n",
      "  11. w296543095068492\n",
      "  12. w24513122842603\n",
      "  13. w49707187859286\n",
      "  14. w2956180317929\n",
      "  15. w222312844371891\n",
      "  16. w11847911762086\n",
      "  17. w158276580078574\n",
      "  18. w203579689387385\n",
      "  19. w131283967855710\n",
      "  20. w15092690029425\n",
      "\n",
      "\n",
      "======================================================================\n",
      "í…ŒìŠ¤íŠ¸ 2: 30ëŒ€ ë‚¨ì„± ì°¾ì•„ì¤˜\n",
      "======================================================================\n",
      "\n",
      "============================================================\n",
      "ê²€ìƒ‰ ì§ˆì˜: 30ëŒ€ ë‚¨ì„± ì°¾ì•„ì¤˜\n",
      "ìš”ì²­ ì¸ì›: 10ëª…\n",
      "============================================================\n",
      "\n",
      "[1ë‹¨ê³„] ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ì¤‘...\n",
      "ì¶”ì¶œëœ ë©”íƒ€ë°ì´í„°: {\n",
      "  \"ì—°ë ¹ëŒ€\": \"30ëŒ€\",\n",
      "  \"ì„±ë³„\": \"ë‚¨\"\n",
      "}\n",
      "\n",
      "topicë³„ ë©”íƒ€ë°ì´í„° í•„í„°:\n",
      "  - ê¸°ë³¸ì •ë³´: {\"$and\": [{\"ì—°ë ¹ëŒ€\": \"30ëŒ€\"}, {\"ì„±ë³„\": \"ë‚¨\"}]}\n",
      "\n",
      "[2ë‹¨ê³„] ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ ì¤‘...\n",
      "ë¶„ë¥˜ëœ ì¹´í…Œê³ ë¦¬ (ìˆœì„œ): ['ê¸°ë³¸ì •ë³´']\n",
      "\n",
      "[3ë‹¨ê³„] ì¹´í…Œê³ ë¦¬ë³„ ìì—°ì–´ í…ìŠ¤íŠ¸ ìƒì„± ì¤‘...\n",
      "  - ê¸°ë³¸ì •ë³´: ì„œìš¸ì— ê±°ì£¼í•˜ëŠ” 30ëŒ€ ë‚¨ì„±ì…ë‹ˆë‹¤.\n",
      "\n",
      "[4ë‹¨ê³„] ì„ë² ë”© ìƒì„± ì¤‘...\n",
      "  - ê¸°ë³¸ì •ë³´: ì„ë² ë”© ìƒì„± ì™„ë£Œ (ì°¨ì›: 4096)\n",
      "\n",
      "[5ë‹¨ê³„] ì¹´í…Œê³ ë¦¬ ìˆœì„œëŒ€ë¡œ ë‹¨ê³„ì  í•„í„°ë§ ì¤‘...\n",
      "  ğŸ¯ í™œì„±í™”ëœ ë©”íƒ€ë°ì´í„° í•„í„°:\n",
      "     - ê¸°ë³¸ì •ë³´: {\"$and\": [{\"ì—°ë ¹ëŒ€\": \"30ëŒ€\"}, {\"ì„±ë³„\": \"ë‚¨\"}]}\n",
      "\n",
      "[1ë‹¨ê³„] 'ê¸°ë³¸ì •ë³´' ì¹´í…Œê³ ë¦¬ë¡œ ê²€ìƒ‰ (ë©”íƒ€ë°ì´í„° í•„í„° ì ìš©)\n",
      "  â†’ í•„í„° ì¡°ê±´: {'$and': [{'ì—°ë ¹ëŒ€': '30ëŒ€'}, {'ì„±ë³„': 'ë‚¨'}]}\n",
      "  [ë©”íƒ€ë°ì´í„° í•„í„° í™œì„±í™”] ê¸°ë³¸ì •ë³´: {'$and': [{'ì—°ë ¹ëŒ€': '30ëŒ€'}, {'ì„±ë³„': 'ë‚¨'}]}\n",
      "  â†’ 13ëª…ì˜ í›„ë³´ ì„ ë³„ ì™„ë£Œ\n",
      "\n",
      "[ìµœì¢…] 10ëª… ì„ ë³„ ì™„ë£Œ\n",
      "\n",
      "============================================================\n",
      "âœ… ê²€ìƒ‰ ì™„ë£Œ!\n",
      "============================================================\n",
      "\n",
      "\n",
      "ê²€ìƒ‰ëœ mb_sn ë¦¬ìŠ¤íŠ¸ (10ê°œ):\n",
      "  1. w401654560558589\n",
      "  2. w19518097000737\n",
      "  3. w8336330477970\n",
      "  4. w3573848667265\n",
      "  5. w165940139224841\n",
      "  6. w41627917087592\n",
      "  7. w10410228982425\n",
      "  8. w311229782857060\n",
      "  9. w5427712543275\n",
      "  10. w328858987651957\n"
     ]
    }
   ],
   "source": [
    "# ğŸ¯ ë©”íƒ€ë°ì´í„° í•„í„° í™œìš© í…ŒìŠ¤íŠ¸\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ 1: ì„œìš¸ 20ëŒ€ ì—¬ì\n",
    "print(\"=\" * 70)\n",
    "test1 = 'ê²½ê¸° ëŒ€ì¡¸ ì°¨ëŸ‰ ìˆëŠ” ë‚¨ì„±'\n",
    "print(\"í…ŒìŠ¤íŠ¸ 1: \" + test1)\n",
    "print(\"=\" * 70)\n",
    "\n",
    "result1 = pipeline.search(test1, final_count=10)\n",
    "mb_sns1 = result1['final_mb_sns']\n",
    "\n",
    "print(f\"\\nê²€ìƒ‰ëœ mb_sn ë¦¬ìŠ¤íŠ¸ ({len(mb_sns1)}ê°œ):\")\n",
    "for i, mb_sn in enumerate(mb_sns1, 1):\n",
    "    print(f\"  {i}. {mb_sn}\")\n",
    "\n",
    "print(\"\\n\\n\" + \"=\" * 70)\n",
    "test2 = 'ì„œìš¸ ê¸°í˜¼ 3030'\n",
    "print(\"í…ŒìŠ¤íŠ¸ 2: \" + test2)\n",
    "print(\"=\" * 70)\n",
    "\n",
    "result2 = pipeline.search(test2, final_count=10)\n",
    "mb_sns2 = result2['final_mb_sns']\n",
    "\n",
    "print(f\"\\nê²€ìƒ‰ëœ mb_sn ë¦¬ìŠ¤íŠ¸ ({len(mb_sns2)}ê°œ):\")\n",
    "for i, mb_sn in enumerate(mb_sns2, 1):\n",
    "    print(f\"  {i}. {mb_sn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. PostgreSQL ê²°ê³¼ ì¡°íšŒ í´ë˜ìŠ¤\n",
    "\n",
    "ê²€ìƒ‰ ê²°ê³¼(mb_sn)ë¡œ PostgreSQL í…Œì´ë¸”ì—ì„œ ì¹´í…Œê³ ë¦¬ ì •ë³´ ì¡°íšŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… PanelDataQuerier ì •ì˜ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "class PanelDataQuerier:\n",
    "    \"\"\"PostgreSQLì—ì„œ íŒ¨ë„ ë°ì´í„° ì¡°íšŒ\"\"\"\n",
    "    \n",
    "    # ì¹´í…Œê³ ë¦¬ ì´ë¦„ ë§¤í•‘ (Pinecone topic â†’ PostgreSQL ì¹¼ëŸ¼ëª…)\n",
    "    CATEGORY_COLUMN_MAPPING = {\n",
    "        \"ê¸°ë³¸ì •ë³´\": [\"ì„±ë³„\", \"ë‚˜ì´\", \"ì§€ì—­\"],  # ê¸°ë³¸ ì¹¼ëŸ¼\n",
    "        \"ì§ì—…ì†Œë“\": \"ì§ì—…_ë°_ì†Œë“\",\n",
    "        \"ì „ìì œí’ˆ\": \"ê°€ì „_ë°_ë””ì§€í„¸ê¸°ê¸°ë³´ìœ \",\n",
    "        \"ìë™ì°¨\": \"ìë™ì°¨ë³´ìœ _ë°_ë¸Œëœë“œ\",\n",
    "        \"í¡ì—°\": \"í¡ì—°\",\n",
    "        \"ìŒì£¼\": \"ìŒì£¼\",\n",
    "        \"ìŠ¤íŠ¸ë ˆìŠ¤\": \"ìŠ¤íŠ¸ë ˆìŠ¤\",\n",
    "        \"ë·°í‹°\": \"ë¯¸ìš©\",\n",
    "        \"AIì„œë¹„ìŠ¤\": \"AIì„œë¹„ìŠ¤\",\n",
    "        \"ë¯¸ë””ì–´\": \"ë¯¸ë””ì–´\",\n",
    "        \"ì†Œë¹„\": \"ì†Œë¹„\",\n",
    "        \"ë¼ì´í”„ìŠ¤íƒ€ì¼\": \"ë¼ì´í”„ìŠ¤íƒ€ì¼\",\n",
    "        \"ê²½í—˜\": \"ê²½í—˜\",\n",
    "        \"ì‹ìŠµê´€\": \"ì‹ìŠµê´€\",\n",
    "        \"ì—¬í–‰\": \"ì—¬í–‰\",\n",
    "        \"ê³„ì ˆ\": \"ê³„ì ˆ\",\n",
    "        \"ê±´ê°•\": \"ê±´ê°•\"\n",
    "    }\n",
    "    \n",
    "    def __init__(self, db_config: Dict[str, Any]):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            db_config: {\"host\": \"localhost\", \"port\": 5432, \"database\": \"ProjectDB\", \n",
    "                       \"user\": \"postgres\", \"password\": \"3961\"}\n",
    "        \"\"\"\n",
    "        self.db_config = db_config\n",
    "    \n",
    "    def query_panels(self, mb_sns: List[str], categories: List[str]) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        mb_sn ë¦¬ìŠ¤íŠ¸ë¡œ íŒ¨ë„ ë°ì´í„° ì¡°íšŒ\n",
    "        \n",
    "        Args:\n",
    "            mb_sns: ì¡°íšŒí•  mb_sn ë¦¬ìŠ¤íŠ¸\n",
    "            categories: ì¡°íšŒí•  ì¹´í…Œê³ ë¦¬ ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: [\"ê¸°ë³¸ì •ë³´\", \"í¡ì—°\", \"ìŒì£¼\"])\n",
    "        \n",
    "        Returns:\n",
    "            DataFrame with columns: mb_sn, ì„±ë³„, ë‚˜ì´, ì§€ì—­, ì¹´í…Œê³ ë¦¬ë³„ JSONB ì¹¼ëŸ¼\n",
    "        \"\"\"\n",
    "        if not mb_sns:\n",
    "            print(\"âš ï¸ ì¡°íšŒí•  mb_snì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        # ì¡°íšŒí•  ì¹¼ëŸ¼ ê²°ì •\n",
    "        columns = [\"mb_sn\"]\n",
    "        \n",
    "        for category in categories:\n",
    "            if category == \"ê¸°ë³¸ì •ë³´\":\n",
    "                columns.extend([\"ì„±ë³„\", \"ë‚˜ì´\", \"ì§€ì—­\"])\n",
    "            else:\n",
    "                col_name = self.CATEGORY_COLUMN_MAPPING.get(category)\n",
    "                if col_name and col_name not in columns:\n",
    "                    columns.append(col_name)\n",
    "        \n",
    "        # SQL ì¿¼ë¦¬ ìƒì„±\n",
    "        columns_str = \", \".join(columns)\n",
    "        placeholders = \", \".join([\"%s\"] * len(mb_sns))\n",
    "        \n",
    "        query = f\"\"\"\n",
    "            SELECT {columns_str}\n",
    "            FROM test.panel_data_unified\n",
    "            WHERE mb_sn IN ({placeholders})\n",
    "        \"\"\"\n",
    "        \n",
    "        # DB ì—°ê²° ë° ì¡°íšŒ\n",
    "        try:\n",
    "            conn = psycopg2.connect(**self.db_config)\n",
    "            df = pd.read_sql_query(query, conn, params=mb_sns)\n",
    "            conn.close()\n",
    "            \n",
    "            print(f\"âœ… {len(df)}ê°œ íŒ¨ë„ ë°ì´í„° ì¡°íšŒ ì™„ë£Œ\")\n",
    "            return df\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ DB ì¡°íšŒ ì‹¤íŒ¨: {e}\")\n",
    "            return pd.DataFrame()\n",
    "    \n",
    "    def display_results(self, df: pd.DataFrame, categories: List[str]):\n",
    "        \"\"\"\n",
    "        ì¡°íšŒ ê²°ê³¼ë¥¼ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥\n",
    "        \n",
    "        Args:\n",
    "            df: query_panels()ì˜ ê²°ê³¼ DataFrame\n",
    "            categories: ì¡°íšŒí•œ ì¹´í…Œê³ ë¦¬ ë¦¬ìŠ¤íŠ¸\n",
    "        \"\"\"\n",
    "        if df.empty:\n",
    "            print(\"ì¡°íšŒ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "            return\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"ğŸ“Š íŒ¨ë„ ê²€ìƒ‰ ê²°ê³¼ ìƒì„¸ ì •ë³´ ({len(df)}ëª…)\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "        \n",
    "        for idx, row in df.iterrows():\n",
    "            print(f\"[{idx+1}] mb_sn: {row['mb_sn']}\")\n",
    "            print(\"-\" * 60)\n",
    "            \n",
    "            # ê¸°ë³¸ì •ë³´ ì¶œë ¥\n",
    "            if \"ê¸°ë³¸ì •ë³´\" in categories:\n",
    "                if \"ì„±ë³„\" in row:\n",
    "                    print(f\"  â€¢ ì„±ë³„: {row['ì„±ë³„']}\")\n",
    "                if \"ë‚˜ì´\" in row:\n",
    "                    print(f\"  â€¢ ë‚˜ì´: {row['ë‚˜ì´']}ì„¸\")\n",
    "                if \"ì§€ì—­\" in row:\n",
    "                    print(f\"  â€¢ ì§€ì—­: {row['ì§€ì—­']}\")\n",
    "            \n",
    "            # ì¹´í…Œê³ ë¦¬ë³„ JSONB ë°ì´í„° ì¶œë ¥\n",
    "            for category in categories:\n",
    "                if category == \"ê¸°ë³¸ì •ë³´\":\n",
    "                    continue\n",
    "                \n",
    "                col_name = self.CATEGORY_COLUMN_MAPPING.get(category)\n",
    "                if col_name and col_name in row and pd.notna(row[col_name]):\n",
    "                    print(f\"  â€¢ {category}:\")\n",
    "                    \n",
    "                    # JSONB ë°ì´í„°ë¥¼ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥\n",
    "                    data = row[col_name]\n",
    "                    if isinstance(data, dict):\n",
    "                        for key, value in data.items():\n",
    "                            # ê°’ì´ ë„ˆë¬´ ê¸¸ë©´ ì¤„ì„\n",
    "                            value_str = str(value)\n",
    "                            if len(value_str) > 50:\n",
    "                                value_str = value_str[:50] + \"...\"\n",
    "                            print(f\"    - {key}: {value_str}\")\n",
    "            \n",
    "            print()\n",
    "        \n",
    "        print(f\"{'='*80}\\n\")\n",
    "\n",
    "\n",
    "# DB ì„¤ì •\n",
    "DB_CONFIG = {\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": 5432,\n",
    "    \"database\": \"ProjectDB\",\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"3961\"\n",
    "}\n",
    "\n",
    "# Querier ì´ˆê¸°í™”\n",
    "querier = PanelDataQuerier(DB_CONFIG)\n",
    "\n",
    "print(\"âœ… PanelDataQuerier ì •ì˜ ì™„ë£Œ\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. í†µí•© ê²€ìƒ‰ ë° ì¡°íšŒ í…ŒìŠ¤íŠ¸\n",
    "\n",
    "ê²€ìƒ‰ ê²°ê³¼ì—ì„œ mb_snê³¼ ì¹´í…Œê³ ë¦¬ ì •ë³´ë¥¼ í•¨ê»˜ ì¡°íšŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ì˜ˆì‹œ 1: \"ê²½ê¸° ëŒ€ì¡¸ ì°¨ëŸ‰ ìˆëŠ” ë‚¨ì„±\",\n",
      "================================================================================\n",
      "\n",
      "============================================================\n",
      "ê²€ìƒ‰ ì§ˆì˜: \"ê²½ê¸° ëŒ€ì¡¸ ì°¨ëŸ‰ ìˆëŠ” ë‚¨ì„±\",\n",
      "ìš”ì²­ ì¸ì›: 10ëª…\n",
      "============================================================\n",
      "\n",
      "[1ë‹¨ê³„] ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ì¤‘...\n",
      "ì¶”ì¶œëœ ë©”íƒ€ë°ì´í„°: {\n",
      "  \"ì§€ì—­\": \"ê²½ê¸°\",\n",
      "  \"í•™ë ¥\": \"ëŒ€ì¡¸\",\n",
      "  \"ì°¨ëŸ‰\": \"ìˆëŠ”\",\n",
      "  \"ì„±ë³„\": \"ë‚¨\"\n",
      "}\n",
      "\n",
      "topicë³„ ë©”íƒ€ë°ì´í„° í•„í„°:\n",
      "  - ê¸°ë³¸ì •ë³´: {\"$and\": [{\"ì§€ì—­\": \"ê²½ê¸°\"}, {\"ì„±ë³„\": \"ë‚¨\"}]}\n",
      "\n",
      "[2ë‹¨ê³„] ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ ì¤‘...\n",
      "ë¶„ë¥˜ëœ ì¹´í…Œê³ ë¦¬ (ìˆœì„œ): ['ê¸°ë³¸ì •ë³´', 'ìë™ì°¨']\n",
      "\n",
      "[3ë‹¨ê³„] ì¹´í…Œê³ ë¦¬ë³„ ìì—°ì–´ í…ìŠ¤íŠ¸ ìƒì„± ì¤‘...\n",
      "  - ê¸°ë³¸ì •ë³´: ê²½ê¸°ë„ì— ê±°ì£¼í•˜ëŠ” ë‚¨ì„±ìœ¼ë¡œ ëŒ€í•™êµë¥¼ ì¡¸ì—…í–ˆìŠµë‹ˆë‹¤.\n",
      "  - ìë™ì°¨: ìë™ì°¨ë¥¼ ë³´ìœ í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "[4ë‹¨ê³„] ì„ë² ë”© ìƒì„± ì¤‘...\n",
      "  - ê¸°ë³¸ì •ë³´: ì„ë² ë”© ìƒì„± ì™„ë£Œ (ì°¨ì›: 4096)\n",
      "  - ìë™ì°¨: ì„ë² ë”© ìƒì„± ì™„ë£Œ (ì°¨ì›: 4096)\n",
      "\n",
      "[5ë‹¨ê³„] ì¹´í…Œê³ ë¦¬ ìˆœì„œëŒ€ë¡œ ë‹¨ê³„ì  í•„í„°ë§ ì¤‘...\n",
      "  ğŸ¯ í™œì„±í™”ëœ ë©”íƒ€ë°ì´í„° í•„í„°:\n",
      "     - ê¸°ë³¸ì •ë³´: {\"$and\": [{\"ì§€ì—­\": \"ê²½ê¸°\"}, {\"ì„±ë³„\": \"ë‚¨\"}]}\n",
      "\n",
      "[1ë‹¨ê³„] 'ê¸°ë³¸ì •ë³´' ì¹´í…Œê³ ë¦¬ë¡œ ê²€ìƒ‰ (ë©”íƒ€ë°ì´í„° í•„í„° ì ìš©)\n",
      "  â†’ í•„í„° ì¡°ê±´: {'$and': [{'ì§€ì—­': 'ê²½ê¸°'}, {'ì„±ë³„': 'ë‚¨'}]}\n",
      "  [ë©”íƒ€ë°ì´í„° í•„í„° í™œì„±í™”] ê¸°ë³¸ì •ë³´: {'$and': [{'ì§€ì—­': 'ê²½ê¸°'}, {'ì„±ë³„': 'ë‚¨'}]}\n",
      "  â†’ 50ëª…ì˜ í›„ë³´ ì„ ë³„ ì™„ë£Œ\n",
      "\n",
      "[2ë‹¨ê³„] 'ìë™ì°¨' ì¹´í…Œê³ ë¦¬ë¡œ í•„í„°ë§ ì¤‘... (ë²¡í„° ìœ ì‚¬ë„ + í›„ë³´: 50ëª…)\n",
      "  â†’ 30ëª…ìœ¼ë¡œ ì¶•ì†Œ\n",
      "\n",
      "[ìµœì¢…] 10ëª… ì„ ë³„ ì™„ë£Œ\n",
      "\n",
      "============================================================\n",
      "âœ… ê²€ìƒ‰ ì™„ë£Œ!\n",
      "============================================================\n",
      "\n",
      "\n",
      "ê²€ìƒ‰ëœ ì¹´í…Œê³ ë¦¬: ['ê¸°ë³¸ì •ë³´', 'ìë™ì°¨']\n",
      "ê²€ìƒ‰ëœ íŒ¨ë„ ìˆ˜: 10ëª…\n",
      "\n",
      "âœ… 10ê°œ íŒ¨ë„ ë°ì´í„° ì¡°íšŒ ì™„ë£Œ\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š íŒ¨ë„ ê²€ìƒ‰ ê²°ê³¼ ìƒì„¸ ì •ë³´ (10ëª…)\n",
      "================================================================================\n",
      "\n",
      "[1] mb_sn: w110085012255285\n",
      "------------------------------------------------------------\n",
      "  â€¢ ì„±ë³„: ë‚¨\n",
      "  â€¢ ë‚˜ì´: 41ì„¸\n",
      "  â€¢ ì§€ì—­: ê²½ê¸°\n",
      "  â€¢ ìë™ì°¨:\n",
      "    - ë³´ìœ ì°¨ëŸ‰ì—¬ë¶€: ì—†ë‹¤\n",
      "\n",
      "[2] mb_sn: w11537093427012\n",
      "------------------------------------------------------------\n",
      "  â€¢ ì„±ë³„: ë‚¨\n",
      "  â€¢ ë‚˜ì´: 24ì„¸\n",
      "  â€¢ ì§€ì—­: ê²½ê¸°\n",
      "  â€¢ ìë™ì°¨:\n",
      "    - ë³´ìœ ì°¨ëŸ‰ì—¬ë¶€: ì—†ë‹¤\n",
      "\n",
      "[3] mb_sn: w186865619363250\n",
      "------------------------------------------------------------\n",
      "  â€¢ ì„±ë³„: ë‚¨\n",
      "  â€¢ ë‚˜ì´: 61ì„¸\n",
      "  â€¢ ì§€ì—­: ê²½ê¸°\n",
      "  â€¢ ìë™ì°¨:\n",
      "    - ë³´ìœ ì°¨ëŸ‰ì—¬ë¶€: ì—†ë‹¤\n",
      "\n",
      "[4] mb_sn: w204244844126505\n",
      "------------------------------------------------------------\n",
      "  â€¢ ì„±ë³„: ë‚¨\n",
      "  â€¢ ë‚˜ì´: 68ì„¸\n",
      "  â€¢ ì§€ì—­: ê²½ê¸°\n",
      "  â€¢ ìë™ì°¨:\n",
      "    - ë³´ìœ ì°¨ëŸ‰ì—¬ë¶€: ì—†ë‹¤\n",
      "\n",
      "[5] mb_sn: w22516576801551\n",
      "------------------------------------------------------------\n",
      "  â€¢ ì„±ë³„: ë‚¨\n",
      "  â€¢ ë‚˜ì´: 59ì„¸\n",
      "  â€¢ ì§€ì—­: ê²½ê¸°\n",
      "  â€¢ ìë™ì°¨:\n",
      "    - ë³´ìœ ì°¨ëŸ‰ì—¬ë¶€: ì—†ë‹¤\n",
      "\n",
      "[6] mb_sn: w253440542435038\n",
      "------------------------------------------------------------\n",
      "  â€¢ ì„±ë³„: ë‚¨\n",
      "  â€¢ ë‚˜ì´: 49ì„¸\n",
      "  â€¢ ì§€ì—­: ê²½ê¸°\n",
      "  â€¢ ìë™ì°¨:\n",
      "    - ë³´ìœ ì°¨ëŸ‰ì—¬ë¶€: ì—†ë‹¤\n",
      "\n",
      "[7] mb_sn: w46119349524965\n",
      "------------------------------------------------------------\n",
      "  â€¢ ì„±ë³„: ë‚¨\n",
      "  â€¢ ë‚˜ì´: 60ì„¸\n",
      "  â€¢ ì§€ì—­: ê²½ê¸°\n",
      "  â€¢ ìë™ì°¨:\n",
      "    - ë³´ìœ ì°¨ëŸ‰ì—¬ë¶€: ì—†ë‹¤\n",
      "\n",
      "[8] mb_sn: w94327029022500\n",
      "------------------------------------------------------------\n",
      "  â€¢ ì„±ë³„: ë‚¨\n",
      "  â€¢ ë‚˜ì´: 61ì„¸\n",
      "  â€¢ ì§€ì—­: ê²½ê¸°\n",
      "  â€¢ ìë™ì°¨:\n",
      "    - ë³´ìœ ì°¨ëŸ‰ì—¬ë¶€: ì—†ë‹¤\n",
      "\n",
      "[9] mb_sn: w136343034897397\n",
      "------------------------------------------------------------\n",
      "  â€¢ ì„±ë³„: ë‚¨\n",
      "  â€¢ ë‚˜ì´: 52ì„¸\n",
      "  â€¢ ì§€ì—­: ê²½ê¸°\n",
      "  â€¢ ìë™ì°¨:\n",
      "    - ë³´ìœ ì°¨ëŸ‰ì—¬ë¶€: ì—†ë‹¤\n",
      "\n",
      "[10] mb_sn: w15051978875233\n",
      "------------------------------------------------------------\n",
      "  â€¢ ì„±ë³„: ë‚¨\n",
      "  â€¢ ë‚˜ì´: 45ì„¸\n",
      "  â€¢ ì§€ì—­: ê²½ê¸°\n",
      "  â€¢ ìë™ì°¨:\n",
      "    - ë³´ìœ ì°¨ëŸ‰ì—¬ë¶€: ì—†ë‹¤\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\TempFolder\\ipykernel_25024\\1868296373.py:76: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(query, conn, params=mb_sns)\n"
     ]
    }
   ],
   "source": [
    "# ğŸ¯ í†µí•© ê²€ìƒ‰ + DB ì¡°íšŒ ì˜ˆì‹œ\n",
    "\n",
    "# ì˜ˆì‹œ 1: \"í¡ì—°í•˜ëŠ” ë‚¨ì 5ëª…\" ê²€ìƒ‰ í›„ ìƒì„¸ ì •ë³´ ì¡°íšŒ\n",
    "print(\"=\" * 80)\n",
    "test_text1 = '\"ê²½ê¸° ëŒ€ì¡¸ ì°¨ëŸ‰ ìˆëŠ” ë‚¨ì„±\",'\n",
    "print(\"ì˜ˆì‹œ 1: \" + test_text1)\n",
    "print(\"=\" * 80)\n",
    "\n",
    "result = pipeline.search(test_text1, final_count=10)\n",
    "\n",
    "# ê²€ìƒ‰ ê²°ê³¼ (mb_snê³¼ ì¹´í…Œê³ ë¦¬)\n",
    "mb_sns = result['final_mb_sns']\n",
    "categories = result['category_order']  # ì§ˆì˜ì— í¬í•¨ëœ ì¹´í…Œê³ ë¦¬\n",
    "\n",
    "print(f\"\\nê²€ìƒ‰ëœ ì¹´í…Œê³ ë¦¬: {categories}\")\n",
    "print(f\"ê²€ìƒ‰ëœ íŒ¨ë„ ìˆ˜: {len(mb_sns)}ëª…\\n\")\n",
    "\n",
    "# PostgreSQLì—ì„œ ìƒì„¸ ì •ë³´ ì¡°íšŒ\n",
    "df = querier.query_panels(mb_sns, categories)\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "querier.display_results(df, categories)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "================================================================================\n",
      "ì˜ˆì‹œ 2: ì„œìš¸ 20ëŒ€ ì—¬ì ë„·í”Œë¦­ìŠ¤ ë³´ëŠ” ì‚¬ëŒ 3ëª…\n",
      "================================================================================\n",
      "\n",
      "============================================================\n",
      "ê²€ìƒ‰ ì§ˆì˜: ì„œìš¸ 20ëŒ€ ì—¬ì ë„·í”Œë¦­ìŠ¤ ë³´ëŠ” ì‚¬ëŒ 3ëª…\n",
      "ìš”ì²­ ì¸ì›: 3ëª…\n",
      "============================================================\n",
      "\n",
      "[1ë‹¨ê³„] ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ì¤‘...\n",
      "ì¶”ì¶œëœ ë©”íƒ€ë°ì´í„°: {\n",
      "  \"ì§€ì—­\": \"ì„œìš¸\",\n",
      "  \"ì—°ë ¹ëŒ€\": \"20ëŒ€\",\n",
      "  \"ì„±ë³„\": \"ì—¬\",\n",
      "  \"í™œë™\": \"ë„·í”Œë¦­ìŠ¤ ë³´ëŠ”\",\n",
      "  \"ì¸ì›\": \"3ëª…\"\n",
      "}\n",
      "\n",
      "topicë³„ ë©”íƒ€ë°ì´í„° í•„í„°:\n",
      "  - ê¸°ë³¸ì •ë³´: {\"$and\": [{\"ì§€ì—­\": \"ì„œìš¸\"}, {\"ì—°ë ¹ëŒ€\": \"20ëŒ€\"}, {\"ì„±ë³„\": \"ì—¬\"}]}\n",
      "\n",
      "[2ë‹¨ê³„] ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ ì¤‘...\n",
      "ë¶„ë¥˜ëœ ì¹´í…Œê³ ë¦¬ (ìˆœì„œ): ['ê¸°ë³¸ì •ë³´', 'ë¯¸ë””ì–´']\n",
      "\n",
      "[3ë‹¨ê³„] ì¹´í…Œê³ ë¦¬ë³„ ìì—°ì–´ í…ìŠ¤íŠ¸ ìƒì„± ì¤‘...\n",
      "  - ê¸°ë³¸ì •ë³´: ì„œìš¸ì— ê±°ì£¼í•˜ëŠ” 20ëŒ€ ì—¬ì„±ìœ¼ë¡œ 3ëª…ì˜ ê°€ì¡±ê³¼ í•¨ê»˜ ìƒí™œí•˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "  - ë¯¸ë””ì–´: ì£¼ë¡œ ì´ìš©í•˜ëŠ” OTT ì„œë¹„ìŠ¤ëŠ” ë„·í”Œë¦­ìŠ¤ì…ë‹ˆë‹¤.\n",
      "\n",
      "[4ë‹¨ê³„] ì„ë² ë”© ìƒì„± ì¤‘...\n",
      "  - ê¸°ë³¸ì •ë³´: ì„ë² ë”© ìƒì„± ì™„ë£Œ (ì°¨ì›: 4096)\n",
      "  - ë¯¸ë””ì–´: ì„ë² ë”© ìƒì„± ì™„ë£Œ (ì°¨ì›: 4096)\n",
      "\n",
      "[5ë‹¨ê³„] ì¹´í…Œê³ ë¦¬ ìˆœì„œëŒ€ë¡œ ë‹¨ê³„ì  í•„í„°ë§ ì¤‘...\n",
      "  ğŸ¯ í™œì„±í™”ëœ ë©”íƒ€ë°ì´í„° í•„í„°:\n",
      "     - ê¸°ë³¸ì •ë³´: {\"$and\": [{\"ì§€ì—­\": \"ì„œìš¸\"}, {\"ì—°ë ¹ëŒ€\": \"20ëŒ€\"}, {\"ì„±ë³„\": \"ì—¬\"}]}\n",
      "\n",
      "[1ë‹¨ê³„] 'ê¸°ë³¸ì •ë³´' ì¹´í…Œê³ ë¦¬ë¡œ ê²€ìƒ‰ (ë©”íƒ€ë°ì´í„° í•„í„° ì ìš©)\n",
      "  â†’ í•„í„° ì¡°ê±´: {'$and': [{'ì§€ì—­': 'ì„œìš¸'}, {'ì—°ë ¹ëŒ€': '20ëŒ€'}, {'ì„±ë³„': 'ì—¬'}]}\n",
      "  [ë©”íƒ€ë°ì´í„° í•„í„° í™œì„±í™”] ê¸°ë³¸ì •ë³´: {'$and': [{'ì§€ì—­': 'ì„œìš¸'}, {'ì—°ë ¹ëŒ€': '20ëŒ€'}, {'ì„±ë³„': 'ì—¬'}]}\n",
      "  â†’ 40ëª…ì˜ í›„ë³´ ì„ ë³„ ì™„ë£Œ\n",
      "\n",
      "[2ë‹¨ê³„] 'ë¯¸ë””ì–´' ì¹´í…Œê³ ë¦¬ë¡œ í•„í„°ë§ ì¤‘... (ë²¡í„° ìœ ì‚¬ë„ + í›„ë³´: 40ëª…)\n",
      "  â†’ 23ëª…ìœ¼ë¡œ ì¶•ì†Œ\n",
      "\n",
      "[ìµœì¢…] 3ëª… ì„ ë³„ ì™„ë£Œ\n",
      "\n",
      "============================================================\n",
      "âœ… ê²€ìƒ‰ ì™„ë£Œ!\n",
      "============================================================\n",
      "\n",
      "\n",
      "ê²€ìƒ‰ëœ ì¹´í…Œê³ ë¦¬: ['ê¸°ë³¸ì •ë³´', 'ë¯¸ë””ì–´']\n",
      "ê²€ìƒ‰ëœ íŒ¨ë„ ìˆ˜: 3ëª…\n",
      "\n",
      "âœ… 3ê°œ íŒ¨ë„ ë°ì´í„° ì¡°íšŒ ì™„ë£Œ\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š íŒ¨ë„ ê²€ìƒ‰ ê²°ê³¼ ìƒì„¸ ì •ë³´ (3ëª…)\n",
      "================================================================================\n",
      "\n",
      "[1] mb_sn: w3646841013915\n",
      "------------------------------------------------------------\n",
      "  â€¢ ì„±ë³„: ì—¬\n",
      "  â€¢ ë‚˜ì´: 29ì„¸\n",
      "  â€¢ ì§€ì—­: ì„œìš¸\n",
      "  â€¢ ë¯¸ë””ì–´:\n",
      "    - Q017: {'answer': 'ë™ì˜ìƒ ìŠ¤íŠ¸ë¦¬ë° ì•± (ìœ íŠœë¸Œ, ë„·í”Œë¦­ìŠ¤ ë“±)', 'question':...\n",
      "\n",
      "[2] mb_sn: w10089453710354\n",
      "------------------------------------------------------------\n",
      "  â€¢ ì„±ë³„: ì—¬\n",
      "  â€¢ ë‚˜ì´: 25ì„¸\n",
      "  â€¢ ì§€ì—­: ì„œìš¸\n",
      "  â€¢ ë¯¸ë””ì–´:\n",
      "    - Q010: {'answer': '2ê°œ', 'question': 'ì—¬ëŸ¬ë¶„ì´ í˜„ì¬ ì´ìš© ì¤‘ì¸ OTT ì„œë¹„...\n",
      "    - Q017: {'answer': 'ë™ì˜ìƒ ìŠ¤íŠ¸ë¦¬ë° ì•± (ìœ íŠœë¸Œ, ë„·í”Œë¦­ìŠ¤ ë“±)', 'question':...\n",
      "\n",
      "[3] mb_sn: w6177024161626\n",
      "------------------------------------------------------------\n",
      "  â€¢ ì„±ë³„: ì—¬\n",
      "  â€¢ ë‚˜ì´: 26ì„¸\n",
      "  â€¢ ì§€ì—­: ì„œìš¸\n",
      "  â€¢ ë¯¸ë””ì–´:\n",
      "    - Q010: {'answer': '2ê°œ', 'question': 'ì—¬ëŸ¬ë¶„ì´ í˜„ì¬ ì´ìš© ì¤‘ì¸ OTT ì„œë¹„...\n",
      "    - Q017: {'answer': 'SNS ì•± (ì¸ìŠ¤íƒ€ê·¸ë¨, í˜ì´ìŠ¤ë¶, í‹±í†¡ ë“±)', 'question'...\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\TempFolder\\ipykernel_25024\\1868296373.py:76: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(query, conn, params=mb_sns)\n"
     ]
    }
   ],
   "source": [
    "# ì˜ˆì‹œ 2: \"ì„œìš¸ 20ëŒ€ ì—¬ì ë„·í”Œë¦­ìŠ¤ ë³´ëŠ” ì‚¬ëŒ 3ëª…\" ê²€ìƒ‰ í›„ ìƒì„¸ ì •ë³´ ì¡°íšŒ\n",
    "\n",
    "# Querierê°€ ì •ì˜ë˜ì§€ ì•Šì€ ê²½ìš° ì´ˆê¸°í™”\n",
    "if 'querier' not in globals():\n",
    "    querier = PanelDataQuerier(DB_CONFIG)\n",
    "\n",
    "print(\"\\n\\n\" + \"=\" * 80)\n",
    "search1 = \"ì„œìš¸ 20ëŒ€ ì—¬ì ë„·í”Œë¦­ìŠ¤ ë³´ëŠ” ì‚¬ëŒ 3ëª…\"\n",
    "print(\"ì˜ˆì‹œ 2: \" + search1)\n",
    "print(\"=\" * 80)\n",
    "\n",
    "result2 = pipeline.search(search1, final_count=3)\n",
    "\n",
    "# ê²€ìƒ‰ ê²°ê³¼\n",
    "mb_sns2 = result2['final_mb_sns']\n",
    "categories2 = result2['category_order']\n",
    "\n",
    "print(f\"\\nê²€ìƒ‰ëœ ì¹´í…Œê³ ë¦¬: {categories2}\")\n",
    "print(f\"ê²€ìƒ‰ëœ íŒ¨ë„ ìˆ˜: {len(mb_sns2)}ëª…\\n\")\n",
    "\n",
    "# PostgreSQLì—ì„œ ìƒì„¸ ì •ë³´ ì¡°íšŒ\n",
    "df2 = querier.query_panels(mb_sns2, categories2)\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "querier.display_results(df2, categories2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
