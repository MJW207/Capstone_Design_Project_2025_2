"""í´ëŸ¬ìŠ¤í„°ë§ ìŠ¤í‚¤ë§ˆ í™•ì¸ ìŠ¤í¬ë¦½íŠ¸"""
import asyncio
import sys
from pathlib import Path
from sqlalchemy import text
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession
from sqlalchemy.orm import sessionmaker
import os
from dotenv import load_dotenv

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
project_root = Path(__file__).resolve().parent.parent.parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / "server"))

# Windows ì´ë²¤íŠ¸ ë£¨í”„ ì •ì±… ì„¤ì •
if sys.platform == 'win32':
    asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())

load_dotenv(override=True)

async def check_clustering_schema():
    """í´ëŸ¬ìŠ¤í„°ë§ ê´€ë ¨ í…Œì´ë¸” êµ¬ì¡° í™•ì¸"""
    uri = os.getenv("ASYNC_DATABASE_URI")
    if not uri:
        print("âŒ ASYNC_DATABASE_URI í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return
    
    # postgresql://ë¥¼ postgresql+psycopg://ë¡œ ë³€í™˜
    if uri.startswith("postgresql://"):
        uri = uri.replace("postgresql://", "postgresql+psycopg://", 1)
    elif "postgresql+asyncpg" in uri:
        uri = uri.replace("postgresql+asyncpg", "postgresql+psycopg", 1)
    
    engine = create_async_engine(uri, echo=False, pool_pre_ping=True)
    
    try:
        async with engine.begin() as conn:
            # í…Œì´ë¸” ëª©ë¡ í™•ì¸
            print("=" * 80)
            print("í´ëŸ¬ìŠ¤í„°ë§ ê´€ë ¨ í…Œì´ë¸” í™•ì¸")
            print("=" * 80)
            
            tables = [
                'clustering_sessions',
                'panel_cluster_mappings',
                'umap_coordinates',
                'cluster_profiles',
                'cluster_metadata',
                'cluster_comparisons'
            ]
            
            for table_name in tables:
                print(f"\nğŸ“‹ í…Œì´ë¸”: {table_name}")
                print("-" * 80)
                
                # í…Œì´ë¸” ì¡´ì¬ ì—¬ë¶€ í™•ì¸
                check_table = await conn.execute(text(f"""
                    SELECT EXISTS (
                        SELECT FROM information_schema.tables 
                        WHERE table_name = '{table_name}'
                    );
                """))
                exists = check_table.scalar()
                
                if not exists:
                    print(f"  âŒ í…Œì´ë¸”ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                    continue
                
                # ì»¬ëŸ¼ ì •ë³´ ì¡°íšŒ
                columns_query = await conn.execute(text(f"""
                    SELECT 
                        column_name,
                        data_type,
                        character_maximum_length,
                        is_nullable,
                        column_default
                    FROM information_schema.columns
                    WHERE table_name = '{table_name}'
                    ORDER BY ordinal_position;
                """))
                
                columns = columns_query.fetchall()
                print(f"  âœ… í…Œì´ë¸” ì¡´ì¬ (ì»¬ëŸ¼ ìˆ˜: {len(columns)})")
                print(f"\n  ì»¬ëŸ¼ êµ¬ì¡°:")
                for col in columns:
                    col_name = col[0]
                    col_type = col[1]
                    col_length = f"({col[2]})" if col[2] else ""
                    nullable = "NULL" if col[3] == 'YES' else "NOT NULL"
                    default = f" DEFAULT {col[4]}" if col[4] else ""
                    print(f"    - {col_name}: {col_type}{col_length} {nullable}{default}")
                
                # í–‰ ìˆ˜ í™•ì¸
                count_query = await conn.execute(text(f"SELECT COUNT(*) FROM {table_name};"))
                row_count = count_query.scalar()
                print(f"\n  ë°ì´í„° í–‰ ìˆ˜: {row_count:,}ê°œ")
                
                # ìƒ˜í”Œ ë°ì´í„° í™•ì¸ (ìˆëŠ” ê²½ìš°)
                if row_count > 0:
                    sample_query = await conn.execute(text(f"SELECT * FROM {table_name} LIMIT 1;"))
                    sample = sample_query.fetchone()
                    if sample:
                        print(f"\n  ìƒ˜í”Œ ë°ì´í„° (ì²« ë²ˆì§¸ í–‰):")
                        for i, col in enumerate(columns):
                            col_name = col[0]
                            value = sample[i]
                            if isinstance(value, (dict, list)):
                                value_str = str(value)[:100] + "..." if len(str(value)) > 100 else str(value)
                            else:
                                value_str = str(value)[:100] + "..." if len(str(value)) > 100 else str(value)
                            print(f"    - {col_name}: {value_str}")
            
            # ì¸ë±ìŠ¤ í™•ì¸
            print(f"\n\nğŸ“Š ì¸ë±ìŠ¤ ì •ë³´")
            print("-" * 80)
            for table_name in tables:
                indexes_query = await conn.execute(text(f"""
                    SELECT 
                        indexname,
                        indexdef
                    FROM pg_indexes
                    WHERE tablename = '{table_name}'
                    ORDER BY indexname;
                """))
                indexes = indexes_query.fetchall()
                if indexes:
                    print(f"\n  í…Œì´ë¸”: {table_name}")
                    for idx in indexes:
                        print(f"    - {idx[0]}")
                        print(f"      {idx[1]}")
            
            # ë·° í™•ì¸
            print(f"\n\nğŸ‘ï¸ ë·° ì •ë³´")
            print("-" * 80)
            views = ['clustering_sessions_summary', 'cluster_panel_counts']
            for view_name in views:
                check_view = await conn.execute(text(f"""
                    SELECT EXISTS (
                        SELECT FROM information_schema.views 
                        WHERE table_name = '{view_name}'
                    );
                """))
                exists = check_view.scalar()
                if exists:
                    print(f"  âœ… {view_name} ì¡´ì¬")
                else:
                    print(f"  âŒ {view_name} ì—†ìŒ")
            
            # Precomputed ì„¸ì…˜ í™•ì¸
            print(f"\n\nğŸ” Precomputed ì„¸ì…˜ í™•ì¸")
            print("-" * 80)
            precomputed_query = await conn.execute(text("""
                SELECT 
                    session_id,
                    precomputed_name,
                    n_samples,
                    n_clusters,
                    algorithm,
                    created_at,
                    is_precomputed
                FROM clustering_sessions
                WHERE is_precomputed = TRUE
                ORDER BY created_at DESC;
            """))
            precomputed_sessions = precomputed_query.fetchall()
            
            if precomputed_sessions:
                print(f"  âœ… Precomputed ì„¸ì…˜: {len(precomputed_sessions)}ê°œ")
                for session in precomputed_sessions:
                    print(f"\n    ì„¸ì…˜ ID: {session[0]}")
                    print(f"    ì´ë¦„: {session[1]}")
                    print(f"    ìƒ˜í”Œ ìˆ˜: {session[2]:,}ê°œ")
                    print(f"    í´ëŸ¬ìŠ¤í„° ìˆ˜: {session[3]}ê°œ")
                    print(f"    ì•Œê³ ë¦¬ì¦˜: {session[4]}")
                    print(f"    ìƒì„±ì¼: {session[5]}")
            else:
                print(f"  âš ï¸ Precomputed ì„¸ì…˜ì´ ì—†ìŠµë‹ˆë‹¤.")
            
            # ì „ì²´ ì„¸ì…˜ í†µê³„
            print(f"\n\nğŸ“ˆ ì „ì²´ ì„¸ì…˜ í†µê³„")
            print("-" * 80)
            stats_query = await conn.execute(text("""
                SELECT 
                    COUNT(*) as total_sessions,
                    COUNT(*) FILTER (WHERE is_precomputed = TRUE) as precomputed_sessions,
                    COUNT(*) FILTER (WHERE is_precomputed = FALSE) as regular_sessions,
                    SUM(n_samples) as total_samples,
                    AVG(n_clusters) as avg_clusters
                FROM clustering_sessions;
            """))
            stats = stats_query.fetchone()
            if stats and stats[0]:
                print(f"  ì´ ì„¸ì…˜ ìˆ˜: {stats[0]}ê°œ")
                print(f"  - Precomputed: {stats[1]}ê°œ")
                print(f"  - ì¼ë°˜: {stats[2]}ê°œ")
                print(f"  ì´ ìƒ˜í”Œ ìˆ˜: {stats[3]:,}ê°œ")
                print(f"  í‰ê·  í´ëŸ¬ìŠ¤í„° ìˆ˜: {stats[4]:.1f}ê°œ")
            
            print("\n" + "=" * 80)
            print("ìŠ¤í‚¤ë§ˆ í™•ì¸ ì™„ë£Œ")
            print("=" * 80)
            
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        traceback.print_exc()
    finally:
        await engine.dispose()

if __name__ == "__main__":
    asyncio.run(check_clustering_schema())

