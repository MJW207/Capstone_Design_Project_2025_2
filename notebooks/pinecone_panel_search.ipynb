{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pinecone 패널 검색 시스템 (메타데이터 필터 + 다중 값 지원)\n",
    "\n",
    "## 주요 개선사항\n",
    "- **Pinecone 벡터 데이터베이스**: 클라우드 기반 고성능 벡터 검색\n",
    "- **메타데이터 필터 적용**: 지역, 연령대, 성별 등 정확한 필터링\n",
    "- **다중 값 필터 지원**: $in 연산자로 \"서울, 경기\" 같은 다중 조건 지원\n",
    "- **Fallback 메커니즘**: 메타데이터 필터로 0건이면 topic만으로 재검색\n",
    "\n",
    "## 검색 파이프라인\n",
    "1. **메타데이터 추출**: LLM으로 검색 쿼리에서 구조화된 메타데이터 추출\n",
    "2. **카테고리 분류**: LLM으로 메타데이터를 카테고리별로 분류\n",
    "3. **텍스트 생성**: 카테고리별로 자연어 텍스트 생성\n",
    "4. **임베딩 생성**: Upstage Solar (query 모델) 임베딩\n",
    "5. **Pinecone 검색**: topic + 메타데이터 필터로 정확한 검색\n",
    "6. **단계적 필터링**: 여러 카테고리를 순차적으로 적용하여 후보 축소\n",
    "\n",
    "## 필요한 패키지\n",
    "```bash\n",
    "pip install anthropic langchain-upstage pinecone-client\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 라이브러리 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "from typing import List, Dict, Any, Optional\n",
    "from anthropic import Anthropic\n",
    "from langchain_upstage import UpstageEmbeddings\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 설정 및 Config 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 환경 설정 완료\n",
      "   카테고리 수: 17개\n",
      "   Pinecone 인덱스: panel-profiles\n"
     ]
    }
   ],
   "source": [
    "# Pinecone 설정\n",
    "PINECONE_API_KEY = os.getenv('PINECONE_API_KEY', 'pcsk_7H6b9v_Ryek82UqkXvJ8rM2Lsfrzu49R2U3XBuAeU9yFUoTjC2LPqyTVTMCn9r4QQwjqop')  # ⭐ 실제 API 키로 변경\n",
    "PINECONE_INDEX_NAME = \"panel-profiles\"  # Pinecone 인덱스 이름\n",
    "PINECONE_ENVIRONMENT = \"us-east-1\"  # Pinecone 환경 (리전)\n",
    "\n",
    "# API Keys\n",
    "UPSTAGE_API_KEY = os.getenv('UPSTAGE_API_KEY', 'up_2KGGBmZpBmlePxUyk3ouWBf9iqOmJ')\n",
    "ANTHROPIC_API_KEY = os.getenv('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')\n",
    "\n",
    "# category_config.json 로드\n",
    "CATEGORY_CONFIG_PATH = r\"C:\\Capstone\\search2\\category_config.json\"\n",
    "\n",
    "with open(CATEGORY_CONFIG_PATH, 'r', encoding='utf-8') as f:\n",
    "    CATEGORY_CONFIG = json.load(f)\n",
    "\n",
    "print(\"✅ 환경 설정 완료\")\n",
    "print(f\"   카테고리 수: {len(CATEGORY_CONFIG)}개\")\n",
    "print(f\"   Pinecone 인덱스: {PINECONE_INDEX_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 메타데이터 추출기 (LLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MetadataExtractor 클래스 정의 완료 (직업 15개 보기 정규화 추가)\n"
     ]
    }
   ],
   "source": [
    "class MetadataExtractor:\n",
    "    \"\"\"LLM으로 검색 쿼리에서 메타데이터 추출\"\"\"\n",
    "\n",
    "    def __init__(self, api_key: str):\n",
    "        self.client = Anthropic(api_key=api_key)\n",
    "        self.model = \"claude-sonnet-4-5-20250929\"\n",
    "\n",
    "    def extract(self, query: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        자연어 쿼리에서 구조화된 메타데이터 추출 (다중 값/범위 지원)\n",
    "\n",
    "        Args:\n",
    "            query: 검색 쿼리 (예: \"서울 강남구 27세 기혼 남자\")\n",
    "\n",
    "        Returns:\n",
    "            메타데이터 딕셔너리 (예: {\"지역\": \"서울\", \"지역구\": \"강남구\", \"나이\": 27, \"연령대\": \"20대\", \"성별\": \"남\", \"결혼여부\": \"기혼\"})\n",
    "        \"\"\"\n",
    "        prompt = f\"\"\"당신은 자연어 질의에서 메타데이터를 추출하는 전문가입니다.\n",
    "\n",
    "자연어 질의를 분석하여 모든 정보를 메타데이터로 추출하세요.\n",
    "\n",
    "=== 추출 규칙 ===\n",
    "\n",
    "1. **지역 관련 정보는 모두 \"지역\" 키로 추출** (매우 중요!)\n",
    "   - 국내 지역: \"서울\", \"경기\", \"부산\" 등 → \"지역\" 키 사용\n",
    "   - 지역구: \"강남구\", \"서초구\", \"양산시\" 등 → \"지역구\" 키로 별도 추출\n",
    "   - 해외 관련: \"해외\", \"외국\", \"국외\", \"외국인\", \"해외 거주\" 등 → \"지역\": \"해외\"\n",
    "   - \"거주지\", \"거주\", \"사는 곳\" 등의 키 사용 금지\n",
    "   - 반드시 \"지역\" 키만 사용할 것\n",
    "\n",
    "2. **다중 값은 리스트로 표현**\n",
    "   - \"서울, 경기\" → \"지역\": [\"서울\", \"경기\"]\n",
    "   - \"서울 또는 경기\" → \"지역\": [\"서울\", \"경기\"]\n",
    "   - \"20대, 30대\" → \"연령대\": [\"20대\", \"30대\"]\n",
    "\n",
    "3. **나이와 연령대 모두 추출**\n",
    "   - \"27세\" → \"나이\": 27, \"연령대\": \"20대\"\n",
    "   - \"35세\" → \"나이\": 35, \"연령대\": \"30대\"\n",
    "   - 연령대만 있으면: \"20대\" → \"연령대\": \"20대\"\n",
    "\n",
    "4. **범위는 연령대 리스트로 변환**\n",
    "   - \"10~20세\" → \"연령대\": [\"10대\", \"20대\"]\n",
    "   - \"20대~30대\" → \"연령대\": [\"20대\", \"30대\"]\n",
    "   - **\"40세 이하\" → \"연령대\": [\"10대\", \"20대\", \"30대\", \"40대\"]** ⭐\n",
    "   - **\"40대 이하\" → \"연령대\": [\"10대\", \"20대\", \"30대\", \"40대\"]** ⭐\n",
    "\n",
    "5. **성별 정규화**\n",
    "   - \"남성\", \"남자\", \"남\" → \"남자\"\n",
    "   - \"여성\", \"여자\", \"여\" → \"여자\"\n",
    "\n",
    "6. **결혼여부 추출** (⭐⭐⭐ 가장 중요! 절대 지켜야 함!)\n",
    "   - 반드시 \"결혼여부\" 키만 사용 (다른 키 사용 절대 금지!)\n",
    "   - \"기혼\", \"결혼한\", \"결혼한 사람\", \"결혼함\" → \"결혼여부\": \"기혼\"\n",
    "   - \"미혼\", \"미혼인\", \"결혼 안한\" → \"결혼여부\": \"미혼\"\n",
    "   - ⚠️ 절대 사용 금지 키: \"결혼상태\", \"결혼상황\", \"혼인\", \"결혼\" (이런 키 쓰면 안됨!)\n",
    "\n",
    "7. **자녀수/가족수 추출** (⭐⭐⭐ 매우 중요!)\n",
    "   - 반드시 \"자녀수\", \"가족수\" 키만 사용 (다른 키 사용 절대 금지!)\n",
    "   - \"자녀 2명\" → \"자녀수\": 2\n",
    "   - \"가족 3명\", \"가족 구성 3명\" → \"가족수\": 3\n",
    "   - **\"혼자 사는\", \"1인 가구\", \"독거\", \"혼자 거주\" → \"가족수\": 1** ⭐\n",
    "   - **\"2인 가구\" → \"가족수\": 2** ⭐\n",
    "   - ⚠️ 절대 사용 금지 키: \"가구형태\", \"가구유형\", \"거주형태\" (이런 키 쓰면 안됨!)\n",
    "\n",
    "8. **학력 추출**\n",
    "   - \"고졸\", \"고등학교 졸업\" → \"학력\": \"고등학교 졸업 이하\"\n",
    "   - \"대학생\", \"대학 재학\" → \"학력\": \"대학교 재학\"\n",
    "   - \"대졸\", \"대학교 졸업\" → \"학력\": \"대학교 졸업\"\n",
    "   - \"대학원\", \"석사\", \"박사\" → \"학력\": \"대학원 재학/졸업 이상\"\n",
    "\n",
    "9. **직업 추출** (⭐⭐⭐ 매우 중요: 15개 보기 중 하나로 정확히 매핑)\n",
    "   - **전문직**: 의사, 간호사, 변호사, 회계사, 예술가, 종교인, 엔지니어, 프로그래머, 기술사\n",
    "   - **교직**: 교수, 교사, 강사\n",
    "   - **경영/관리직**: 사장, 임원, 대기업 간부, 고위 공무원\n",
    "   - **사무직**: 일반 사무직, 은행원, 공무원, 군인, 경찰, 소방관\n",
    "   - **자영업**: 제조업, 건설업, 도소매업, 운수업, 무역업, 서비스업 경영 (⭐ 건설업은 자영업!)\n",
    "   - **판매직**: 매장 판매직, 세일즈, 보험설계사, 텔레마케터, 영업\n",
    "   - **서비스직**: 미용, 통신, 안내, 요식업 직원\n",
    "   - **생산/노무직**: 차량운전자, 현장직, 생산직 (⭐ 건설 현장직만 해당, 건설업 경영은 자영업)\n",
    "   - **기능직**: 제빵사, 목수, 전기공, 정비사, 배관공\n",
    "   - **농업/임업/축산업/광업/수산업**\n",
    "   - **임대업**\n",
    "   - **중/고등학생**\n",
    "   - **대학생/대학원생**\n",
    "   - **전업주부**\n",
    "   - **퇴직/연금생활자**\n",
    "\n",
    "   중요한 구분:\n",
    "   - \"건설업 경영\", \"건설업에서 일하는\", \"건설업 종사\" → \"자영업\"\n",
    "   - \"건설 현장\", \"건설 노무자\", \"건설 일용직\" → \"생산/노무직\"\n",
    "\n",
    "10. **자동차 정보 추출** (⭐ 새로 추가!)\n",
    "   - \"타는\", \"운전하는\", \"소유한\", \"보유한\" 등의 표현에서 자동차 추출\n",
    "   - 브랜드와 모델명 함께 추출: \"자동차\": \"브랜드 모델명\"\n",
    "   - 예: \"테슬라 사이버트럭 타는\" → \"자동차\": \"테슬라 사이버트럭\"\n",
    "   - 예: \"현대 소나타\" → \"자동차\": \"현대 소나타\"\n",
    "   - 예: \"BMW\" → \"자동차\": \"BMW\"\n",
    "   - 차량 없음: \"차 없는\", \"자동차 없는\" → \"자동차\": \"없음\"\n",
    "\n",
    "11. **휴대폰 정보 추출** (⭐ 새로 추가!)\n",
    "   - \"쓰는\", \"사용하는\", \"보유한\" 등의 표현에서 휴대폰 추출\n",
    "   - 브랜드와 모델명 추출: \"휴대폰\": \"브랜드 모델명\"\n",
    "   - 예: \"아이폰 쓰는\" → \"휴대폰\": \"아이폰\"\n",
    "   - 예: \"삼성 갤럭시\" → \"휴대폰\": \"삼성 갤럭시\"\n",
    "   - 예: \"iPhone 15\" → \"휴대폰\": \"iPhone 15\"\n",
    "\n",
    "12. **전자제품 정보 추출** (⭐ 새로 추가!)\n",
    "   - TV, 냉장고, 세탁기, 에어컨 등\n",
    "   - \"전자제품\": \"제품명\" 또는 \"전자제품\": [\"제품1\", \"제품2\"]\n",
    "   - 예: \"LG TV 사용하는\" → \"전자제품\": \"LG TV\"\n",
    "\n",
    "13. **음주 정보 추출** (⭐ 새로 추가!)\n",
    "   - \"술\", \"음주\", \"마시는\", \"먹은\", \"좋아하는\" 등의 표현에서 음주 추출\n",
    "   - 술 종류와 함께 추출: \"음주\": \"술 종류\" 또는 \"음주\": \"경험\"\n",
    "   - 예: \"술을 먹은\" → \"음주\": \"경험\"\n",
    "   - 예: \"술 마시는\" → \"음주\": \"경험\"\n",
    "   - 예: \"소주 마시는\" → \"음주\": \"소주\"\n",
    "   - 예: \"맥주 좋아하는\" → \"음주\": \"맥주\"\n",
    "   - 여러 종류: \"소주, 맥주\" → \"음주\": [\"소주\", \"맥주\"]\n",
    "\n",
    "14. **흡연 정보 추출** (⭐ 새로 추가!)\n",
    "   - \"담배\", \"흡연\", \"피우는\" 등의 표현에서 흡연 추출\n",
    "   - \"흡연\": \"경험\" 또는 \"흡연\": \"일반담배\"\n",
    "   - 예: \"담배 피우는\" → \"흡연\": \"일반담배\"\n",
    "   - 예: \"흡연하는\" → \"흡연\": \"경험\"\n",
    "   - 예: \"전자담배\" → \"흡연\": \"전자담배\"\n",
    "   - 비흡연: \"담배 안 피우는\", \"비흡연\" → \"흡연\": \"없음\"\n",
    "\n",
    "15. **모호한 표현 해석**\n",
    "   - \"젊은층\", \"청년\" → \"연령대\": [\"20대\", \"30대\"]\n",
    "   - \"중년층\", \"장년\" → \"연령대\": [\"40대\", \"50대\"]\n",
    "   - \"MZ세대\" → \"연령대\": [\"20대\", \"30대\"]\n",
    "\n",
    "16. **전국/전체는 빈 값으로 처리**\n",
    "   - \"전국\" → 지역 필드 생성하지 않음\n",
    "\n",
    "17. **수도권 특별 처리**\n",
    "   - \"수도권\" → \"지역\": [\"서울\", \"경기\", \"인천\"]\n",
    "\n",
    "=== 예시 ===\n",
    "\n",
    "입력: \"서울 강남구 27세 기혼 남자\"\n",
    "출력:\n",
    "{{\n",
    "    \"지역\": \"서울\",\n",
    "    \"지역구\": \"강남구\",\n",
    "    \"나이\": 27,\n",
    "    \"연령대\": \"20대\",\n",
    "    \"결혼여부\": \"기혼\",\n",
    "    \"성별\": \"남자\"\n",
    "}}\n",
    "\n",
    "입력: \"테슬라 사이버트럭 타는 패널\"\n",
    "출력:\n",
    "{{\n",
    "    \"자동차\": \"테슬라 사이버트럭\"\n",
    "}}\n",
    "\n",
    "입력: \"아이폰 쓰는 30대\"\n",
    "출력:\n",
    "{{\n",
    "    \"휴대폰\": \"아이폰\",\n",
    "    \"연령대\": \"30대\"\n",
    "}}\n",
    "\n",
    "입력: \"술을 먹은\"\n",
    "출력:\n",
    "{{\n",
    "    \"음주\": \"경험\"\n",
    "}}\n",
    "\n",
    "입력: \"소주 마시는 30대\"\n",
    "출력:\n",
    "{{\n",
    "    \"음주\": \"소주\",\n",
    "    \"연령대\": \"30대\"\n",
    "}}\n",
    "\n",
    "입력: \"담배 피우는 사람\"\n",
    "출력:\n",
    "{{\n",
    "    \"흡연\": \"일반담배\"\n",
    "}}\n",
    "\n",
    "입력: \"건설업에서 근무하는 사람\"\n",
    "출력:\n",
    "{{\n",
    "    \"직업\": \"자영업\"\n",
    "}}\n",
    "\n",
    "질의: {query}\n",
    "\n",
    "⚠️⚠️⚠️ 필수 주의사항:\n",
    "- 직업은 15개 보기 중 하나로 정확히 매핑!\n",
    "- 자동차, 휴대폰, 전자제품, 음주, 흡연도 추출!\n",
    "- 건설업 = 자영업 (건설업 경영)\n",
    "- 건설 현장 = 생산/노무직 (건설 현장직)\n",
    "- 결혼 관련 정보는 반드시 \"결혼여부\" 키만 사용!\n",
    "- 가족/가구 관련 정보는 반드시 \"가족수\" 키만 사용!\n",
    "\n",
    "JSON만 반환하세요. 다른 설명은 하지 마세요.\n",
    "\"\"\"\n",
    "\n",
    "        try:\n",
    "            response = self.client.messages.create(\n",
    "                model=self.model,\n",
    "                max_tokens=1024,\n",
    "                temperature=0.0,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "            )\n",
    "\n",
    "            text = response.content[0].text\n",
    "            \n",
    "            # JSON 파싱 (코드블록 제거)\n",
    "            if '```json' in text:\n",
    "                json_text = text.split('```json')[1].split('```')[0].strip()\n",
    "            elif '```' in text:\n",
    "                json_text = text.split('```')[1].strip()\n",
    "            else:\n",
    "                json_text = text.strip()\n",
    "            \n",
    "            metadata = json.loads(json_text)\n",
    "            \n",
    "            # ===== 후처리: 키 이름 및 값 정규화 =====\n",
    "            print(f\"\\n[메타데이터 추출 - LLM 원본] {metadata}\")\n",
    "\n",
    "            # 1. 지역 키 정규화\n",
    "            if \"거주지\" in metadata and \"지역\" not in metadata:\n",
    "                metadata[\"지역\"] = metadata.pop(\"거주지\")\n",
    "            if \"거주\" in metadata and \"지역\" not in metadata:\n",
    "                metadata[\"지역\"] = metadata.pop(\"거주\")\n",
    "\n",
    "            # 2. 결혼여부 키 정규화\n",
    "            marriage_keys = [\"결혼상태\", \"결혼상황\", \"혼인\", \"혼인여부\", \"결혼\"]\n",
    "            for key in marriage_keys:\n",
    "                if key in metadata and \"결혼여부\" not in metadata:\n",
    "                    metadata[\"결혼여부\"] = metadata.pop(key)\n",
    "                    print(f\"   [후처리] '{key}' → '결혼여부'로 키 정규화\")\n",
    "                    break\n",
    "\n",
    "            # 3. 결혼여부 값 정규화\n",
    "            if \"결혼여부\" in metadata:\n",
    "                marriage = metadata[\"결혼여부\"]\n",
    "                if isinstance(marriage, str):\n",
    "                    original = marriage\n",
    "                    if marriage in [\"결혼함\", \"결혼\", \"결혼한\", \"기혼자\", \"유부남\", \"유부녀\"]:\n",
    "                        metadata[\"결혼여부\"] = \"기혼\"\n",
    "                        print(f\"   [후처리] 결혼여부 값 '{original}' → '기혼'으로 정규화\")\n",
    "                    elif marriage in [\"미혼인\", \"결혼 안함\", \"미혼자\"]:\n",
    "                        metadata[\"결혼여부\"] = \"미혼\"\n",
    "                        print(f\"   [후처리] 결혼여부 값 '{original}' → '미혼'으로 정규화\")\n",
    "\n",
    "            # 4. 가족수 키 정규화\n",
    "            household_keys = [\"가구형태\", \"가구유형\", \"거주형태\", \"가구구성\"]\n",
    "            for key in household_keys:\n",
    "                if key in metadata and \"가족수\" not in metadata:\n",
    "                    value = metadata.pop(key)\n",
    "                    if isinstance(value, str):\n",
    "                        import re\n",
    "                        match = re.search(r'(\\d+)인', value)\n",
    "                        if match:\n",
    "                            metadata[\"가족수\"] = int(match.group(1))\n",
    "                            print(f\"   [후처리] '{key}: {value}' → '가족수: {metadata['가족수']}'로 변환\")\n",
    "                    break\n",
    "\n",
    "            # 5. ⭐ 직업 정규화 (15개 보기로 매핑, 건설업 = 자영업)\n",
    "            if \"직업\" in metadata:\n",
    "                job = metadata[\"직업\"]\n",
    "                job_normalized = self._normalize_job(job)\n",
    "                if job_normalized != job:\n",
    "                    print(f\"   [후처리] 직업 '{job}' → '{job_normalized}'로 정규화\")\n",
    "                    metadata[\"직업\"] = job_normalized\n",
    "\n",
    "            # 6. 성별 정규화\n",
    "            if \"성별\" in metadata:\n",
    "                gender = metadata[\"성별\"]\n",
    "                if isinstance(gender, str):\n",
    "                    if gender in [\"남성\", \"남자\", \"male\", \"M\"]:\n",
    "                        metadata[\"성별\"] = \"남\"\n",
    "                    elif gender in [\"여성\", \"여자\", \"female\", \"F\"]:\n",
    "                        metadata[\"성별\"] = \"여\"\n",
    "                elif isinstance(gender, list):\n",
    "                    normalized = []\n",
    "                    for g in gender:\n",
    "                        if g in [\"남성\", \"남자\", \"male\", \"M\"]:\n",
    "                            normalized.append(\"남\")\n",
    "                        elif g in [\"여성\", \"여자\", \"female\", \"F\"]:\n",
    "                            normalized.append(\"여\")\n",
    "                        else:\n",
    "                            normalized.append(g)\n",
    "                    metadata[\"성별\"] = normalized\n",
    "\n",
    "            print(f\"[메타데이터 추출 - 최종] {metadata}\")\n",
    "            return metadata\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] 메타데이터 추출 실패: {e}\")\n",
    "            return {}\n",
    "\n",
    "    def _normalize_job(self, job: str) -> str:\n",
    "        \"\"\"\n",
    "        직업을 15개 보기 중 하나로 정규화\n",
    "        \n",
    "        ⭐ 중요: 원본 데이터의 직업 정의를 정확히 따름\n",
    "        - 자영업 = 제조업, 건설업, 도소매업, 운수업, 무역업, 서비스업 경영\n",
    "        - 생산/노무직 = 차량운전자, 건설 현장직, 생산직\n",
    "        \"\"\"\n",
    "        job_lower = job.lower()\n",
    "        \n",
    "        # ⭐⭐⭐ 우선순위 1: 자영업 (제조업, 건설업, 도소매업 등의 경영)\n",
    "        # \"건설업\", \"제조업\", \"도소매업\" 등은 자영업으로 매핑\n",
    "        if any(kw in job_lower for kw in [\"자영업\", \"사업\", \"경영\"]):\n",
    "            return \"자영업\"\n",
    "        # 건설업, 제조업 등의 업종명이 있고 \"현장\", \"노무\", \"일용직\"이 없으면 자영업\n",
    "        if any(kw in job_lower for kw in [\"건설업\", \"제조업\", \"도소매\", \"운수업\", \"무역업\", \"서비스업\"]) and \\\n",
    "           not any(kw in job_lower for kw in [\"현장\", \"노무\", \"일용\", \"기사\", \"운전\"]):\n",
    "            return \"자영업\"\n",
    "        \n",
    "        # 우선순위 2: 전문직\n",
    "        if any(kw in job_lower for kw in [\"전문직\", \"의사\", \"간호사\", \"변호사\", \"회계사\", \"예술가\", \"종교인\", \"엔지니어\", \"프로그래머\", \"기술사\"]):\n",
    "            return \"전문직\"\n",
    "        \n",
    "        # 우선순위 3: 교직\n",
    "        elif any(kw in job_lower for kw in [\"교직\", \"교수\", \"교사\", \"강사\"]):\n",
    "            return \"교직\"\n",
    "        \n",
    "        # 우선순위 4: 경영/관리직\n",
    "        elif any(kw in job_lower for kw in [\"경영\", \"관리직\", \"사장\", \"임원\", \"대기업 간부\", \"고위 공무원\"]):\n",
    "            return \"경영/관리직\"\n",
    "        \n",
    "        # 우선순위 5: 사무직\n",
    "        elif any(kw in job_lower for kw in [\"사무직\", \"공무원\", \"회사원\", \"직장인\", \"은행원\", \"군인\", \"경찰\", \"소방관\"]):\n",
    "            return \"사무직\"\n",
    "        \n",
    "        # 우선순위 6: 판매직\n",
    "        elif any(kw in job_lower for kw in [\"판매직\", \"세일즈\", \"보험설계사\", \"영업\"]):\n",
    "            return \"판매직\"\n",
    "        \n",
    "        # 우선순위 7: 서비스직\n",
    "        elif any(kw in job_lower for kw in [\"서비스직\", \"미용\", \"요식업\"]):\n",
    "            return \"서비스직\"\n",
    "        \n",
    "        # 우선순위 8: 생산/노무직 (건설 현장직, 운전기사 포함)\n",
    "        elif any(kw in job_lower for kw in [\"생산직\", \"노무직\", \"운전\", \"현장직\", \"일용직\", \"기사\"]):\n",
    "            return \"생산/노무직\"\n",
    "        \n",
    "        # 우선순위 9: 기능직\n",
    "        elif any(kw in job_lower for kw in [\"기능직\", \"기술직\", \"제빵\", \"목수\", \"전기공\", \"정비사\", \"배관공\"]):\n",
    "            return \"기능직\"\n",
    "        \n",
    "        # 우선순위 10: 농업/임업/축산업/광업/수산업\n",
    "        elif any(kw in job_lower for kw in [\"농업\", \"임업\", \"축산\", \"수산\", \"광업\"]):\n",
    "            return \"농업/임업/축산업/광업/수산업\"\n",
    "        \n",
    "        # 우선순위 11: 임대업\n",
    "        elif \"임대\" in job_lower:\n",
    "            return \"임대업\"\n",
    "        \n",
    "        # 우선순위 12: 중/고등학생\n",
    "        elif any(kw in job_lower for kw in [\"중학생\", \"고등학생\", \"학생\"]) and \"대학\" not in job_lower:\n",
    "            return \"중/고등학생\"\n",
    "        \n",
    "        # 우선순위 13: 대학생/대학원생\n",
    "        elif any(kw in job_lower for kw in [\"대학생\", \"대학원생\"]):\n",
    "            return \"대학생/대학원생\"\n",
    "        \n",
    "        # 우선순위 14: 전업주부\n",
    "        elif any(kw in job_lower for kw in [\"주부\", \"전업주부\"]):\n",
    "            return \"전업주부\"\n",
    "        \n",
    "        # 우선순위 15: 퇴직/연금생활자\n",
    "        elif any(kw in job_lower for kw in [\"퇴직\", \"은퇴\", \"연금\"]):\n",
    "            return \"퇴직/연금생활자\"\n",
    "        \n",
    "        # 15개 보기에 해당하지 않으면 그대로 반환\n",
    "        return job\n",
    "\n",
    "\n",
    "print(\"MetadataExtractor 클래스 정의 완료 (직업 15개 보기 정규화 추가)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 메타데이터 필터 추출기\n",
    "\n",
    "카테고리별로 사용할 메타데이터 필터를 추출합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ MetadataFilterExtractor 클래스 정의 완료 (직업/소득 필터 제거, 벡터 검색으로만 처리)\n"
     ]
    }
   ],
   "source": [
    "class MetadataFilterExtractor:\n",
    "    \"\"\"LLM으로 카테고리별 메타데이터 필터 추출 및 정규화 (복수 값 지원)\"\"\"\n",
    "\n",
    "    def __init__(self, api_key: str):\n",
    "        self.client = Anthropic(api_key=api_key)\n",
    "        self.model = \"claude-sonnet-4-5-20250929\"\n",
    "\n",
    "    def extract_filters(self, metadata: Dict[str, Any], category: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        특정 카테고리에 적용할 메타데이터 필터를 추출 및 정규화\n",
    "        \n",
    "        Args:\n",
    "            metadata: 전체 메타데이터\n",
    "            category: 카테고리명 (예: \"기본정보\")\n",
    "        \n",
    "        Returns:\n",
    "            정규화된 메타데이터 필터 (복수 값 포함)\n",
    "            예: {\"지역\": [\"서울\", \"경기\"], \"연령대\": [\"10대\", \"20대\"], \"성별\": \"남\", \"결혼여부\": \"기혼\"}\n",
    "        \"\"\"\n",
    "        # ⭐⭐⭐ ChromaDB 실제 메타데이터 구조에 맞춘 카테고리별 매핑\n",
    "        # ChromaDB 확인 결과:\n",
    "        #   - \"인구\" topic: 지역, 지역구, 연령대, 성별, 나이, 결혼여부, 자녀수, 가족수, 학력 (9개 필드)\n",
    "        #   - 기타 모든 topic: topic, index, mb_sn만 존재 (메타데이터 필터 사용 불가)\n",
    "        \n",
    "        CATEGORY_METADATA_MAPPING = {\n",
    "            \"기본정보\": [\"지역\", \"지역구\", \"연령대\", \"성별\", \"나이\", \"결혼여부\", \"자녀수\", \"가족수\", \"학력\"],\n",
    "        }\n",
    "        \n",
    "        applicable_keys = CATEGORY_METADATA_MAPPING.get(category, [])\n",
    "        \n",
    "        if not applicable_keys:\n",
    "            return {}\n",
    "        \n",
    "        # 해당 카테고리에 적용 가능한 메타데이터만 추출\n",
    "        relevant_metadata = {}\n",
    "        for key in applicable_keys:\n",
    "            if key in metadata:\n",
    "                relevant_metadata[key] = metadata[key]\n",
    "        \n",
    "        if not relevant_metadata:\n",
    "            return {}\n",
    "        \n",
    "        # ⭐ 복수 값 보존을 위해 rule-based 정규화 직접 사용\n",
    "        # LLM이 리스트를 단일 값으로 변환하는 문제를 해결\n",
    "        normalized_filter = self._rule_based_normalize(relevant_metadata)\n",
    "        \n",
    "        print(f\"   [{category}] 필터 정규화: {relevant_metadata} → {normalized_filter}\")\n",
    "        return normalized_filter\n",
    "\n",
    "    def _rule_based_normalize(self, metadata: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"규칙 기반 정규화 (복수 값 지원, 새 필터 포함)\"\"\"\n",
    "        filter_dict = {}\n",
    "        \n",
    "        # 지역명 매핑\n",
    "        region_mapping = {\n",
    "            \"서울특별시\": \"서울\", \"서울시\": \"서울\",\n",
    "            \"부산광역시\": \"부산\", \"부산시\": \"부산\",\n",
    "            \"대구광역시\": \"대구\", \"대구시\": \"대구\",\n",
    "            \"인천광역시\": \"인천\", \"인천시\": \"인천\",\n",
    "            \"광주광역시\": \"광주\", \"광주시\": \"광주\",\n",
    "            \"대전광역시\": \"대전\", \"대전시\": \"대전\",\n",
    "            \"울산광역시\": \"울산\", \"울산시\": \"울산\",\n",
    "            \"세종특별자치시\": \"세종\", \"세종시\": \"세종\",\n",
    "            \"경기도\": \"경기\", \"강원도\": \"강원\", \"강원특별자치도\": \"강원\",\n",
    "            \"충청북도\": \"충북\", \"충북도\": \"충북\",\n",
    "            \"충청남도\": \"충남\", \"충남도\": \"충남\",\n",
    "            \"전라북도\": \"전북\", \"전북도\": \"전북\", \"전북특별자치도\": \"전북\",\n",
    "            \"전라남도\": \"전남\", \"전남도\": \"전남\",\n",
    "            \"경상북도\": \"경북\", \"경북도\": \"경북\",\n",
    "            \"경상남도\": \"경남\", \"경남도\": \"경남\",\n",
    "            \"제주특별자치도\": \"제주\", \"제주도\": \"제주\", \"제주시\": \"제주\",\n",
    "            \"해외\": \"해외\", \"외국\": \"해외\", \"국외\": \"해외\",\n",
    "        }\n",
    "        \n",
    "        # 학력 매핑 (텍스트 정규화)\n",
    "        education_mapping = {\n",
    "            \"고졸\": \"고등학교 졸업 이하\",\n",
    "            \"고등학교\": \"고등학교 졸업 이하\",\n",
    "            \"고등학교 졸업\": \"고등학교 졸업 이하\",\n",
    "            \"대학생\": \"대학교 재학\",\n",
    "            \"대학 재학\": \"대학교 재학\",\n",
    "            \"대학교 재학\": \"대학교 재학\",\n",
    "            \"대재\": \"대학교 재학\",\n",
    "            \"대졸\": \"대학교 졸업\",\n",
    "            \"대학 졸업\": \"대학교 졸업\",\n",
    "            \"대학교 졸업\": \"대학교 졸업\",\n",
    "            \"대학원\": \"대학원 재학/졸업 이상\",\n",
    "            \"석사\": \"대학원 재학/졸업 이상\",\n",
    "            \"박사\": \"대학원 재학/졸업 이상\",\n",
    "            \"대학원 재학\": \"대학원 재학/졸업 이상\",\n",
    "            \"대학원 졸업\": \"대학원 재학/졸업 이상\",\n",
    "        }\n",
    "        \n",
    "        for key, value in metadata.items():\n",
    "            if not value or value == '':\n",
    "                continue\n",
    "            \n",
    "            # 리스트인 경우 모든 값을 정규화\n",
    "            if isinstance(value, list):\n",
    "                normalized_list = []\n",
    "                for item in value:\n",
    "                    if key == \"지역\":\n",
    "                        normalized_list.append(region_mapping.get(item, item))\n",
    "                    elif key == \"성별\":\n",
    "                        if item in [\"남성\", \"남자\", \"male\", \"M\"]:\n",
    "                            normalized_list.append(\"남\")\n",
    "                        elif item in [\"여성\", \"여자\", \"female\", \"F\"]:\n",
    "                            normalized_list.append(\"여\")\n",
    "                        else:\n",
    "                            normalized_list.append(item)\n",
    "                    elif key == \"학력\":\n",
    "                        normalized_list.append(education_mapping.get(item, item))\n",
    "                    else:\n",
    "                        normalized_list.append(item)\n",
    "                filter_dict[key] = normalized_list\n",
    "            else:\n",
    "                # 단일 값인 경우\n",
    "                if key == \"지역\":\n",
    "                    value = region_mapping.get(value, value)\n",
    "                elif key == \"성별\":\n",
    "                    if value in [\"남성\", \"남자\", \"male\", \"M\"]:\n",
    "                        value = \"남\"\n",
    "                    elif value in [\"여성\", \"여자\", \"female\", \"F\"]:\n",
    "                        value = \"여\"\n",
    "                elif key == \"학력\":\n",
    "                    value = education_mapping.get(value, value)\n",
    "                elif key == \"결혼여부\":\n",
    "                    # 결혼여부 정규화: \"기혼\", \"미혼\", \"기타\" 중 하나\n",
    "                    if value in [\"결혼\", \"결혼한\", \"기혼자\"]:\n",
    "                        value = \"기혼\"\n",
    "                    elif value in [\"미혼자\", \"결혼 안한\"]:\n",
    "                        value = \"미혼\"\n",
    "                # 나이, 자녀수, 가족수는 숫자 그대로 유지\n",
    "                elif key in [\"나이\", \"자녀수\", \"가족수\"]:\n",
    "                    # 문자열이면 int로 변환 시도\n",
    "                    if isinstance(value, str) and value.isdigit():\n",
    "                        value = int(value)\n",
    "                \n",
    "                filter_dict[key] = value\n",
    "        \n",
    "        return filter_dict\n",
    "\n",
    "\n",
    "print(\"✅ MetadataFilterExtractor 클래스 정의 완료 (직업/소득 필터 제거, 벡터 검색으로만 처리)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 카테고리 분류기 (간소화)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CategoryClassifier 클래스 정의 완료\n"
     ]
    }
   ],
   "source": [
    "class CategoryClassifier:\n",
    "    \"\"\"LLM으로 메타데이터를 카테고리별로 분류 (panel_search.ipynb와 동일)\"\"\"\n",
    "\n",
    "    def __init__(self, category_config: Dict[str, Any], api_key: str):\n",
    "        self.category_config = category_config\n",
    "        self.client = Anthropic(api_key=api_key)\n",
    "        self.model = \"claude-sonnet-4-5-20250929\"\n",
    "\n",
    "    def _build_prompt(self, metadata: Dict[str, Any]) -> str:\n",
    "        \"\"\"카테고리 설명 + 메타데이터를 포함한 LLM용 프롬프트 생성\"\"\"\n",
    "        \n",
    "        # 카테고리 설명\n",
    "        category_desc = \"\\n\".join([\n",
    "            f\"- {cat}: {info.get('description', ', '.join(info.get('keywords', [])))}\"\n",
    "            for cat, info in self.category_config.items()\n",
    "        ])\n",
    "\n",
    "        # 키: 값 형식으로 메타데이터 나열\n",
    "        meta_lines = [f\"{k}: {v}\" for k, v in metadata.items()]\n",
    "        meta_text = \"\\n\".join(meta_lines)\n",
    "\n",
    "        # 사용 가능한 키 이름 목록\n",
    "        meta_keys = \", \".join(metadata.keys())\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "당신은 메타데이터를 카테고리로 분류하는 전문가입니다.\n",
    "\n",
    "다음은 사용할 수 있는 카테고리 목록과 설명입니다:\n",
    "{category_desc}\n",
    "\n",
    "다음은 분류해야 할 메타데이터입니다 (키: 값 형식):\n",
    "{meta_text}\n",
    "\n",
    "이때 사용할 수 있는 '키 이름' 목록은 다음과 같습니다:\n",
    "{meta_keys}\n",
    "\n",
    "당신의 작업:\n",
    "각 메타데이터의 \"키 이름\"을 정확히 하나의 카테고리에 배정하세요.\n",
    "\n",
    "출력은 반드시 아래 JSON 형식을 따라야 합니다 (예시는 구조만 참고):\n",
    "\n",
    "{{\n",
    "  \"기본정보\": [\"지역\", \"성별\"],\n",
    "  \"미디어\": [\"조건\"],\n",
    "  \"스트레스\": [],\n",
    "  \"기타\": []\n",
    "}}\n",
    "\n",
    "카테고리 작업 규칙:\n",
    "1. 각 메타데이터 키는 반드시 1개의 카테고리에만 속해야 합니다.\n",
    "2. \"키: 값\" 전체를 쓰지 말고, 오직 '키 이름'만 써야 합니다.\n",
    "3. 값(value)이나 새로운 문장, 설명문, 여분의 텍스트는 절대 포함하지 마세요.\n",
    "4. 반드시 위에 나열된 키 이름만 사용하세요. 값이나 문장을 JSON에 넣으면 안 됩니다.\n",
    "\n",
    "JSON만 반환하세요:\n",
    "\"\"\"\n",
    "        return prompt.strip()\n",
    "\n",
    "    def classify(self, metadata: Dict[str, Any]) -> Dict[str, List[str]]:\n",
    "        \"\"\"\n",
    "        메타데이터를 LLM을 통해 카테고리별로 분류\n",
    "\n",
    "        Returns:\n",
    "            {\"카테고리명\": [\"키: 값\", \"키: 값\", ...]}\n",
    "        \"\"\"\n",
    "        if not metadata:\n",
    "            return {}\n",
    "\n",
    "        prompt = self._build_prompt(metadata)\n",
    "\n",
    "        try:\n",
    "            # LLM 호출\n",
    "            response = self.client.messages.create(\n",
    "                model=self.model,\n",
    "                max_tokens=1024,\n",
    "                temperature=0.2,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "            )\n",
    "            \n",
    "            raw_output = response.content[0].text.strip()\n",
    "\n",
    "            # JSON 파싱\n",
    "            mapping_tokens = self._parse_llm_output(raw_output)\n",
    "\n",
    "            # 토큰들을 실제 메타데이터 키로 매핑\n",
    "            categorized: Dict[str, List[str]] = {}\n",
    "            used_keys: set = set()\n",
    "\n",
    "            for cat, tokens in mapping_tokens.items():\n",
    "                for token in tokens:\n",
    "                    meta_key = self._match_llm_token_to_key(token, metadata, used_keys)\n",
    "                    if meta_key is None:\n",
    "                        continue\n",
    "                    categorized.setdefault(cat, []).append(f\"{meta_key}: {metadata[meta_key]}\")\n",
    "                    used_keys.add(meta_key)\n",
    "\n",
    "            # 아무 것도 매핑 안 됐으면 rule-based로 폴백\n",
    "            if not categorized:\n",
    "                print(\"[WARN] LLM 기반 분류 결과 매핑 실패 -> rule-based로 대체\")\n",
    "                return self._rule_based_classify(metadata)\n",
    "            \n",
    "            print(f\"\\n[카테고리 분류] {dict(categorized)}\")\n",
    "            return categorized\n",
    "\n",
    "        except Exception as e:\n",
    "            return self._rule_based_classify(metadata)\n",
    "\n",
    "    def _parse_llm_output(self, raw_output: str) -> Dict[str, List[str]]:\n",
    "        \"\"\"LLM이 반환한 raw 문자열을 JSON으로 파싱\"\"\"\n",
    "        # 코드블록 제거\n",
    "        if \"```json\" in raw_output:\n",
    "            try:\n",
    "                raw_output = raw_output.split(\"```json\", 1)[1].split(\"```\", 1)[0].strip()\n",
    "            except:\n",
    "                pass\n",
    "        elif \"```\" in raw_output:\n",
    "            try:\n",
    "                raw_output = raw_output.split(\"```\", 1)[1].split(\"```\", 1)[0].strip()\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        # JSON 파싱\n",
    "        parsed = json.loads(raw_output)\n",
    "\n",
    "        # 값들을 전부 리스트[str] 형태로 정규화\n",
    "        mapping_tokens: Dict[str, List[str]] = {}\n",
    "        for cat, vals in parsed.items():\n",
    "            if isinstance(vals, list):\n",
    "                tokens = [str(v).strip() for v in vals if str(v).strip()]\n",
    "            elif isinstance(vals, str):\n",
    "                tokens = [vals.strip()] if vals.strip() else []\n",
    "            elif isinstance(vals, dict):\n",
    "                tokens = [str(k).strip() for k in vals.keys() if str(k).strip()]\n",
    "            else:\n",
    "                tokens = [str(vals).strip()]\n",
    "\n",
    "            if tokens:\n",
    "                mapping_tokens[cat] = tokens\n",
    "\n",
    "        return mapping_tokens\n",
    "\n",
    "    def _match_llm_token_to_key(self, token: str, metadata: Dict[str, Any], used_keys: set) -> Optional[str]:\n",
    "        \"\"\"LLM이 JSON에 넣은 토큰을 실제 메타데이터 키로 매핑\"\"\"\n",
    "        t = token.strip()\n",
    "        if not t:\n",
    "            return None\n",
    "\n",
    "        # 1) 정확히 같은 키 이름\n",
    "        if t in metadata and t not in used_keys:\n",
    "            return t\n",
    "\n",
    "        # 2) \"키: 값\" 형식으로 온 경우\n",
    "        if \":\" in t:\n",
    "            left = t.split(\":\", 1)[0].strip()\n",
    "            if left in metadata and left not in used_keys:\n",
    "                return left\n",
    "\n",
    "        # 3) 값 문자열과의 유사 매칭\n",
    "        t_lower = t.lower()\n",
    "        for meta_key, meta_value in metadata.items():\n",
    "            if meta_key in used_keys:\n",
    "                continue\n",
    "            v_lower = str(meta_value).lower()\n",
    "\n",
    "            if t_lower in v_lower or v_lower in t_lower:\n",
    "                return meta_key\n",
    "\n",
    "        return None\n",
    "\n",
    "    def _rule_based_classify(self, metadata: Dict[str, Any]) -> Dict[str, List[str]]:\n",
    "        \"\"\"백업용: 기존 키워드 기반 규칙 분류\"\"\"\n",
    "        categorized: Dict[str, List[str]] = {}\n",
    "        for meta_key, meta_value in metadata.items():\n",
    "            matched_categories = self._match_categories(meta_value)\n",
    "            for category in matched_categories:\n",
    "                categorized.setdefault(category, []).append(f\"{meta_key}: {meta_value}\")\n",
    "        return categorized\n",
    "\n",
    "    def _match_categories(self, value) -> List[str]:\n",
    "        matched: List[str] = []\n",
    "        if isinstance(value, list):\n",
    "            for item in value:\n",
    "                if isinstance(item, str):\n",
    "                    matched.extend(self._match_single_value(item))\n",
    "        elif isinstance(value, str):\n",
    "            matched = self._match_single_value(value)\n",
    "        return list(set(matched))\n",
    "\n",
    "    def _match_single_value(self, value: str) -> List[str]:\n",
    "        matched: List[str] = []\n",
    "        value_lower = value.lower()\n",
    "        for category_name, category_info in self.category_config.items():\n",
    "            for keyword in category_info.get(\"keywords\", []):\n",
    "                if keyword.lower() in value_lower:\n",
    "                    matched.append(category_name)\n",
    "                    break\n",
    "        return matched\n",
    "\n",
    "\n",
    "print(\"CategoryClassifier 클래스 정의 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 텍스트 생성기 (LLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CategoryTextGenerator 클래스 정의 완료 (ChromaDB 저장 형식 + 직업 상세 설명)\n"
     ]
    }
   ],
   "source": [
    "class CategoryTextGenerator:\n",
    "    \"\"\"카테고리별로 자연어 텍스트 생성 (ChromaDB 저장 형식에 맞춤)\"\"\"\n",
    "\n",
    "    def __init__(self, api_key: str):\n",
    "        self.client = Anthropic(api_key=api_key)\n",
    "        self.model = \"claude-sonnet-4-5-20250929\"\n",
    "\n",
    "    def generate(self, category: str, metadata_items: List[str]) -> str:\n",
    "        \"\"\"\n",
    "        카테고리별 자연어 텍스트 생성 (ChromaDB 실제 저장 형식 참고)\n",
    "        \n",
    "        ⭐ 중요: ChromaDB에 저장된 텍스트 형식을 최대한 유사하게 생성해야 벡터 유사도가 높아짐\n",
    "        \"\"\"\n",
    "        if not metadata_items:\n",
    "            return \"\"\n",
    "\n",
    "        # 메타데이터를 딕셔너리로 파싱\n",
    "        metadata_dict = {}\n",
    "        for item in metadata_items:\n",
    "            if \": \" in item:\n",
    "                key, value = item.split(\": \", 1)\n",
    "                metadata_dict[key] = value\n",
    "\n",
    "        try:\n",
    "            # 카테고리별 템플릿 기반 텍스트 생성\n",
    "            text = self._generate_by_template(category, metadata_dict)\n",
    "            \n",
    "            if text:\n",
    "                print(f\"\\n[{category}] {text[:80]}...\")\n",
    "                return text\n",
    "            \n",
    "            # 템플릿이 없으면 LLM으로 생성\n",
    "            return self._generate_by_llm(category, metadata_items)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] 텍스트 생성 실패 ({category}): {e}\")\n",
    "            return \", \".join(metadata_items)\n",
    "\n",
    "    def _generate_by_template(self, category: str, metadata: Dict[str, str]) -> str:\n",
    "        \"\"\"\n",
    "        ChromaDB 저장 형식을 참고한 템플릿 기반 텍스트 생성\n",
    "        \n",
    "        실제 ChromaDB 저장 예시:\n",
    "        - 인구: \"경기 성남시에 거주하는 48세 남이며 미혼, 가족 구성은 2명, 최종 학력은 대학교 재학입니다.\"\n",
    "        - 직업소득: \"현재 직업은 전문직 (의사, 간호사, 변호사, 회계사, 예술가, 종교인, 엔지니어, 프로그래머, 기술사 등)이며, 직무는 IT입니다. 월평균 개인 소득은 월 600~699만원이고, 가구 소득은 월 600~699만원입니다.\"\n",
    "        \"\"\"\n",
    "        \n",
    "        if category == \"기본정보\":\n",
    "            # ChromaDB topic=\"인구\" 형식\n",
    "            parts = []\n",
    "            \n",
    "            # 지역 정보\n",
    "            if \"지역\" in metadata or \"지역구\" in metadata:\n",
    "                region_text = \"\"\n",
    "                if \"지역\" in metadata and \"지역구\" in metadata:\n",
    "                    region_text = f\"{metadata['지역']} {metadata['지역구']}\"\n",
    "                elif \"지역구\" in metadata:\n",
    "                    region_text = metadata['지역구']\n",
    "                elif \"지역\" in metadata:\n",
    "                    region_text = metadata['지역']\n",
    "                \n",
    "                if region_text:\n",
    "                    parts.append(f\"{region_text}에 거주하는\")\n",
    "            \n",
    "            # 나이\n",
    "            if \"나이\" in metadata:\n",
    "                parts.append(f\"{metadata['나이']}세\")\n",
    "                \n",
    "            # ⭐ 연령대 추가 (나이가 없을 때만 사용)\n",
    "            elif \"연령대\" in metadata:\n",
    "                parts.append(metadata['연령대'])\n",
    "            \n",
    "            # 성별\n",
    "            if \"성별\" in metadata:\n",
    "                parts.append(metadata['성별'])\n",
    "            \n",
    "            # 기본 정보 연결\n",
    "            base_text = \" \".join(parts) if parts else \"\"\n",
    "            \n",
    "            # 추가 정보 (이며 ~)\n",
    "            additional = []\n",
    "            if \"결혼여부\" in metadata:\n",
    "                additional.append(metadata['결혼여부'])\n",
    "            \n",
    "            if \"자녀수\" in metadata:\n",
    "                additional.append(f\"자녀는 {metadata['자녀수']}명\")\n",
    "            \n",
    "            if \"가족수\" in metadata:\n",
    "                additional.append(f\"가족 구성은 {metadata['가족수']}명\")\n",
    "            \n",
    "            if \"학력\" in metadata:\n",
    "                additional.append(f\"최종 학력은 {metadata['학력']}\")\n",
    "            \n",
    "            # 최종 조합\n",
    "            if base_text and additional:\n",
    "                return f\"{base_text}이며 {', '.join(additional)}입니다.\"\n",
    "            elif base_text:\n",
    "                return f\"{base_text}입니다.\"\n",
    "            elif additional:\n",
    "                return f\"{', '.join(additional)}입니다.\"\n",
    "            \n",
    "            return \"\"\n",
    "        \n",
    "        elif category == \"직업소득\":\n",
    "            # ChromaDB topic=\"직업소득\" 형식\n",
    "            # ⭐ 핵심: 실제 저장 형식은 매우 상세함\n",
    "            # \"현재 직업은 전문직 (의사, 간호사, 변호사, 회계사, 예술가, 종교인, 엔지니어, 프로그래머, 기술사 등)이며, 직무는 IT입니다. 월평균 개인 소득은 월 600~699만원이고, 가구 소득은 월 600~699만원입니다.\"\n",
    "            \n",
    "            # 직업별 상세 설명 매핑 (ChromaDB 실제 패턴)\n",
    "            job_details = {\n",
    "                \"전문직\": \" (의사, 간호사, 변호사, 회계사, 예술가, 종교인, 엔지니어, 프로그래머, 기술사 등)\",\n",
    "                \"사무직\": \" (일반 사무직, 은행원, 공무원, 군인, 경찰, 소방관 등)\",\n",
    "                \"서비스직\": \" (미용, 통신, 안내, 요식업 직원 등)\",\n",
    "                \"판매직\": \" (매장 판매직, 세일즈, 보험설계사, 텔레마케터, 영업 등)\",\n",
    "                \"생산직\": \" (차량운전자, 현장직, 생산직 등)\",\n",
    "                \"생산/노무직\": \" (차량운전자, 현장직, 생산직 등)\",\n",
    "                \"교직\": \" (교수, 교사, 강사 등)\",\n",
    "                \"자영업\": \" (제조업, 건설업, 도소매업, 운수업, 무역업, 서비스업 경영)\",\n",
    "                \"농/임/수산/축산업\": \"\",\n",
    "                \"대학생/대학원생\": \"\",\n",
    "                \"중/고등학생\": \"\",\n",
    "                \"전업주부\": \"\",\n",
    "                \"무직\": \"\",\n",
    "                \"은퇴\": \"\",\n",
    "                \"프리랜서\": \"\",\n",
    "                \"회사원\": \"\",  # 일반적인 경우\n",
    "            }\n",
    "            \n",
    "            parts = []\n",
    "            \n",
    "            if \"직업\" in metadata:\n",
    "                job = metadata['직업']\n",
    "                # 상세 설명 추가\n",
    "                job_detail = job_details.get(job, \"\")\n",
    "                parts.append(f\"현재 직업은 {job}{job_detail}입니다\")\n",
    "            \n",
    "            # 학력이 있으면 추가 (직업 정보와 함께)\n",
    "            if \"학력\" in metadata:\n",
    "                parts.append(f\"최종 학력은 {metadata['학력']}입니다\")\n",
    "            \n",
    "            # 소득 정보는 쿼리에서 제공되지 않으므로 생략\n",
    "            # (실제 ChromaDB에는 있지만, 검색 시에는 직업만으로 충분)\n",
    "            \n",
    "            return \". \".join(parts) + \".\" if parts else \"\"\n",
    "        \n",
    "        elif category == \"전자제품\":\n",
    "            # ChromaDB topic=\"전자제품\" 형식\n",
    "            # \"TV, 냉장고, 세탁기 등 전자제품을 보유하고 있습니다.\"\n",
    "            if \"전자제품\" in metadata:\n",
    "                products = metadata['전자제품']\n",
    "                return f\"{products} 등 전자제품을 보유하고 있습니다.\"\n",
    "            return \"\"\n",
    "        \n",
    "        elif category == \"휴대폰\":\n",
    "            # ChromaDB topic=\"휴대폰\" 형식\n",
    "            # \"현재 사용 중인 휴대폰은 삼성전자의 갤럭시 M 시리즈입니다.\"\n",
    "            if \"휴대폰\" in metadata:\n",
    "                return f\"현재 사용 중인 휴대폰은 {metadata['휴대폰']}입니다.\"\n",
    "            return \"\"\n",
    "        \n",
    "        elif category == \"자동차\":\n",
    "            # ChromaDB topic=\"자동차\" 형식\n",
    "            # \"현재 보유 차량은 없습니다.\" 또는 \"지프 컴패스 모델의 자동차를 보유하고 있습니다.\"\n",
    "            if \"자동차\" in metadata:\n",
    "                car = metadata['자동차']\n",
    "                if car in [\"없음\", \"없습니다\", \"보유하지 않음\"]:\n",
    "                    return \"현재 보유 차량은 없습니다.\"\n",
    "                else:\n",
    "                    return f\"{car} 모델의 자동차를 보유하고 있습니다.\"\n",
    "            return \"\"\n",
    "        \n",
    "        elif category == \"흡연\":\n",
    "            # ChromaDB topic=\"흡연\" 형식\n",
    "            # \"일반 담배를 경험한 적이 있습니다.\"\n",
    "            if \"흡연\" in metadata:\n",
    "                smoking = metadata['흡연']\n",
    "                if smoking in [\"흡연\", \"일반담배\", \"담배\"]:\n",
    "                    return \"일반 담배를 경험한 적이 있습니다.\"\n",
    "                elif smoking in [\"비흡연\", \"없음\"]:\n",
    "                    return \"흡연 경험이 없습니다.\"\n",
    "                else:\n",
    "                    return f\"{smoking}를 경험한 적이 있습니다.\"\n",
    "            return \"\"\n",
    "        \n",
    "        elif category == \"음주\":\n",
    "            # ChromaDB topic=\"음주\" 형식\n",
    "            # \"음주 경험이 있는 술 종류는 소주, 맥주입니다.\"\n",
    "            if \"음주\" in metadata:\n",
    "                drinks = metadata['음주']\n",
    "                return f\"음주 경험이 있는 술 종류는 {drinks}입니다.\"\n",
    "            return \"\"\n",
    "        \n",
    "        elif category == \"건강\":\n",
    "            # ChromaDB에는 건강 topic이 없지만, 활동/운동 정보 생성\n",
    "            parts = []\n",
    "            if \"활동\" in metadata:\n",
    "                parts.append(f\"{metadata['활동']} 활동을 합니다\")\n",
    "            if \"운동\" in metadata:\n",
    "                parts.append(f\"{metadata['운동']} 운동을 합니다\")\n",
    "            return \". \".join(parts) + \".\" if parts else \"\"\n",
    "        \n",
    "        elif category == \"미디어\":\n",
    "            # ChromaDB에는 미디어 topic 형식 참고\n",
    "            if \"OTT\" in metadata:\n",
    "                return f\"현재 이용 중인 OTT 서비스는 {metadata['OTT']}개입니다.\"\n",
    "            return \"\"\n",
    "        \n",
    "        # 기본 템플릿이 없는 경우\n",
    "        return \"\"\n",
    "\n",
    "    def _generate_by_llm(self, category: str, metadata_items: List[str]) -> str:\n",
    "        \"\"\"LLM으로 텍스트 생성 (템플릿이 없는 경우)\"\"\"\n",
    "        metadata_str = \", \".join(metadata_items)\n",
    "        \n",
    "        prompt = f\"\"\"다음 메타데이터를 자연스러운 한국어 문장으로 변환하세요.\n",
    "\n",
    "카테고리: {category}\n",
    "메타데이터: {metadata_str}\n",
    "\n",
    "규칙:\n",
    "- 존댓말 사용 (입니다/습니다)\n",
    "- 제공된 정보만 사용\n",
    "- 카테고리 이름 포함하지 말 것\n",
    "\n",
    "문장만 출력하세요:\"\"\"\n",
    "\n",
    "        try:\n",
    "            response = self.client.messages.create(\n",
    "                model=self.model,\n",
    "                max_tokens=512,\n",
    "                temperature=0.3,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "            )\n",
    "            \n",
    "            text = response.content[0].text.strip()\n",
    "            text = text.replace('\"', '').replace(\"'\", '').replace('```', '').strip()\n",
    "            \n",
    "            print(f\"\\n[{category}] {text[:80]}...\")\n",
    "            return text\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] LLM 텍스트 생성 실패: {e}\")\n",
    "            return metadata_str\n",
    "\n",
    "\n",
    "print(\"CategoryTextGenerator 클래스 정의 완료 (ChromaDB 저장 형식 + 직업 상세 설명)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 임베딩 생성기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ EmbeddingGenerator 클래스 정의 완료 (검색용 query 모델)\n"
     ]
    }
   ],
   "source": [
    "class EmbeddingGenerator:\n",
    "    \"\"\"Upstage Solar로 임베딩 생성 (검색용 query 모델)\"\"\"\n",
    "\n",
    "    def __init__(self, api_key: str):\n",
    "        # ⭐ 검색할 때는 solar-embedding-1-large-query 사용\n",
    "        # (Pinecone에 저장할 때는 solar-embedding-1-large-passage 사용했음)\n",
    "        self.embeddings = UpstageEmbeddings(\n",
    "            api_key=api_key,\n",
    "            model=\"solar-embedding-1-large-query\"\n",
    "        )\n",
    "\n",
    "    def generate(self, texts: Dict[str, str]) -> Dict[str, List[float]]:\n",
    "        \"\"\"카테고리별 임베딩 생성\"\"\"\n",
    "        result = {}\n",
    "\n",
    "        for category, text in texts.items():\n",
    "            if not text:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                embedding = self.embeddings.embed_query(text)\n",
    "                result[category] = embedding\n",
    "                print(f\"✅ [{category}] 임베딩 생성 완료\")\n",
    "            except Exception as e:\n",
    "                print(f\"❌ [{category}] 임베딩 생성 실패: {e}\")\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "print(\"✅ EmbeddingGenerator 클래스 정의 완료 (검색용 query 모델)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Pinecone 검색기 (다중 값 필터 지원) ⭐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ PineconeSearcher 클래스 정의 완료\n"
     ]
    }
   ],
   "source": [
    "class PineconeSearcher:\n",
    "    \"\"\"Pinecone 벡터DB 검색 (전체 topic 메타데이터 필터 지원 + Fallback)\"\"\"\n",
    "\n",
    "    def __init__(self, pinecone_api_key: str, index_name: str, category_config: Dict[str, Any]):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            pinecone_api_key: Pinecone API 키\n",
    "            index_name: Pinecone 인덱스 이름\n",
    "            category_config: 카테고리 설정 딕셔너리\n",
    "        \"\"\"\n",
    "        self.category_config = category_config\n",
    "\n",
    "        # Pinecone 초기화\n",
    "        pc = Pinecone(api_key=pinecone_api_key)\n",
    "        self.index = pc.Index(index_name)\n",
    "\n",
    "        print(f\"✅ Pinecone 검색기 초기화 완료: {index_name}\")\n",
    "\n",
    "    def search_by_category(\n",
    "        self,\n",
    "        query_embedding: List[float],\n",
    "        category: str,\n",
    "        top_k: int,\n",
    "        filter_mb_sns: List[str] = None,\n",
    "        metadata_filter: Dict[str, Any] = None\n",
    "    ) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        특정 카테고리로 Pinecone 검색 (메타데이터 필터 + Fallback 지원)\n",
    "\n",
    "        Args:\n",
    "            query_embedding: 쿼리 임베딩 벡터\n",
    "            category: 검색할 카테고리 (예: \"기본정보\", \"직업소득\", \"자동차\")\n",
    "            top_k: 검색 결과 개수\n",
    "            filter_mb_sns: 필터링할 mb_sn 리스트 (이 중에서만 검색)\n",
    "            metadata_filter: Pinecone 메타데이터 필터 (topic별로 다름)\n",
    "\n",
    "        Returns:\n",
    "            [{\"id\": ..., \"score\": ..., \"mb_sn\": ..., \"index\": ..., \"topic\": ..., \"text\": ...}]\n",
    "        \"\"\"\n",
    "        # top_k 유효성 검사\n",
    "        if top_k <= 0:\n",
    "            return []\n",
    "\n",
    "        # 후보 mb_sn이 비어있는 경우 처리\n",
    "        if filter_mb_sns is not None and len(filter_mb_sns) == 0:\n",
    "            return []\n",
    "\n",
    "        # 카테고리에 해당하는 Pinecone topic 가져오기\n",
    "        pinecone_topic = self.category_config.get(category, {}).get(\"pinecone_topic\", category)\n",
    "\n",
    "        # 기본 필터: topic\n",
    "        filter_dict = {\"topic\": pinecone_topic}\n",
    "\n",
    "        # mb_sn 필터 추가 (이전 단계에서 선별된 mb_sn들로 제한)\n",
    "        if filter_mb_sns:\n",
    "            filter_dict[\"mb_sn\"] = {\"$in\": filter_mb_sns}\n",
    "\n",
    "        # 🎯 1차 시도: 메타데이터 필터 적용\n",
    "        if metadata_filter:\n",
    "            filter_with_metadata = filter_dict.copy()\n",
    "            filter_with_metadata.update(metadata_filter)\n",
    "\n",
    "            # Pinecone 검색 (메타데이터 필터 포함)\n",
    "            search_results = self.index.query(\n",
    "                vector=query_embedding,\n",
    "                top_k=top_k,\n",
    "                include_metadata=True,\n",
    "                filter=filter_with_metadata\n",
    "            )\n",
    "\n",
    "            # 🔄 Fallback: 결과가 0개면 메타데이터 필터 없이 재검색\n",
    "            if len(search_results.matches) == 0:\n",
    "                print(f\"    ⚠️ 메타데이터 필터로 0건 → Fallback (topic만)\")\n",
    "                search_results = self.index.query(\n",
    "                    vector=query_embedding,\n",
    "                    top_k=top_k,\n",
    "                    include_metadata=True,\n",
    "                    filter=filter_dict  # 메타데이터 필터 제거\n",
    "                )\n",
    "        else:\n",
    "            # 메타데이터 필터 없이 검색\n",
    "            search_results = self.index.query(\n",
    "                vector=query_embedding,\n",
    "                top_k=top_k,\n",
    "                include_metadata=True,\n",
    "                filter=filter_dict\n",
    "            )\n",
    "\n",
    "        # 결과 저장\n",
    "        matches = []\n",
    "        for match in search_results.matches:\n",
    "            metadata = match.metadata or {}\n",
    "            matches.append({\n",
    "                \"id\": match.id,\n",
    "                \"score\": match.score,\n",
    "                \"mb_sn\": metadata.get(\"mb_sn\", \"\"),\n",
    "                \"index\": metadata.get(\"index\", 0),\n",
    "                \"topic\": metadata.get(\"topic\", \"\"),\n",
    "                \"text\": metadata.get(\"text\", \"\"),\n",
    "                \"지역\": metadata.get(\"지역\", \"\"),\n",
    "                \"연령대\": metadata.get(\"연령대\", \"\"),\n",
    "                \"성별\": metadata.get(\"성별\", \"\")\n",
    "            })\n",
    "\n",
    "        return matches\n",
    "\n",
    "\n",
    "print(\"✅ PineconeSearcher 클래스 정의 완료\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 결과 필터 (단계적 필터링)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ResultFilter 클래스 정의 완료\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import gc\n",
    "\n",
    "class ResultFilter:\n",
    "    \"\"\"카테고리 순서에 따라 단계적으로 mb_sn을 필터링 (전체 topic 메타데이터 필터 지원)\"\"\"\n",
    "\n",
    "    def __init__(self, pinecone_searcher: PineconeSearcher):\n",
    "        self.searcher = pinecone_searcher\n",
    "\n",
    "    def filter_by_categories(\n",
    "        self,\n",
    "        embeddings: Dict[str, List[float]],\n",
    "        category_order: List[str],\n",
    "        final_count: int,\n",
    "        topic_filters: Dict[str, Dict[str, Any]] = None\n",
    "    ) -> List[str]:\n",
    "        \"\"\"\n",
    "        카테고리 순서대로 단계적으로 필터링하여 최종 mb_sn 리스트 반환\n",
    "\n",
    "        Args:\n",
    "            embeddings: {\"카테고리명\": [임베딩 벡터]}\n",
    "            category_order: 카테고리 순서 (예: [\"기본정보\", \"직업소득\", \"자동차\"])\n",
    "            final_count: 최종 출력할 mb_sn 개수\n",
    "            topic_filters: topic별 메타데이터 필터 (예: {\"기본정보\": {...}, \"직업소득\": {...}})\n",
    "\n",
    "        Returns:\n",
    "            최종 선별된 mb_sn 리스트\n",
    "        \"\"\"\n",
    "        if not category_order:\n",
    "            return []\n",
    "\n",
    "        # 첫 번째 카테고리로 초기 선별\n",
    "        first_category = category_order[0]\n",
    "        first_embedding = embeddings.get(first_category)\n",
    "\n",
    "        if first_embedding is None:\n",
    "            return []\n",
    "\n",
    "        # 🎯 첫 번째 카테고리의 메타데이터 필터 가져오기\n",
    "        first_filter = (topic_filters or {}).get(first_category, {})\n",
    "\n",
    "        if first_filter:\n",
    "            print(f\"\\n[1단계] {first_category} 카테고리 검색 (메타데이터 필터 적용)\")\n",
    "            print(f\"   필터: {first_filter}\")\n",
    "        else:\n",
    "            print(f\"\\n[1단계] {first_category} 카테고리 검색 (필터 없음)\")\n",
    "\n",
    "        # 초기 검색 수 결정\n",
    "        initial_count = max(final_count * 10, 100)\n",
    "\n",
    "        first_results = self.searcher.search_by_category(\n",
    "            query_embedding=first_embedding,\n",
    "            category=first_category,\n",
    "            top_k=initial_count,\n",
    "            metadata_filter=first_filter\n",
    "        )\n",
    "\n",
    "        # 첫 번째 카테고리에서 선별된 mb_sn 추출\n",
    "        candidate_mb_sns = list(set([r[\"mb_sn\"] for r in first_results if r[\"mb_sn\"]]))\n",
    "\n",
    "        print(f\"   -> {len(candidate_mb_sns)}개 후보 선별\")\n",
    "\n",
    "        # 후보가 없으면 빈 리스트 반환\n",
    "        if len(candidate_mb_sns) == 0:\n",
    "            return []\n",
    "\n",
    "        # 나머지 카테고리로 점진적 필터링\n",
    "        for i, category in enumerate(category_order[1:], start=2):\n",
    "            embedding = embeddings.get(category)\n",
    "\n",
    "            if embedding is None:\n",
    "                continue\n",
    "\n",
    "            # 🎯 현재 카테고리의 메타데이터 필터 가져오기\n",
    "            category_filter = (topic_filters or {}).get(category, {})\n",
    "\n",
    "            if category_filter:\n",
    "                print(f\"\\n[{i}단계] {category} 카테고리로 재필터링 (메타데이터 필터 적용)\")\n",
    "                print(f\"   필터: {category_filter}\")\n",
    "            else:\n",
    "                print(f\"\\n[{i}단계] {category} 카테고리로 재필터링 (필터 없음)\")\n",
    "\n",
    "            # 후보가 비어있으면 필터링 중단\n",
    "            if len(candidate_mb_sns) == 0:\n",
    "                break\n",
    "\n",
    "            # 후보가 너무 많으면 Pinecone 필터로 처리 가능한 수준으로 제한\n",
    "            search_count = min(len(candidate_mb_sns) * 2, 1000)\n",
    "\n",
    "            # search_count가 0 이하가 되지 않도록 보장\n",
    "            search_count = max(search_count, 1)\n",
    "\n",
    "            results = self.searcher.search_by_category(\n",
    "                query_embedding=embedding,\n",
    "                category=category,\n",
    "                top_k=search_count,\n",
    "                filter_mb_sns=candidate_mb_sns,\n",
    "                metadata_filter=category_filter\n",
    "            )\n",
    "\n",
    "            # mb_sn별 최고 점수 집계\n",
    "            mb_sn_scores = {}\n",
    "            for r in results:\n",
    "                mb_sn = r[\"mb_sn\"]\n",
    "                if mb_sn in candidate_mb_sns:\n",
    "                    if mb_sn not in mb_sn_scores or r[\"score\"] > mb_sn_scores[mb_sn]:\n",
    "                        mb_sn_scores[mb_sn] = r[\"score\"]\n",
    "\n",
    "            # 점수 순으로 정렬하여 상위 후보 선별\n",
    "            sorted_mb_sns = sorted(mb_sn_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "            # 다음 단계를 위한 후보 수 결정\n",
    "            next_candidate_count = max(final_count * 3, 30)\n",
    "            candidate_mb_sns = [mb_sn for mb_sn, score in sorted_mb_sns[:next_candidate_count]]\n",
    "\n",
    "            print(f\"   -> {len(candidate_mb_sns)}개 후보 선별\")\n",
    "\n",
    "        # 최종 결과 반환\n",
    "        final_mb_sns = candidate_mb_sns[:final_count]\n",
    "\n",
    "        print(f\"\\n최종 {len(final_mb_sns)}개 패널 선별 완료\")\n",
    "        print(\"=\" * 80)\n",
    "\n",
    "        return final_mb_sns\n",
    "\n",
    "\n",
    "print(\"✅ ResultFilter 클래스 정의 완료\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 전체 검색 파이프라인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PanelSearchPipeline 클래스 정의 완료 (Pinecone + LLM 필터 + 다중 값 지원)\n"
     ]
    }
   ],
   "source": [
    "class PanelSearchPipeline:\n",
    "    \"\"\"전체 검색 파이프라인 (Pinecone + LLM 기반 메타데이터 필터)\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        pinecone_api_key: str,\n",
    "        pinecone_index_name: str,\n",
    "        category_config: Dict[str, Any],\n",
    "        anthropic_api_key: str,\n",
    "        upstage_api_key: str\n",
    "    ):\n",
    "        self.metadata_extractor = MetadataExtractor(anthropic_api_key)\n",
    "        self.filter_extractor = MetadataFilterExtractor(anthropic_api_key)  # ⭐ LLM 기반 필터 추출기 추가\n",
    "        self.category_classifier = CategoryClassifier(category_config, anthropic_api_key)\n",
    "        self.text_generator = CategoryTextGenerator(anthropic_api_key)\n",
    "        self.embedding_generator = EmbeddingGenerator(upstage_api_key)\n",
    "        self.searcher = PineconeSearcher(pinecone_api_key, pinecone_index_name, category_config)  # ⭐ Pinecone으로 변경\n",
    "        self.result_filter = ResultFilter(self.searcher)\n",
    "\n",
    "    def search(self, query: str, top_k: int = 10) -> List[str]:\n",
    "        \"\"\"\n",
    "        자연어 쿼리로 패널 검색\n",
    "\n",
    "        Args:\n",
    "            query: 검색 쿼리 (예: \"서울 20대 남자\")\n",
    "            top_k: 반환할 패널 수\n",
    "\n",
    "        Returns:\n",
    "            mb_sn 리스트\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(f\"검색 쿼리: '{query}'\")\n",
    "        print(\"=\" * 80)\n",
    "\n",
    "        # 1단계: 메타데이터 추출\n",
    "        print(\"\\n[1단계] 메타데이터 추출\")\n",
    "        metadata = self.metadata_extractor.extract(query)\n",
    "\n",
    "        if not metadata:\n",
    "            print(\"[ERROR] 메타데이터 추출 실패\")\n",
    "            return []\n",
    "\n",
    "        # 2단계: 카테고리 분류\n",
    "        print(\"\\n[2단계] 카테고리 분류\")\n",
    "        classified = self.category_classifier.classify(metadata)\n",
    "\n",
    "        if not classified:\n",
    "            print(\"[ERROR] 카테고리 분류 실패\")\n",
    "            return []\n",
    "\n",
    "        # 2.5단계: LLM으로 카테고리별 메타데이터 필터 추출 및 정규화\n",
    "        print(\"\\n[2.5단계] 카테고리별 메타데이터 필터 추출 (LLM)\")\n",
    "        category_filters = {}\n",
    "        for category in classified.keys():\n",
    "            cat_filter = self.filter_extractor.extract_filters(metadata, category)  # ⭐ LLM 사용\n",
    "            if cat_filter:\n",
    "                category_filters[category] = cat_filter\n",
    "\n",
    "        # 3단계: 자연어 텍스트 생성\n",
    "        print(\"\\n[3단계] 자연어 텍스트 생성\")\n",
    "        texts = {}\n",
    "        for category, items in classified.items():\n",
    "            text = self.text_generator.generate(category, items)\n",
    "            if text:\n",
    "                texts[category] = text\n",
    "\n",
    "        # 4단계: 임베딩 생성\n",
    "        print(\"\\n[4단계] 임베딩 생성\")\n",
    "        embeddings = self.embedding_generator.generate(texts)\n",
    "\n",
    "        if not embeddings:\n",
    "            print(\"[ERROR] 임베딩 생성 실패\")\n",
    "            return []\n",
    "\n",
    "        # 5단계: 단계적 필터링 검색\n",
    "        print(f\"\\n[5단계] 패널 검색 시작\")\n",
    "\n",
    "        category_order = list(embeddings.keys())\n",
    "        final_mb_sns = self.result_filter.filter_by_categories(\n",
    "            embeddings=embeddings,\n",
    "            category_order=category_order,\n",
    "            final_count=top_k,\n",
    "            topic_filters=category_filters\n",
    "        )\n",
    "\n",
    "        return final_mb_sns\n",
    "\n",
    "\n",
    "print(\"PanelSearchPipeline 클래스 정의 완료 (Pinecone + LLM 필터 + 다중 값 지원)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. 파이프라인 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Pinecone 검색기 초기화 완료: panel-profiles\n",
      "\n",
      "[SUCCESS] Pinecone 검색 파이프라인 초기화 완료 (다중 값 필터 지원)\n"
     ]
    }
   ],
   "source": [
    "# 검색 파이프라인 초기화 (Pinecone 버전)\n",
    "\n",
    "# 이전 파이프라인 객체가 있으면 정리\n",
    "if 'pipeline' in locals() or 'pipeline' in globals():\n",
    "    try:\n",
    "        if hasattr(pipeline, 'searcher'):\n",
    "            if hasattr(pipeline.searcher, 'pc'):\n",
    "                del pipeline.searcher.pc\n",
    "            if hasattr(pipeline.searcher, 'index'):\n",
    "                del pipeline.searcher.index\n",
    "        if hasattr(pipeline, 'embedding_generator') and hasattr(pipeline.embedding_generator, 'embeddings'):\n",
    "            del pipeline.embedding_generator.embeddings\n",
    "        del pipeline\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# 가비지 컬렉션 강제 실행\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "try:\n",
    "    pipeline = PanelSearchPipeline(\n",
    "        pinecone_api_key=PINECONE_API_KEY,\n",
    "        pinecone_index_name=PINECONE_INDEX_NAME,\n",
    "        category_config=CATEGORY_CONFIG,\n",
    "        anthropic_api_key=ANTHROPIC_API_KEY,\n",
    "        upstage_api_key=UPSTAGE_API_KEY\n",
    "    )\n",
    "    print(\"\\n[SUCCESS] Pinecone 검색 파이프라인 초기화 완료 (다중 값 필터 지원)\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n[ERROR] 파이프라인 초기화 실패:\")\n",
    "    print(f\"  오류 타입: {type(e).__name__}\")\n",
    "    print(f\"  오류 메시지: {str(e)}\")\n",
    "    print(\"\\n⚠️ 해결 방법: Pinecone API 키와 인덱스 이름을 확인하세요\")\n",
    "    import traceback\n",
    "    print(f\"\\n상세 오류:\")\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. 테스트: 검색 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "검색 쿼리: '서울 술을 먹은 여자'\n",
      "================================================================================\n",
      "\n",
      "[1단계] 메타데이터 추출\n",
      "\n",
      "[메타데이터 추출 - LLM 원본] {'지역': '서울', '음주': '경험', '성별': '여자'}\n",
      "[메타데이터 추출 - 최종] {'지역': '서울', '음주': '경험', '성별': '여'}\n",
      "\n",
      "[2단계] 카테고리 분류\n",
      "\n",
      "[카테고리 분류] {'기본정보': ['지역: 서울', '성별: 여'], '음주': ['음주: 경험']}\n",
      "\n",
      "[2.5단계] 카테고리별 메타데이터 필터 추출 (LLM)\n",
      "   [기본정보] 필터 정규화: {'지역': '서울', '성별': '여'} → {'지역': '서울', '성별': '여'}\n",
      "\n",
      "[3단계] 자연어 텍스트 생성\n",
      "\n",
      "[기본정보] 서울에 거주하는 여입니다....\n",
      "\n",
      "[음주] 음주 경험이 있는 술 종류는 경험입니다....\n",
      "\n",
      "[4단계] 임베딩 생성\n",
      "✅ [기본정보] 임베딩 생성 완료\n",
      "✅ [음주] 임베딩 생성 완료\n",
      "\n",
      "[5단계] 패널 검색 시작\n",
      "\n",
      "[1단계] 기본정보 카테고리 검색 (메타데이터 필터 적용)\n",
      "   필터: {'지역': '서울', '성별': '여'}\n",
      "   -> 79개 후보 선별\n",
      "\n",
      "[2단계] 음주 카테고리로 재필터링 (필터 없음)\n",
      "   -> 30개 후보 선별\n",
      "\n",
      "최종 10개 패널 선별 완료\n",
      "================================================================================\n",
      "\n",
      "총 10개 패널 발견\n",
      "\n",
      "패널 목록:\n",
      "  1. w79026584473603\n",
      "  2. w449965879417018\n",
      "  3. w428875643389843\n",
      "  4. w187667133316212\n",
      "  5. w275833310402669\n",
      "  6. w183588945614086\n",
      "  7. w204143358246717\n",
      "  8. w69197643971928\n",
      "  9. w188629558729641\n",
      "  10. w394286397471609\n"
     ]
    }
   ],
   "source": [
    "# ===== 테스트 1: 단일 조건 ===== \n",
    "# 테스트 쿼리: \"서울 20대 남자\"\n",
    "# → 메타데이터 필터: {\"지역\": \"서울\", \"연령대\": \"20대\", \"성별\": \"남자\"}\n",
    "test_query = \"서울 술을 먹은 여자\"\n",
    "\n",
    "# 검색 실행\n",
    "results = pipeline.search(test_query, top_k=10)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"\\n총 {len(results)}개 패널 발견\")\n",
    "\n",
    "if len(results) > 0:\n",
    "    print(\"\\n패널 목록:\")\n",
    "    for i, mb_sn in enumerate(results, 1):\n",
    "        print(f\"  {i}. {mb_sn}\")\n",
    "else:\n",
    "    print(\"\\n조건에 맞는 패널이 없습니다.\")\n",
    "\n",
    "# ===== 테스트 2: 다중 값 필터 (⭐ Pinecone $in 연산자 활용) =====\n",
    "# 테스트 쿼리: \"서울, 경기 30대 여자\"\n",
    "# → 메타데이터 필터: {\"지역\": [\"서울\", \"경기\"], \"연령대\": \"30대\", \"성별\": \"여자\"}\n",
    "# Pinecone은 $in 연산자를 통해 \"서울 또는 경기\"를 자동 처리\n",
    "# test_query2 = \"서울, 경기 30대 여자\"\n",
    "\n",
    "# print(\"\\n\" + \"=\" * 80)\n",
    "# print(\"\\n🔍 다중 값 필터 테스트 (서울 OR 경기)\")\n",
    "# results2 = pipeline.search(test_query2, top_k=10)\n",
    "\n",
    "# print(f\"\\n총 {len(results2)}개 패널 발견\")\n",
    "# if len(results2) > 0:\n",
    "#     print(\"\\n패널 목록:\")\n",
    "#     for i, mb_sn in enumerate(results2, 1):\n",
    "#         print(f\"  {i}. {mb_sn}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1단계: 메모리 완전 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gc\n",
    "\n",
    "# # 모든 객체 삭제\n",
    "# objects_to_delete = ['pipeline', 'client', 'response', 'searcher', 'embeddings']\n",
    "\n",
    "# for obj_name in objects_to_delete:\n",
    "#     if obj_name in globals():\n",
    "#         try:\n",
    "#             del globals()[obj_name]\n",
    "#             print(f\"✅ {obj_name} 삭제됨\")\n",
    "#         except:\n",
    "#             pass\n",
    "\n",
    "# # 강제 가비지 컬렉션 (3번 실행)\n",
    "# for i in range(3):\n",
    "#     gc.collect()\n",
    "#     print(f\"🗑️ GC 실행 {i+1}/3\")\n",
    "\n",
    "# print(\"\\n✅ 메모리 정리 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2단계: ChromaDB 연결 완전 종료"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ChromaDB 클라이언트들이 파일을 많이 열어두는 경우가 많음\n",
    "# import chromadb\n",
    "\n",
    "# # 기존 ChromaDB 인스턴스 정리\n",
    "# try:\n",
    "#     # 혹시 있을 수 있는 persistent client 정리\n",
    "#     if 'chroma_client' in globals():\n",
    "#         del chroma_client\n",
    "#     gc.collect()\n",
    "#     print(\"✅ ChromaDB 연결 정리 완료\")\n",
    "# except Exception as e:\n",
    "#     print(f\"ChromaDB 정리 중 에러 (무시 가능): {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3단계: Context Manager로 API 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from anthropic import Anthropic\n",
    "# import os\n",
    "\n",
    "# current_key = os.getenv('ANTHROPIC_API_KEY', ANTHROPIC_API_KEY)\n",
    "\n",
    "# # Context Manager 사용 - 자동으로 연결 종료\n",
    "# try:\n",
    "#     with Anthropic(api_key=current_key) as client:\n",
    "#         response = client.messages.create(\n",
    "#             model=\"claude-haiku-4-5-20251001\",\n",
    "#             max_tokens=20,\n",
    "#             messages=[{\"role\": \"user\", \"content\": \"Say hi\"}]\n",
    "#         )\n",
    "        \n",
    "#         print(\"✅ API 호출 성공!\")\n",
    "#         print(f\"응답: {response.content[0].text}\")\n",
    "#         print(f\"Input tokens: {response.usage.input_tokens}\")\n",
    "#         print(f\"Output tokens: {response.usage.output_tokens}\")\n",
    "#         print(f\"\\nModel: {response.model}\")\n",
    "#         print(f\"Stop reason: {response.stop_reason}\")\n",
    "        \n",
    "# except Exception as e:\n",
    "#     print(f\"❌ API 호출 실패: {e}\")\n",
    "#     import traceback\n",
    "#     traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
